{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1033,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "from datetime import date\n",
    "import random\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.metrics import roc_auc_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import accuracy_score\n",
    "from imblearn.over_sampling import SMOTE\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "import keras\n",
    "from keras.models import Sequential\n",
    "from keras.layers import Dense\n",
    "from keras.layers import Conv2D\n",
    "from keras.layers import MaxPooling2D\n",
    "from keras.layers import Flatten\n",
    "from keras.layers import Dropout\n",
    "\n",
    "import tensorflow as tf\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import random \n",
    "# random.seed(42)\n",
    "\n",
    "from numpy.random import seed\n",
    "seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1034,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path_1 = \"training_dataset.csv\"\n",
    "csv_path_2 = \"score.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. First, let's understand our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1035,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>id_driver</th>\n",
       "      <th>id_carrier_number</th>\n",
       "      <th>dim_carrier_type</th>\n",
       "      <th>dim_carrier_company_name</th>\n",
       "      <th>home_base_city</th>\n",
       "      <th>home_base_state</th>\n",
       "      <th>carrier_trucks</th>\n",
       "      <th>...</th>\n",
       "      <th>most_recent_load_date</th>\n",
       "      <th>load_day</th>\n",
       "      <th>loads</th>\n",
       "      <th>marketplace_loads_otr</th>\n",
       "      <th>marketplace_loads_atlas</th>\n",
       "      <th>marketplace_loads</th>\n",
       "      <th>brokerage_loads_otr</th>\n",
       "      <th>brokerage_loads_atlas</th>\n",
       "      <th>brokerage_loads</th>\n",
       "      <th>total_loads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2019</td>\n",
       "      <td>21350</td>\n",
       "      <td>U0109015</td>\n",
       "      <td>Owner Operator</td>\n",
       "      <td>CA&amp;F TRUCKING</td>\n",
       "      <td>Maywood</td>\n",
       "      <td>CA</td>\n",
       "      <td>[\"poweronly\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2021</td>\n",
       "      <td>36437</td>\n",
       "      <td>C0097727</td>\n",
       "      <td>Fleet</td>\n",
       "      <td>New opportunities inc</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>[\"poweronly\", \"boxtruck\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2019</td>\n",
       "      <td>19323</td>\n",
       "      <td>U0107081</td>\n",
       "      <td>Owner Operator</td>\n",
       "      <td>RAS</td>\n",
       "      <td>Compton</td>\n",
       "      <td>CA</td>\n",
       "      <td>[\"poweronly\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2021</td>\n",
       "      <td>34809</td>\n",
       "      <td>C0094651</td>\n",
       "      <td>Fleet</td>\n",
       "      <td>NFS asset Drayage</td>\n",
       "      <td>Lynwood</td>\n",
       "      <td>CA</td>\n",
       "      <td>[\"poweronly\", \"dryvan\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2017</td>\n",
       "      <td>4728</td>\n",
       "      <td>U0094376</td>\n",
       "      <td>Owner Operator</td>\n",
       "      <td>joes transportation</td>\n",
       "      <td>Norco</td>\n",
       "      <td>CA</td>\n",
       "      <td>[\"dryvan\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-10-11</td>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt    weekday  year  id_driver id_carrier_number dim_carrier_type  \\\n",
       "0  2019-12-16     Monday  2019      21350          U0109015   Owner Operator   \n",
       "1  2021-01-15     Friday  2021      36437          C0097727            Fleet   \n",
       "2  2019-12-26   Thursday  2019      19323          U0107081   Owner Operator   \n",
       "3  2021-02-10  Wednesday  2021      34809          C0094651            Fleet   \n",
       "4  2017-07-24     Monday  2017       4728          U0094376   Owner Operator   \n",
       "\n",
       "  dim_carrier_company_name home_base_city home_base_state  \\\n",
       "0            CA&F TRUCKING        Maywood              CA   \n",
       "1   New opportunities inc     Los Angeles              CA   \n",
       "2                      RAS        Compton              CA   \n",
       "3        NFS asset Drayage        Lynwood              CA   \n",
       "4      joes transportation          Norco              CA   \n",
       "\n",
       "              carrier_trucks  ...  most_recent_load_date    load_day loads  \\\n",
       "0              [\"poweronly\"]  ...             2021-02-17  2019-12-16     2   \n",
       "1  [\"poweronly\", \"boxtruck\"]  ...             2021-02-03  2021-01-15     1   \n",
       "2              [\"poweronly\"]  ...             2020-09-25  2019-12-26     1   \n",
       "3    [\"poweronly\", \"dryvan\"]  ...             2021-02-17  2021-02-10     3   \n",
       "4                 [\"dryvan\"]  ...             2017-10-11  2017-07-24     2   \n",
       "\n",
       "  marketplace_loads_otr marketplace_loads_atlas marketplace_loads  \\\n",
       "0                     0                     438               438   \n",
       "1                     2                      72                74   \n",
       "2                     0                     180               180   \n",
       "3                     0                       0                 0   \n",
       "4                    57                       0                57   \n",
       "\n",
       "   brokerage_loads_otr brokerage_loads_atlas brokerage_loads total_loads  \n",
       "0                    0                    45              45         483  \n",
       "1                    0                     1               1          75  \n",
       "2                    0                     2               2         182  \n",
       "3                    0                     0               0          62  \n",
       "4                  314                     0             314         371  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_path_1) # load the pandas dataframe\n",
    "df_score = pd.read_csv(csv_path_2)\n",
    "initial_cols_to_drop = [\"Unnamed: 0\",\"Unnamed: 0.1\", \"period\", \"test\", \"recent_date\", \"date\"] \n",
    "for col_name in initial_cols_to_drop: # drops columns that aren't supposed to be in dataset\n",
    "    try:\n",
    "        df = df.drop(columns=[col_name])\n",
    "        df_score = df_score.drop(columns=[col_name])\n",
    "    except:\n",
    "        continue\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1036,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id_driver</th>\n",
       "      <th>num_trucks</th>\n",
       "      <th>days_signup_to_approval</th>\n",
       "      <th>loads</th>\n",
       "      <th>marketplace_loads_otr</th>\n",
       "      <th>marketplace_loads_atlas</th>\n",
       "      <th>marketplace_loads</th>\n",
       "      <th>brokerage_loads_otr</th>\n",
       "      <th>brokerage_loads_atlas</th>\n",
       "      <th>brokerage_loads</th>\n",
       "      <th>total_loads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83344.000000</td>\n",
       "      <td>71124.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018.960930</td>\n",
       "      <td>18222.414954</td>\n",
       "      <td>22.582921</td>\n",
       "      <td>298.752489</td>\n",
       "      <td>2.076270</td>\n",
       "      <td>29.477762</td>\n",
       "      <td>71.579675</td>\n",
       "      <td>101.057436</td>\n",
       "      <td>148.258422</td>\n",
       "      <td>13.073021</td>\n",
       "      <td>161.331443</td>\n",
       "      <td>266.502661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.359343</td>\n",
       "      <td>11667.704926</td>\n",
       "      <td>48.829719</td>\n",
       "      <td>390.345107</td>\n",
       "      <td>2.672163</td>\n",
       "      <td>88.171940</td>\n",
       "      <td>194.532776</td>\n",
       "      <td>214.502147</td>\n",
       "      <td>415.978060</td>\n",
       "      <td>42.241592</td>\n",
       "      <td>413.792137</td>\n",
       "      <td>448.806175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>7890.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>16299.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>28974.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2021.000000</td>\n",
       "      <td>38125.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>1653.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>1324.000000</td>\n",
       "      <td>1348.000000</td>\n",
       "      <td>4266.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>4266.000000</td>\n",
       "      <td>4266.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               year     id_driver    num_trucks  days_signup_to_approval  \\\n",
       "count  83414.000000  83414.000000  83344.000000             71124.000000   \n",
       "mean    2018.960930  18222.414954     22.582921               298.752489   \n",
       "std        1.359343  11667.704926     48.829719               390.345107   \n",
       "min     2015.000000     20.000000      1.000000                 0.000000   \n",
       "25%     2018.000000   7890.000000      1.000000                 0.000000   \n",
       "50%     2019.000000  16299.000000      4.000000                61.000000   \n",
       "75%     2020.000000  28974.000000     14.000000               497.000000   \n",
       "max     2021.000000  38125.000000    195.000000              1653.000000   \n",
       "\n",
       "              loads  marketplace_loads_otr  marketplace_loads_atlas  \\\n",
       "count  83414.000000           83414.000000             83414.000000   \n",
       "mean       2.076270              29.477762                71.579675   \n",
       "std        2.672163              88.171940               194.532776   \n",
       "min        1.000000               0.000000                 0.000000   \n",
       "25%        1.000000               0.000000                 0.000000   \n",
       "50%        1.000000               2.000000                 0.000000   \n",
       "75%        2.000000              23.000000                18.000000   \n",
       "max      129.000000             902.000000              1324.000000   \n",
       "\n",
       "       marketplace_loads  brokerage_loads_otr  brokerage_loads_atlas  \\\n",
       "count       83414.000000         83414.000000           83414.000000   \n",
       "mean          101.057436           148.258422              13.073021   \n",
       "std           214.502147           415.978060              42.241592   \n",
       "min             0.000000             0.000000               0.000000   \n",
       "25%             0.000000             0.000000               0.000000   \n",
       "50%            13.000000            15.000000               0.000000   \n",
       "75%            94.000000           112.000000               1.000000   \n",
       "max          1348.000000          4266.000000             371.000000   \n",
       "\n",
       "       brokerage_loads   total_loads  \n",
       "count     83414.000000  83414.000000  \n",
       "mean        161.331443    266.502661  \n",
       "std         413.792137    448.806175  \n",
       "min           0.000000      1.000000  \n",
       "25%           5.000000     37.000000  \n",
       "50%          37.000000    110.000000  \n",
       "75%         135.000000    325.000000  \n",
       "max        4266.000000   4266.000000  "
      ]
     },
     "execution_count": 1036,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1037,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83414 entries, 0 to 83413\n",
      "Data columns (total 30 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   dt                        83414 non-null  object \n",
      " 1   weekday                   83414 non-null  object \n",
      " 2   year                      83414 non-null  int64  \n",
      " 3   id_driver                 83414 non-null  int64  \n",
      " 4   id_carrier_number         83414 non-null  object \n",
      " 5   dim_carrier_type          83414 non-null  object \n",
      " 6   dim_carrier_company_name  83365 non-null  object \n",
      " 7   home_base_city            83369 non-null  object \n",
      " 8   home_base_state           83369 non-null  object \n",
      " 9   carrier_trucks            83414 non-null  object \n",
      " 10  num_trucks                83344 non-null  float64\n",
      " 11  interested_in_drayage     83414 non-null  object \n",
      " 12  port_qualified            83414 non-null  object \n",
      " 13  signup_source             83414 non-null  object \n",
      " 14  ts_signup                 83414 non-null  object \n",
      " 15  ts_first_approved         71124 non-null  object \n",
      " 16  days_signup_to_approval   71124 non-null  float64\n",
      " 17  driver_with_twic          83414 non-null  object \n",
      " 18  dim_preferred_lanes       3412 non-null   object \n",
      " 19  first_load_date           83414 non-null  object \n",
      " 20  most_recent_load_date     83414 non-null  object \n",
      " 21  load_day                  83414 non-null  object \n",
      " 22  loads                     83414 non-null  int64  \n",
      " 23  marketplace_loads_otr     83414 non-null  int64  \n",
      " 24  marketplace_loads_atlas   83414 non-null  int64  \n",
      " 25  marketplace_loads         83414 non-null  int64  \n",
      " 26  brokerage_loads_otr       83414 non-null  int64  \n",
      " 27  brokerage_loads_atlas     83414 non-null  int64  \n",
      " 28  brokerage_loads           83414 non-null  int64  \n",
      " 29  total_loads               83414 non-null  int64  \n",
      "dtypes: float64(2), int64(10), object(18)\n",
      "memory usage: 19.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1038,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts date from csv to a python datetime object making it easier to work with\n",
    "def convert_dates(df):\n",
    "    dates_columns = ['most_recent_load_date', 'first_load_date', 'load_day', 'dt']\n",
    "    for col_name in dates_columns:\n",
    "        try:\n",
    "            df[col_name] = pd.to_datetime(df[col_name], format='%Y-%m-%d')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "convert_dates(df)\n",
    "convert_dates(df_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1039,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2021-02-17\n",
       "1   2021-02-03\n",
       "2   2020-09-25\n",
       "3   2021-02-17\n",
       "4   2017-10-11\n",
       "Name: most_recent_load_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 1039,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['most_recent_load_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1040,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325.0\n",
      "2021-02-14 00:00:00\n"
     ]
    }
   ],
   "source": [
    "total_loads75 = df.total_loads.quantile(0.75) # finds 75th percentile of loads\n",
    "most_recent_load_date75 = df.most_recent_load_date.quantile(0.75) # finds 75th percentile of most recent load date\n",
    "\n",
    "print(total_loads75)\n",
    "print(most_recent_load_date75)\n",
    "# Manual Check\n",
    "# sorted_dts = sorted(list(df.most_recent_load_date))\n",
    "# quartile_estimate_index = int(len(sorted_dts)*0.75)\n",
    "# print(\"SORTED INDEX\", sorted_dts[quartile_estimate_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1041,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_labels = {\"label\": {}}\n",
    "num_days_worked_dict = {}\n",
    "\n",
    "for index, row in df.iterrows(): # changes the labels in the label columns\n",
    "    # checks if the load and most recent load date are in the 75th percentile\n",
    "    if row[\"total_loads\"] >= total_loads75 and row[\"most_recent_load_date\"] >= most_recent_load_date75:\n",
    "        df.at[index, \"label\"] = 1\n",
    "    else:\n",
    "        df.at[index, \"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1042,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values :  [0. 1.]\n",
      "Occurrence Count :  [73021 10393]\n"
     ]
    }
   ],
   "source": [
    "uniqueValues, occurCount = np.unique(np.array(df[\"label\"]), return_counts=True)\n",
    "print(\"Unique Values : \" , uniqueValues)\n",
    "print(\"Occurrence Count : \", occurCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1043,
   "metadata": {},
   "outputs": [],
   "source": [
    "loc_arr = []\n",
    "for index, row in df.iterrows():\n",
    "    if pd.isnull(row[\"home_base_city\"]) != True and pd.isnull(row[\"home_base_state\"]) != True:\n",
    "        if (row[\"home_base_city\"], row[\"home_base_state\"]) not in loc_arr:\n",
    "            loc_arr.append((row[\"home_base_city\"], row[\"home_base_state\"]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1044,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83414 entries, 0 to 83413\n",
      "Data columns (total 31 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   dt                        83414 non-null  datetime64[ns]\n",
      " 1   weekday                   83414 non-null  object        \n",
      " 2   year                      83414 non-null  int64         \n",
      " 3   id_driver                 83414 non-null  int64         \n",
      " 4   id_carrier_number         83414 non-null  object        \n",
      " 5   dim_carrier_type          83414 non-null  object        \n",
      " 6   dim_carrier_company_name  83365 non-null  object        \n",
      " 7   home_base_city            83369 non-null  object        \n",
      " 8   home_base_state           83369 non-null  object        \n",
      " 9   carrier_trucks            83414 non-null  object        \n",
      " 10  num_trucks                83344 non-null  float64       \n",
      " 11  interested_in_drayage     83414 non-null  object        \n",
      " 12  port_qualified            83414 non-null  object        \n",
      " 13  signup_source             83414 non-null  object        \n",
      " 14  ts_signup                 83414 non-null  object        \n",
      " 15  ts_first_approved         71124 non-null  object        \n",
      " 16  days_signup_to_approval   71124 non-null  float64       \n",
      " 17  driver_with_twic          83414 non-null  object        \n",
      " 18  dim_preferred_lanes       3412 non-null   object        \n",
      " 19  first_load_date           83414 non-null  datetime64[ns]\n",
      " 20  most_recent_load_date     83414 non-null  datetime64[ns]\n",
      " 21  load_day                  83414 non-null  datetime64[ns]\n",
      " 22  loads                     83414 non-null  int64         \n",
      " 23  marketplace_loads_otr     83414 non-null  int64         \n",
      " 24  marketplace_loads_atlas   83414 non-null  int64         \n",
      " 25  marketplace_loads         83414 non-null  int64         \n",
      " 26  brokerage_loads_otr       83414 non-null  int64         \n",
      " 27  brokerage_loads_atlas     83414 non-null  int64         \n",
      " 28  brokerage_loads           83414 non-null  int64         \n",
      " 29  total_loads               83414 non-null  int64         \n",
      " 30  label                     83414 non-null  float64       \n",
      "dtypes: datetime64[ns](4), float64(3), int64(10), object(14)\n",
      "memory usage: 19.7+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1045,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby(\"id_driver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1046,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO: dt, weekday, year, id_carrier_number, dim_preferred_lanes, load_day, loads\n",
    "new_arr = []\n",
    "for key, group in groups:\n",
    "    group.sort_values(by=\"load_day\", ascending=False, inplace=True)\n",
    "    temp_arr = []\n",
    "    temp_arr.append(key)\n",
    "    \n",
    "    if group[\"dim_carrier_type\"].nunique() == 2:\n",
    "        temp_arr.append(\"Both\")\n",
    "    elif group[\"dim_carrier_type\"].nunique() == 0:\n",
    "        temp_arr.append(None)\n",
    "    else:\n",
    "        temp_arr.append((group[\"dim_carrier_type\"].iloc[0]))\n",
    "    \n",
    "    \n",
    "    idxmax_cols = [\"dim_carrier_company_name\", \n",
    "                   \"carrier_trucks\", \"signup_source\", \"ts_signup\", \"ts_first_approved\",\n",
    "                  \"days_signup_to_approval\"] #\"home_base_city\", \"home_base_state\",\n",
    "    \n",
    "    for col in idxmax_cols:\n",
    "        try:\n",
    "            temp_arr.append(group[col].value_counts().dropna(how=\"any\").idxmax())\n",
    "        except:\n",
    "            \n",
    "            temp_arr.append(None)\n",
    "    \n",
    "    try:\n",
    "        x = len(group[\"home_base_city\"].dropna(how=\"any\").iloc[0])\n",
    "        x = len(group[\"home_base_state\"].dropna(how=\"any\").iloc[0])\n",
    "        temp_arr.append(group[\"home_base_city\"].dropna(how=\"any\").iloc[0])\n",
    "        temp_arr.append(group[\"home_base_state\"].dropna(how=\"any\").iloc[0])\n",
    "    except:\n",
    "        index_num = random.randint(0, len(loc_arr)-1)\n",
    "        temp_arr.append(loc_arr[index_num][0])\n",
    "        temp_arr.append(loc_arr[index_num][1])\n",
    "        \n",
    "    \n",
    "    \n",
    "    try:\n",
    "        temp_arr.append(group[\"num_trucks\"].dropna(how=\"any\").mean())\n",
    "    except:\n",
    "        temp_arr.append(None)\n",
    "        \n",
    "    iloc_cols = [\"interested_in_drayage\", \"port_qualified\", \"driver_with_twic\", \n",
    "                 \"first_load_date\", \"most_recent_load_date\", \"marketplace_loads_otr\", \n",
    "                 \"marketplace_loads_atlas\", \"marketplace_loads\", \"brokerage_loads_otr\",\n",
    "                 \"brokerage_loads_atlas\", \"brokerage_loads\", \"total_loads\"]\n",
    "    for col in iloc_cols:\n",
    "        try:\n",
    "            temp_arr.append(group[col].dropna(how=\"any\").iloc[0])\n",
    "        except:\n",
    "            temp_arr.append(None)\n",
    "    \n",
    "    temp_arr.append(group.shape[0])\n",
    "    \n",
    "    temp_arr.append(((pd.to_datetime(date.today()) - group[\"most_recent_load_date\"].dropna(how=\"any\").iloc[0]).days) * (-1))\n",
    "    \n",
    "    temp_arr.append(group[\"label\"].value_counts().dropna(how=\"any\").idxmax())\n",
    "    \n",
    "    new_arr.append(np.array(temp_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1047,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"id_driver\", \"dim_carrier_type\", \"dim_carrier_company_name\", \n",
    "                \"carrier_trucks\", \"signup_source\", \"ts_signup\", \"ts_first_approved\",\n",
    "                \"days_signup_to_approval\", \"home_base_city\", \"home_base_state\", \"num_trucks\", \n",
    "                \"interested_in_drayage\", \"port_qualified\", \"driver_with_twic\", \n",
    "                \"first_load_date\", \"most_recent_load_date\", \"marketplace_loads_otr\", \n",
    "                \"marketplace_loads_atlas\", \"marketplace_loads\", \"brokerage_loads_otr\",\n",
    "                \"brokerage_loads_atlas\", \"brokerage_loads\", \"total_loads\", \"num_trips_made\", \n",
    "                \"days_since_last_load\", \"label\"]\n",
    "\n",
    "df = pd.DataFrame(np.array(new_arr), columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1048,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column_names:\n",
    "    try:\n",
    "        df[col] = df[col].convert_dtypes()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1049,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # NO: dt, weekday, year, id_carrier_number, dim_preferred_lanes, load_day, loads\n",
    "new_dict = {}\n",
    "label_dict = {}\n",
    "most_recent_date_arr = []\n",
    "num_trips_arr = []\n",
    "for key, group in groups:\n",
    "    group.sort_values(by=\"load_day\", ascending=False, inplace=True)\n",
    "    if key not in new_dict:\n",
    "        try:\n",
    "            new_dict[key] = (group[\"load_day\"].dropna(how=\"any\").iloc[0], group.shape[0])\n",
    "        except:\n",
    "            new_dict[key] = None\n",
    "        \n",
    "        try:\n",
    "            label_dict[key] = group[\"label\"].dropna(how=\"any\").iloc[0]\n",
    "        except:\n",
    "            label_dict[key] = 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1050,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5291 entries, 0 to 5290\n",
      "Data columns (total 26 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   id_driver                 5291 non-null   Int64         \n",
      " 1   dim_carrier_type          5291 non-null   string        \n",
      " 2   dim_carrier_company_name  5284 non-null   string        \n",
      " 3   carrier_trucks            5291 non-null   string        \n",
      " 4   signup_source             5291 non-null   string        \n",
      " 5   ts_signup                 5291 non-null   string        \n",
      " 6   ts_first_approved         3962 non-null   string        \n",
      " 7   days_signup_to_approval   3962 non-null   Int64         \n",
      " 8   home_base_city            5291 non-null   string        \n",
      " 9   home_base_state           5291 non-null   string        \n",
      " 10  num_trucks                5249 non-null   float64       \n",
      " 11  interested_in_drayage     5291 non-null   string        \n",
      " 12  port_qualified            5291 non-null   string        \n",
      " 13  driver_with_twic          5291 non-null   string        \n",
      " 14  first_load_date           5291 non-null   datetime64[ns]\n",
      " 15  most_recent_load_date     5291 non-null   datetime64[ns]\n",
      " 16  marketplace_loads_otr     5291 non-null   Int64         \n",
      " 17  marketplace_loads_atlas   5291 non-null   Int64         \n",
      " 18  marketplace_loads         5291 non-null   Int64         \n",
      " 19  brokerage_loads_otr       5291 non-null   Int64         \n",
      " 20  brokerage_loads_atlas     5291 non-null   Int64         \n",
      " 21  brokerage_loads           5291 non-null   Int64         \n",
      " 22  total_loads               5291 non-null   Int64         \n",
      " 23  num_trips_made            5291 non-null   Int64         \n",
      " 24  days_since_last_load      5291 non-null   Int64         \n",
      " 25  label                     5291 non-null   Int64         \n",
      "dtypes: Int64(12), datetime64[ns](2), float64(1), string(11)\n",
      "memory usage: 1.1 MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1051,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5291.000000\n",
       "mean        0.010395\n",
       "std         0.101434\n",
       "min         0.000000\n",
       "25%         0.000000\n",
       "50%         0.000000\n",
       "75%         0.000000\n",
       "max         1.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 1051,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1052,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_score.groupby(\"id_driver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1053,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not here:  13711\n",
      "Not here:  31557\n",
      "Not here:  16642\n",
      "Not here:  13761\n",
      "Not here:  8205\n",
      "Not here:  35572\n",
      "Not here:  7623\n",
      "Not here:  31873\n",
      "Not here:  12429\n",
      "Not here:  1288\n",
      "Not here:  29653\n",
      "Not here:  20357\n",
      "Not here:  15073\n",
      "Not here:  29070\n",
      "Not here:  10359\n",
      "Not here:  11514\n",
      "Not here:  35563\n",
      "Not here:  7594\n",
      "Not here:  26545\n"
     ]
    }
   ],
   "source": [
    "# # NO: dt, weekday, year, id_carrier_number, dim_preferred_lanes, load_day, loads\n",
    "new_dict = {}\n",
    "most_recent_date_arr = []\n",
    "num_trips_arr = []\n",
    "score_labels = []\n",
    "days_since_last_work_arr = []\n",
    "trips_dict = {}\n",
    "for key, group in groups:\n",
    "    group.sort_values(by=\"load_day\", ascending=False, inplace=True)\n",
    "    if key not in new_dict:\n",
    "        try:\n",
    "            new_dict[key] = (group[\"load_day\"].dropna(how=\"any\").iloc[0], group.shape[0])\n",
    "        except:\n",
    "            new_dict[key] = None\n",
    "    if key not in trips_dict:\n",
    "        trips_dict[key] = group.shape[0]\n",
    "\n",
    "for index, row in df_score.iterrows():\n",
    "    most_recent_date_arr.append(new_dict[row[\"id_driver\"]][0])\n",
    "    num_trips_arr.append(new_dict[row[\"id_driver\"]][1])\n",
    "    if row[\"id_driver\"] in label_dict:\n",
    "        score_labels.append(label_dict[row[\"id_driver\"]])\n",
    "    else:\n",
    "        print(\"Not here: \", row[\"id_driver\"])\n",
    "        rand_num = random.randint(0, 1000)\n",
    "        if rand_num <= 125:\n",
    "            score_labels.append(1)\n",
    "            label_dict[row[\"id_driver\"]] = 1\n",
    "        else:\n",
    "            score_labels.append(0)\n",
    "            label_dict[row[\"id_driver\"]] = 0\n",
    "            \n",
    "    try:\n",
    "        x = len(row[\"home_base_city\"])\n",
    "        x = len(row[\"home_base_state\"])\n",
    "    except:\n",
    "        index_num = random.randint(0, len(loc_arr)-1)\n",
    "        df_score.at[index, \"home_base_city\"] = loc_arr[index_num][0]\n",
    "        df_score.at[index, \"home_base_state\"] = loc_arr[index_num][1]\n",
    "        \n",
    "    days_since_last_work_arr.append(((pd.to_datetime(date.today()) - row[\"load_day\"]).days) * (-1))\n",
    "\n",
    "score_labels = np.array(score_labels)\n",
    "df_score[\"most_recent_load_date\"] = np.array(most_recent_date_arr)\n",
    "df_score[\"num_trips_made\"] = np.array(num_trips_arr)\n",
    "df_score[\"days_since_last_load\"] = np.array(days_since_last_work_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1054,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   id_driver                 1000 non-null   int64         \n",
      " 1   dim_carrier_type          1000 non-null   object        \n",
      " 2   dim_carrier_company_name  1000 non-null   object        \n",
      " 3   home_base_city            1000 non-null   object        \n",
      " 4   home_base_state           1000 non-null   object        \n",
      " 5   carrier_trucks            1000 non-null   object        \n",
      " 6   num_trucks                1000 non-null   float64       \n",
      " 7   interested_in_drayage     1000 non-null   object        \n",
      " 8   port_qualified            1000 non-null   object        \n",
      " 9   signup_source             1000 non-null   object        \n",
      " 10  ts_signup                 1000 non-null   object        \n",
      " 11  ts_first_approved         854 non-null    object        \n",
      " 12  days_signup_to_approval   854 non-null    float64       \n",
      " 13  driver_with_twic          1000 non-null   object        \n",
      " 14  first_load_date           1000 non-null   datetime64[ns]\n",
      " 15  marketplace_loads_otr     1000 non-null   int64         \n",
      " 16  marketplace_loads_atlas   1000 non-null   int64         \n",
      " 17  marketplace_loads         1000 non-null   int64         \n",
      " 18  brokerage_loads_otr       1000 non-null   int64         \n",
      " 19  brokerage_loads_atlas     1000 non-null   int64         \n",
      " 20  brokerage_loads           1000 non-null   int64         \n",
      " 21  most_recent_load_date     1000 non-null   datetime64[ns]\n",
      " 22  num_trips_made            1000 non-null   int64         \n",
      " 23  days_since_last_load      1000 non-null   int64         \n",
      "dtypes: datetime64[ns](2), float64(2), int64(9), object(11)\n",
      "memory usage: 187.6+ KB\n"
     ]
    }
   ],
   "source": [
    "column_names = [\"id_driver\", \"dim_carrier_type\", \"dim_carrier_company_name\", \n",
    "                \"carrier_trucks\", \"signup_source\", \"ts_signup\", \"ts_first_approved\",\n",
    "                \"days_signup_to_approval\", \"home_base_city\", \"home_base_state\", \"num_trucks\", \n",
    "                \"interested_in_drayage\", \"port_qualified\", \"driver_with_twic\", \n",
    "                \"first_load_date\", \"most_recent_load_date\", \"marketplace_loads_otr\", \n",
    "                \"marketplace_loads_atlas\", \"marketplace_loads\", \"brokerage_loads_otr\",\n",
    "                \"brokerage_loads_atlas\", \"brokerage_loads\", \"num_trips_made\", \n",
    "                \"days_since_last_load\"]\n",
    "\n",
    "df_temp = df_score.drop(columns = column_names)\n",
    "to_drop = list(df_temp.columns.values)\n",
    "df_score = df_score.drop(columns=to_drop)\n",
    "df_score.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1055,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in column_names:\n",
    "    try:\n",
    "        df_score[col] = df_score[col].convert_dtypes()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1056,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0      4\n",
       "1      1\n",
       "2      1\n",
       "3      3\n",
       "4      1\n",
       "      ..\n",
       "995    1\n",
       "996    3\n",
       "997    1\n",
       "998    1\n",
       "999    1\n",
       "Name: num_trips_made, Length: 1000, dtype: Int64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_score[\"num_trips_made\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1057,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   id_driver                 1000 non-null   Int64         \n",
      " 1   dim_carrier_type          1000 non-null   string        \n",
      " 2   dim_carrier_company_name  1000 non-null   string        \n",
      " 3   home_base_city            1000 non-null   string        \n",
      " 4   home_base_state           1000 non-null   string        \n",
      " 5   carrier_trucks            1000 non-null   string        \n",
      " 6   num_trucks                1000 non-null   Int64         \n",
      " 7   interested_in_drayage     1000 non-null   string        \n",
      " 8   port_qualified            1000 non-null   string        \n",
      " 9   signup_source             1000 non-null   string        \n",
      " 10  ts_signup                 1000 non-null   string        \n",
      " 11  ts_first_approved         854 non-null    string        \n",
      " 12  days_signup_to_approval   854 non-null    Int64         \n",
      " 13  driver_with_twic          1000 non-null   string        \n",
      " 14  first_load_date           1000 non-null   datetime64[ns]\n",
      " 15  marketplace_loads_otr     1000 non-null   Int64         \n",
      " 16  marketplace_loads_atlas   1000 non-null   Int64         \n",
      " 17  marketplace_loads         1000 non-null   Int64         \n",
      " 18  brokerage_loads_otr       1000 non-null   Int64         \n",
      " 19  brokerage_loads_atlas     1000 non-null   Int64         \n",
      " 20  brokerage_loads           1000 non-null   Int64         \n",
      " 21  most_recent_load_date     1000 non-null   datetime64[ns]\n",
      " 22  num_trips_made            1000 non-null   Int64         \n",
      " 23  days_since_last_load      1000 non-null   Int64         \n",
      "dtypes: Int64(11), datetime64[ns](2), string(11)\n",
      "memory usage: 198.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_score.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1058,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"dt\", \"weekday\", \"year\", \"id_carrier_number\", \"dim_preferred_lanes\", \"load_day\", \"loads\"]\n",
    "for col in drop_cols:\n",
    "    try:\n",
    "        df_score = df_score.drop(columns=[col])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "for col in drop_cols:\n",
    "    try:\n",
    "        df = df.drop(columns=[col])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1059,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 24 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   id_driver                 1000 non-null   Int64         \n",
      " 1   dim_carrier_type          1000 non-null   string        \n",
      " 2   dim_carrier_company_name  1000 non-null   string        \n",
      " 3   home_base_city            1000 non-null   string        \n",
      " 4   home_base_state           1000 non-null   string        \n",
      " 5   carrier_trucks            1000 non-null   string        \n",
      " 6   num_trucks                1000 non-null   Int64         \n",
      " 7   interested_in_drayage     1000 non-null   string        \n",
      " 8   port_qualified            1000 non-null   string        \n",
      " 9   signup_source             1000 non-null   string        \n",
      " 10  ts_signup                 1000 non-null   string        \n",
      " 11  ts_first_approved         854 non-null    string        \n",
      " 12  days_signup_to_approval   854 non-null    Int64         \n",
      " 13  driver_with_twic          1000 non-null   string        \n",
      " 14  first_load_date           1000 non-null   datetime64[ns]\n",
      " 15  marketplace_loads_otr     1000 non-null   Int64         \n",
      " 16  marketplace_loads_atlas   1000 non-null   Int64         \n",
      " 17  marketplace_loads         1000 non-null   Int64         \n",
      " 18  brokerage_loads_otr       1000 non-null   Int64         \n",
      " 19  brokerage_loads_atlas     1000 non-null   Int64         \n",
      " 20  brokerage_loads           1000 non-null   Int64         \n",
      " 21  most_recent_load_date     1000 non-null   datetime64[ns]\n",
      " 22  num_trips_made            1000 non-null   Int64         \n",
      " 23  days_since_last_load      1000 non-null   Int64         \n",
      "dtypes: Int64(11), datetime64[ns](2), string(11)\n",
      "memory usage: 198.4 KB\n"
     ]
    }
   ],
   "source": [
    "df_score.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1060,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_driver\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_driver                  1.000000\n",
       "days_since_last_load       0.839446\n",
       "num_trucks                 0.169567\n",
       "brokerage_loads_atlas      0.145307\n",
       "marketplace_loads_atlas    0.138116\n",
       "marketplace_loads          0.123344\n",
       "label                      0.075683\n",
       "total_loads                0.052722\n",
       "num_trips_made             0.018007\n",
       "marketplace_loads_otr     -0.012441\n",
       "brokerage_loads           -0.037352\n",
       "brokerage_loads_otr       -0.063795\n",
       "days_signup_to_approval   -0.734778\n",
       "Name: id_driver, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "dim_carrier_type\n",
      "dim_carrier_type is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "dim_carrier_company_name\n",
      "dim_carrier_company_name is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "carrier_trucks\n",
      "carrier_trucks is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "signup_source\n",
      "signup_source is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "ts_signup\n",
      "ts_signup is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "ts_first_approved\n",
      "ts_first_approved is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "days_signup_to_approval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "days_signup_to_approval    1.000000\n",
       "brokerage_loads_otr        0.048116\n",
       "brokerage_loads            0.027929\n",
       "num_trips_made             0.010462\n",
       "marketplace_loads_otr      0.007436\n",
       "total_loads               -0.043765\n",
       "num_trucks                -0.053498\n",
       "label                     -0.064084\n",
       "marketplace_loads         -0.089268\n",
       "brokerage_loads_atlas     -0.092088\n",
       "marketplace_loads_atlas   -0.099058\n",
       "days_since_last_load      -0.628732\n",
       "id_driver                 -0.734778\n",
       "Name: days_signup_to_approval, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "home_base_city\n",
      "home_base_city is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "home_base_state\n",
      "home_base_state is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "num_trucks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "num_trucks                 1.000000\n",
       "id_driver                  0.169567\n",
       "days_since_last_load       0.163449\n",
       "num_trips_made             0.059784\n",
       "total_loads                0.017664\n",
       "brokerage_loads_otr        0.001285\n",
       "brokerage_loads           -0.006155\n",
       "label                     -0.035292\n",
       "brokerage_loads_atlas     -0.042167\n",
       "marketplace_loads_atlas   -0.050920\n",
       "days_signup_to_approval   -0.053498\n",
       "marketplace_loads_otr     -0.058752\n",
       "marketplace_loads         -0.065660\n",
       "Name: num_trucks, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "interested_in_drayage\n",
      "interested_in_drayage is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "port_qualified\n",
      "port_qualified is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "driver_with_twic\n",
      "driver_with_twic is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "first_load_date\n",
      "first_load_date is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "most_recent_load_date\n",
      "most_recent_load_date is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "marketplace_loads_otr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "marketplace_loads_otr      1.000000\n",
       "num_trips_made             0.511867\n",
       "marketplace_loads          0.395290\n",
       "total_loads                0.268972\n",
       "label                      0.163324\n",
       "days_since_last_load       0.157085\n",
       "marketplace_loads_atlas    0.083147\n",
       "brokerage_loads_otr        0.080873\n",
       "brokerage_loads            0.080687\n",
       "days_signup_to_approval    0.007436\n",
       "brokerage_loads_atlas      0.005160\n",
       "id_driver                 -0.012441\n",
       "num_trucks                -0.058752\n",
       "Name: marketplace_loads_otr, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "marketplace_loads_atlas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "marketplace_loads_atlas    1.000000\n",
       "marketplace_loads          0.948243\n",
       "label                      0.577596\n",
       "total_loads                0.541759\n",
       "num_trips_made             0.445315\n",
       "brokerage_loads_atlas      0.410271\n",
       "days_since_last_load       0.202243\n",
       "id_driver                  0.138116\n",
       "marketplace_loads_otr      0.083147\n",
       "brokerage_loads            0.059796\n",
       "brokerage_loads_otr       -0.012599\n",
       "num_trucks                -0.050920\n",
       "days_signup_to_approval   -0.099058\n",
       "Name: marketplace_loads_atlas, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "marketplace_loads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "marketplace_loads          1.000000\n",
       "marketplace_loads_atlas    0.948243\n",
       "total_loads                0.585073\n",
       "label                      0.584442\n",
       "num_trips_made             0.573574\n",
       "marketplace_loads_otr      0.395290\n",
       "brokerage_loads_atlas      0.379811\n",
       "days_since_last_load       0.236472\n",
       "id_driver                  0.123344\n",
       "brokerage_loads            0.080827\n",
       "brokerage_loads_otr        0.014158\n",
       "num_trucks                -0.065660\n",
       "days_signup_to_approval   -0.089268\n",
       "Name: marketplace_loads, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "brokerage_loads_otr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "brokerage_loads_otr        1.000000\n",
       "brokerage_loads            0.984385\n",
       "total_loads                0.803391\n",
       "num_trips_made             0.572785\n",
       "label                      0.239032\n",
       "marketplace_loads_otr      0.080873\n",
       "days_since_last_load       0.061265\n",
       "days_signup_to_approval    0.048116\n",
       "marketplace_loads          0.014158\n",
       "num_trucks                 0.001285\n",
       "brokerage_loads_atlas     -0.011804\n",
       "marketplace_loads_atlas   -0.012599\n",
       "id_driver                 -0.063795\n",
       "Name: brokerage_loads_otr, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "brokerage_loads_atlas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "brokerage_loads_atlas      1.000000\n",
       "marketplace_loads_atlas    0.410271\n",
       "marketplace_loads          0.379811\n",
       "total_loads                0.329874\n",
       "label                      0.327819\n",
       "num_trips_made             0.257713\n",
       "days_since_last_load       0.179735\n",
       "brokerage_loads            0.164395\n",
       "id_driver                  0.145307\n",
       "marketplace_loads_otr      0.005160\n",
       "brokerage_loads_otr       -0.011804\n",
       "num_trucks                -0.042167\n",
       "days_signup_to_approval   -0.092088\n",
       "Name: brokerage_loads_atlas, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "brokerage_loads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "brokerage_loads            1.000000\n",
       "brokerage_loads_otr        0.984385\n",
       "total_loads                0.850586\n",
       "num_trips_made             0.610399\n",
       "label                      0.293505\n",
       "brokerage_loads_atlas      0.164395\n",
       "days_since_last_load       0.092076\n",
       "marketplace_loads          0.080827\n",
       "marketplace_loads_otr      0.080687\n",
       "marketplace_loads_atlas    0.059796\n",
       "days_signup_to_approval    0.027929\n",
       "num_trucks                -0.006155\n",
       "id_driver                 -0.037352\n",
       "Name: brokerage_loads, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "total_loads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "total_loads                1.000000\n",
       "brokerage_loads            0.850586\n",
       "brokerage_loads_otr        0.803391\n",
       "num_trips_made             0.802860\n",
       "marketplace_loads          0.585073\n",
       "label                      0.541811\n",
       "marketplace_loads_atlas    0.541759\n",
       "brokerage_loads_atlas      0.329874\n",
       "marketplace_loads_otr      0.268972\n",
       "days_since_last_load       0.216076\n",
       "id_driver                  0.052722\n",
       "num_trucks                 0.017664\n",
       "days_signup_to_approval   -0.043765\n",
       "Name: total_loads, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "num_trips_made\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "num_trips_made             1.000000\n",
       "total_loads                0.802860\n",
       "brokerage_loads            0.610399\n",
       "marketplace_loads          0.573574\n",
       "brokerage_loads_otr        0.572785\n",
       "marketplace_loads_otr      0.511867\n",
       "label                      0.481593\n",
       "marketplace_loads_atlas    0.445315\n",
       "days_since_last_load       0.284921\n",
       "brokerage_loads_atlas      0.257713\n",
       "num_trucks                 0.059784\n",
       "id_driver                  0.018007\n",
       "days_signup_to_approval    0.010462\n",
       "Name: num_trips_made, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "days_since_last_load\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "days_since_last_load       1.000000\n",
       "id_driver                  0.839446\n",
       "num_trips_made             0.284921\n",
       "marketplace_loads          0.236472\n",
       "total_loads                0.216076\n",
       "marketplace_loads_atlas    0.202243\n",
       "brokerage_loads_atlas      0.179735\n",
       "num_trucks                 0.163449\n",
       "marketplace_loads_otr      0.157085\n",
       "label                      0.142288\n",
       "brokerage_loads            0.092076\n",
       "brokerage_loads_otr        0.061265\n",
       "days_signup_to_approval   -0.628732\n",
       "Name: days_since_last_load, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label                      1.000000\n",
       "marketplace_loads          0.584442\n",
       "marketplace_loads_atlas    0.577596\n",
       "total_loads                0.541811\n",
       "num_trips_made             0.481593\n",
       "brokerage_loads_atlas      0.327819\n",
       "brokerage_loads            0.293505\n",
       "brokerage_loads_otr        0.239032\n",
       "marketplace_loads_otr      0.163324\n",
       "days_since_last_load       0.142288\n",
       "id_driver                  0.075683\n",
       "num_trucks                -0.035292\n",
       "days_signup_to_approval   -0.064084\n",
       "Name: label, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = df.corr()\n",
    "for col_name in (list(df.columns.values)): # prints all the correlation matrices corresponding to each feature\n",
    "    try:\n",
    "        print(col_name)\n",
    "        display(corr_matrix[col_name].sort_values(ascending=False))\n",
    "        print('---------------------------------------------------------------------')\n",
    "    except:\n",
    "        print(\"{} is not of type integer\".format(col_name))\n",
    "        print('---------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Also year and TODO_FIND_COLUMN_NAME_2 and year are highly correlated and have a similar impact on label, so we could drop one? \n",
    "\n",
    "Is there really a need for brokerage_loads when it is so highly correlated to brokerage_loads_otr due to the vast majority of shipments being delivered over-the-road as compared to via ATLAS? \n",
    "\n",
    "I have the same question about total_loads due to the vast majority of loads being brokerage loads...\n",
    "\n",
    "What's the point of having both year and date?\n",
    "\n",
    "We can remove the id_carrier_number column from this dataset as it is not relevant to predicting a label of 0 or 1 (When trying to find high performing drivers, we need to know their carrier number, so we can extract the id_carrier_number column for now...)\n",
    "\n",
    "We could one-hot-encode sign-up source and see its effect on labels.\n",
    "\n",
    "We can remove the ts_first_approved column because the date of approval shouldn't matter that much but instead the days_signup_to_approval matter.\n",
    "\n",
    "dim_preferred_lanes only has a few values so we can either remove the column or impute values.\n",
    "\n",
    "Also first_load_date, most_recent_load_date and load_day shouldn't matter much. Instead we can have values such as: number of days doing the job = most_recent_load_date - first_load_date\n",
    "AND\n",
    "days_from_last_load_to_today = todays_date - most_recent_load_date\n",
    "\n",
    "There are also a couple other features we need to impute.\n",
    "\n",
    "Also, only people that are port qualified can provide drayage services, so we should create a field called qualified_and_interest_in_drayage which is only 1 (yes) when interested_in_drayage = \"yes\" and port_qualified = \"yes\". We can also cross these features..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Feature Extraction Plan and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1061,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       100000\n",
       "1       100000\n",
       "2       100000\n",
       "3       100000\n",
       "4       100000\n",
       "         ...  \n",
       "5286    100000\n",
       "5287    000001\n",
       "5288    000001\n",
       "5289    000001\n",
       "5290    000001\n",
       "Name: drayage_interested_port_qualified, Length: 5291, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      100000\n",
       "1      000010\n",
       "2      100000\n",
       "3      000010\n",
       "4      000010\n",
       "        ...  \n",
       "995    100000\n",
       "996    100000\n",
       "997    100000\n",
       "998    100000\n",
       "999    000010\n",
       "Name: drayage_interested_port_qualified, Length: 1000, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def drayage_feature_cross(df):\n",
    "    loc_cross = list(zip(df[\"home_base_city\"], df[\"home_base_state\"]))# feature cross to get (city, state) tuple\n",
    "    # feature cross for interested in drayage and port qualified\n",
    "    drayage_cross = list(zip(df[\"interested_in_drayage\"], df[\"port_qualified\"]))\n",
    "\n",
    "    drayage_arr = []\n",
    "    for list_item in drayage_cross:\n",
    "        if list_item[0] == \"yes\" and list_item[1] == \"yes\":\n",
    "            drayage_arr.append(\"000001\")\n",
    "        if list_item[0] == \"yes\" and list_item[1] == \"no\":\n",
    "            drayage_arr.append(\"000010\")\n",
    "        if list_item[0] == \"no\" and list_item[1] == \"yes\":\n",
    "            drayage_arr.append(\"000100\")\n",
    "        if list_item[0] == \"no\" and list_item[1] == \"no\":\n",
    "            drayage_arr.append(\"001000\")\n",
    "        if list_item[0] == \"not specified\" and list_item[1] == \"yes\":\n",
    "            drayage_arr.append(\"010000\")\n",
    "        if list_item[0] == \"not specified\" and list_item[1] == \"no\":\n",
    "            drayage_arr.append(\"100000\")\n",
    "\n",
    "    df[\"drayage_interested_port_qualified\"] = np.array(drayage_arr)\n",
    "    display(df[\"drayage_interested_port_qualified\"])\n",
    "\n",
    "drayage_feature_cross(df)\n",
    "drayage_feature_cross(df_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1062,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_driver_number_col = np.array(df[\"id_driver\"]) # extract id_driver column\n",
    "id_driver_number_col_score = np.array(df_score[\"id_driver\"]) # extract id_driver column\n",
    "\n",
    "drop_cols = [\"id_driver\", \"interested_in_drayage\", \"port_qualified\", \n",
    "             \"ts_signup\", \"ts_first_approved\"] #\"home_base_city\",\"home_base_state\",\n",
    "for col in drop_cols:\n",
    "    try:\n",
    "        df_score = df_score.drop(columns=[col])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "for col in drop_cols:\n",
    "    try:\n",
    "        df = df.drop(columns=[col])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1063,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5291 entries, 0 to 5290\n",
      "Data columns (total 22 columns):\n",
      " #   Column                             Non-Null Count  Dtype         \n",
      "---  ------                             --------------  -----         \n",
      " 0   dim_carrier_type                   5291 non-null   string        \n",
      " 1   dim_carrier_company_name           5284 non-null   string        \n",
      " 2   carrier_trucks                     5291 non-null   string        \n",
      " 3   signup_source                      5291 non-null   string        \n",
      " 4   days_signup_to_approval            3962 non-null   Int64         \n",
      " 5   home_base_city                     5291 non-null   string        \n",
      " 6   home_base_state                    5291 non-null   string        \n",
      " 7   num_trucks                         5249 non-null   float64       \n",
      " 8   driver_with_twic                   5291 non-null   string        \n",
      " 9   first_load_date                    5291 non-null   datetime64[ns]\n",
      " 10  most_recent_load_date              5291 non-null   datetime64[ns]\n",
      " 11  marketplace_loads_otr              5291 non-null   Int64         \n",
      " 12  marketplace_loads_atlas            5291 non-null   Int64         \n",
      " 13  marketplace_loads                  5291 non-null   Int64         \n",
      " 14  brokerage_loads_otr                5291 non-null   Int64         \n",
      " 15  brokerage_loads_atlas              5291 non-null   Int64         \n",
      " 16  brokerage_loads                    5291 non-null   Int64         \n",
      " 17  total_loads                        5291 non-null   Int64         \n",
      " 18  num_trips_made                     5291 non-null   Int64         \n",
      " 19  days_since_last_load               5291 non-null   Int64         \n",
      " 20  label                              5291 non-null   Int64         \n",
      " 21  drayage_interested_port_qualified  5291 non-null   object        \n",
      "dtypes: Int64(11), datetime64[ns](2), float64(1), object(1), string(7)\n",
      "memory usage: 966.4+ KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1064,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {}\n",
    "for index, row in df.iterrows():\n",
    "    names[row[\"dim_carrier_company_name\"]] = int(names.get(row[\"dim_carrier_company_name\"], 0) + 1)\n",
    "listo = list(names.items())\n",
    "listo.sort(reverse=True, key=lambda x: int(x[1]))\n",
    "#listo[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1065,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 50:  1290\n",
      "Percentage 50:  0.5176565008025682\n",
      "['NFS asset Drayage', 'MC Express Trucking LLC', 'Roadrunner Transportation', 'Dong Fang Marketing Inc', 'ROADMOND LOGISTICS INC.', 'Consistent Trucking Inc', 'BLUE FREIGHT TRANSPORT INC', 'Convoy Express', 'Mega Fleet', 'iDC Drayage', 'Cross World Logistics', 'USA Diamonds Trucking', 'pointdirect', 'Chaidez Trucking', 'Saia LTL Freight', 'American Better Choice Corporation', 'American Freightways Lp.', 'Fastrucking', 'MERIDIAN LOGISTICS INC', 'Carlos Flores', 'J&G Transportation Group Inc', 'KLF transport inc', 'Star Rain LLC', 'Starco Logistics Inc.', '664 Transport', 'FTS EXPRESS INC', 'IDC OTR', \"Luna's Transportation group\", 'AGRAMONT TRANSPORT INC', 'BGood VirtueT Inc', 'Geber Freight', 'R&Y Castellanos Trucking Inc.', 'JC Transport', 'Great Qin Transportation LLC', 'JM Express Inc', 'MT Brothers Groups', 'cbt trucking', 'Road Eagle Logistics Corp', 'O.A. EXPRESS INC', 'AMPAK Logistics INC.', 'Kuang Trucking Inc.', 'nolan transportation group', '360 new way inc', 'Innovative Transportation, LLC', 'freight advisor corp', 'one USA group', 'Blue Horizon', 'STS TRUCKING', 'AL JR TRUCKING', 'MG Trucking']\n"
     ]
    }
   ],
   "source": [
    "listo = listo[:50]\n",
    "count_50 = sum([x[1] for x in listo])\n",
    "print(\"# 50: \", count_50)\n",
    "print(\"Percentage 50: \", count_50/len(names))\n",
    "\n",
    "names_arr = [tuples[0] for tuples in listo]\n",
    "print(names_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1066,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize(df):\n",
    "    days_worked = []\n",
    "    for index, row in df.iterrows(): # bucketize the most frequent dim_carrier_company names, \n",
    "                                     # put less frequent names in a single bucket\n",
    "        try:\n",
    "            if row[\"dim_carrier_company_name\"] not in names_arr:\n",
    "                df.at[index, \"dim_carrier_company_name\"] = \"Other\"\n",
    "        except:\n",
    "            df.at[index, \"dim_carrier_company_name\"] = \"Other\"\n",
    "\n",
    "        # find number of days driver has worked\n",
    "        if row[\"most_recent_load_date\"] != np.nan and row[\"first_load_date\"] != np.nan:\n",
    "            days_worked.append((row[\"most_recent_load_date\"] - row[\"first_load_date\"]).days)\n",
    "        else:\n",
    "            days_worked.append(None)\n",
    "    df[\"days_tenured\"] = np.array(days_worked)\n",
    "\n",
    "bucketize(df)\n",
    "bucketize(df_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1067,
   "metadata": {},
   "outputs": [],
   "source": [
    "drop_cols = [\"most_recent_load_date\", \"first_load_date\", \"weekday\", \"load_day\", \"total_loads\"]\n",
    "for col in drop_cols:\n",
    "    try:\n",
    "        df_score = df_score.drop(columns=[col])\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "for col in drop_cols:\n",
    "    try:\n",
    "        df = df.drop(columns=[col])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1068,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled = df.drop(columns=[\"label\"])\n",
    "labels = df[\"label\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1069,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique Values :  [0 1]\n",
      "Occurrence Count :  [5236   55]\n"
     ]
    }
   ],
   "source": [
    "uniqueValues, occurCount = np.unique(labels, return_counts=True)\n",
    "print(\"Unique Values : \" , uniqueValues)\n",
    "print(\"Occurrence Count : \", occurCount)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1070,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5291 entries, 0 to 5290\n",
      "Data columns (total 19 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   dim_carrier_type                   5291 non-null   string \n",
      " 1   dim_carrier_company_name           5291 non-null   string \n",
      " 2   carrier_trucks                     5291 non-null   string \n",
      " 3   signup_source                      5291 non-null   string \n",
      " 4   days_signup_to_approval            3962 non-null   Int64  \n",
      " 5   home_base_city                     5291 non-null   string \n",
      " 6   home_base_state                    5291 non-null   string \n",
      " 7   num_trucks                         5249 non-null   float64\n",
      " 8   driver_with_twic                   5291 non-null   string \n",
      " 9   marketplace_loads_otr              5291 non-null   Int64  \n",
      " 10  marketplace_loads_atlas            5291 non-null   Int64  \n",
      " 11  marketplace_loads                  5291 non-null   Int64  \n",
      " 12  brokerage_loads_otr                5291 non-null   Int64  \n",
      " 13  brokerage_loads_atlas              5291 non-null   Int64  \n",
      " 14  brokerage_loads                    5291 non-null   Int64  \n",
      " 15  num_trips_made                     5291 non-null   Int64  \n",
      " 16  days_since_last_load               5291 non-null   Int64  \n",
      " 17  drayage_interested_port_qualified  5291 non-null   object \n",
      " 18  days_tenured                       5291 non-null   int64  \n",
      "dtypes: Int64(9), float64(1), int64(1), object(1), string(7)\n",
      "memory usage: 832.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_unlabeled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1071,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1000 entries, 0 to 999\n",
      "Data columns (total 19 columns):\n",
      " #   Column                             Non-Null Count  Dtype \n",
      "---  ------                             --------------  ----- \n",
      " 0   dim_carrier_type                   1000 non-null   string\n",
      " 1   dim_carrier_company_name           1000 non-null   string\n",
      " 2   home_base_city                     1000 non-null   string\n",
      " 3   home_base_state                    1000 non-null   string\n",
      " 4   carrier_trucks                     1000 non-null   string\n",
      " 5   num_trucks                         1000 non-null   Int64 \n",
      " 6   signup_source                      1000 non-null   string\n",
      " 7   days_signup_to_approval            854 non-null    Int64 \n",
      " 8   driver_with_twic                   1000 non-null   string\n",
      " 9   marketplace_loads_otr              1000 non-null   Int64 \n",
      " 10  marketplace_loads_atlas            1000 non-null   Int64 \n",
      " 11  marketplace_loads                  1000 non-null   Int64 \n",
      " 12  brokerage_loads_otr                1000 non-null   Int64 \n",
      " 13  brokerage_loads_atlas              1000 non-null   Int64 \n",
      " 14  brokerage_loads                    1000 non-null   Int64 \n",
      " 15  num_trips_made                     1000 non-null   Int64 \n",
      " 16  days_since_last_load               1000 non-null   Int64 \n",
      " 17  drayage_interested_port_qualified  1000 non-null   object\n",
      " 18  days_tenured                       1000 non-null   int64 \n",
      "dtypes: Int64(10), int64(1), object(1), string(7)\n",
      "memory usage: 158.3+ KB\n"
     ]
    }
   ],
   "source": [
    "df_score.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1072,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['dim_carrier_type', 'dim_carrier_company_name', 'carrier_trucks', 'signup_source', 'days_signup_to_approval', 'home_base_city', 'home_base_state', 'num_trucks', 'driver_with_twic', 'marketplace_loads_otr', 'marketplace_loads_atlas', 'marketplace_loads', 'brokerage_loads_otr', 'brokerage_loads_atlas', 'brokerage_loads', 'num_trips_made', 'days_since_last_load', 'drayage_interested_port_qualified', 'days_tenured']\n"
     ]
    }
   ],
   "source": [
    "cols = list(df_unlabeled.columns.values)\n",
    "print(cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1073,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_score = df_score[cols]\n",
    "\n",
    "df_score['num_trucks'] = pd.to_numeric(df_score['num_trucks'], errors='coerce')\n",
    "df_score['days_signup_to_approval'] = pd.to_numeric(df_score['days_signup_to_approval'], errors='coerce')\n",
    "\n",
    "df_unlabeled['num_trucks'] = pd.to_numeric(df_unlabeled['num_trucks'], errors='coerce')\n",
    "df_unlabeled['days_signup_to_approval'] = pd.to_numeric(df_unlabeled['days_signup_to_approval'], errors='coerce')\n",
    "\n",
    "convert = [\"id_driver\", \"days_signup_to_approval\", \"marketplace_loads_otr\", \n",
    "               \"marketplace_loads_atlas\", \"marketplace_loads\", \"brokerage_loads_otr\",\n",
    "               \"brokerage_loads_atlas\", \"brokerage_loads\", \"num_trips_made\",\n",
    "               \"num_trucks\", \"dim_carrier_type\", \"dim_carrier_company_name\",\n",
    "               \"interested_in_drayage\", \"port_qualified\", \"signup_source\", \"driver_with_twic\",\n",
    "          \"home_base_city\",\"home_base_state\"] #\"home_base_city\",\"home_base_state\"\n",
    "for col in convert:\n",
    "    try:\n",
    "        df_score[col] = df_score[col].convert_dtypes()\n",
    "    except:\n",
    "        continue\n",
    "\n",
    "for col in convert:\n",
    "    try:\n",
    "        df_unlabeled[col] = df_unlabeled[col].convert_dtypes()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1074,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6291 entries, 0 to 6290\n",
      "Data columns (total 19 columns):\n",
      " #   Column                             Non-Null Count  Dtype \n",
      "---  ------                             --------------  ----- \n",
      " 0   dim_carrier_type                   6291 non-null   string\n",
      " 1   dim_carrier_company_name           6291 non-null   string\n",
      " 2   carrier_trucks                     6291 non-null   string\n",
      " 3   signup_source                      6291 non-null   string\n",
      " 4   days_signup_to_approval            4816 non-null   Int64 \n",
      " 5   home_base_city                     6291 non-null   string\n",
      " 6   home_base_state                    6291 non-null   string\n",
      " 7   num_trucks                         6249 non-null   object\n",
      " 8   driver_with_twic                   6291 non-null   string\n",
      " 9   marketplace_loads_otr              6291 non-null   Int64 \n",
      " 10  marketplace_loads_atlas            6291 non-null   Int64 \n",
      " 11  marketplace_loads                  6291 non-null   Int64 \n",
      " 12  brokerage_loads_otr                6291 non-null   Int64 \n",
      " 13  brokerage_loads_atlas              6291 non-null   Int64 \n",
      " 14  brokerage_loads                    6291 non-null   Int64 \n",
      " 15  num_trips_made                     6291 non-null   Int64 \n",
      " 16  days_since_last_load               6291 non-null   Int64 \n",
      " 17  drayage_interested_port_qualified  6291 non-null   object\n",
      " 18  days_tenured                       6291 non-null   int64 \n",
      "dtypes: Int64(9), int64(1), object(2), string(7)\n",
      "memory usage: 989.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_concat = pd.concat([df_unlabeled, df_score], ignore_index=True)\n",
    "df_concat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1075,
   "metadata": {},
   "outputs": [],
   "source": [
    "for col in convert:\n",
    "    try:\n",
    "        df_concat[col] = df_concat[col].convert_dtypes()\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1076,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 6291 entries, 0 to 6290\n",
      "Data columns (total 19 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   dim_carrier_type                   6291 non-null   string \n",
      " 1   dim_carrier_company_name           6291 non-null   string \n",
      " 2   carrier_trucks                     6291 non-null   string \n",
      " 3   signup_source                      6291 non-null   string \n",
      " 4   days_signup_to_approval            4816 non-null   Int64  \n",
      " 5   home_base_city                     6291 non-null   string \n",
      " 6   home_base_state                    6291 non-null   string \n",
      " 7   num_trucks                         6249 non-null   float64\n",
      " 8   driver_with_twic                   6291 non-null   string \n",
      " 9   marketplace_loads_otr              6291 non-null   Int64  \n",
      " 10  marketplace_loads_atlas            6291 non-null   Int64  \n",
      " 11  marketplace_loads                  6291 non-null   Int64  \n",
      " 12  brokerage_loads_otr                6291 non-null   Int64  \n",
      " 13  brokerage_loads_atlas              6291 non-null   Int64  \n",
      " 14  brokerage_loads                    6291 non-null   Int64  \n",
      " 15  num_trips_made                     6291 non-null   Int64  \n",
      " 16  days_since_last_load               6291 non-null   Int64  \n",
      " 17  drayage_interested_port_qualified  6291 non-null   object \n",
      " 18  days_tenured                       6291 non-null   int64  \n",
      "dtypes: Int64(9), float64(1), int64(1), object(1), string(7)\n",
      "memory usage: 989.2+ KB\n"
     ]
    }
   ],
   "source": [
    "df_concat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1077,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer()\n",
    "categorical_features_one_hot = [\"dim_carrier_type\", \"dim_carrier_company_name\", \"carrier_trucks\", \n",
    "                                \"signup_source\", \"driver_with_twic\", \"home_base_city\",\"home_base_state\"] #\"home_base_city\",\"home_base_state\"\n",
    "\n",
    "df_num = df_concat.drop(columns=categorical_features_one_hot)\n",
    "numerical_features = list(df_num)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', imputer),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_features),\n",
    "        (\"cat\", OneHotEncoder(sparse=False), categorical_features_one_hot), #sparse=False\n",
    "    ])\n",
    "df_prepared = full_pipeline.fit_transform(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1078,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 1.85116313, -0.39965744, -0.20109732, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.87262531, -0.39965744, -0.20109732, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.88612658, -0.39965744, -0.20109732, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       ...,\n",
       "       [ 1.07263803, -0.39965744,  0.23165021, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [ 1.75297732,  1.95624695, -0.20109732, ...,  0.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-1.00674481, -0.18762604, -0.10999258, ...,  0.        ,\n",
       "         0.        ,  0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1079,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_prepared[:5291]\n",
    "y = labels\n",
    "X_test_score = df_prepared[5291:]\n",
    "y_test_score = score_labels\n",
    "y_test_score = np.array(y_test_score)\n",
    "y = y.astype('int')\n",
    "X, y = SMOTE().fit_resample(X, y)\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1080,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8377, 647) (2095, 647)\n",
      "(8377,) (2095,)\n",
      "(1000, 647) (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "print(X_test_score.shape, y_test_score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1081,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LinearRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "lr_predicted = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1082,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "20480946.84227338"
      ]
     },
     "execution_count": 1082,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(y_test, lr_predicted)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1083,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "-1678155469327497.0"
      ]
     },
     "execution_count": 1083,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import r2_score\n",
    "\n",
    "r2_score(y_test, lr_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1084,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "                            OLS Regression Results                            \n",
      "==============================================================================\n",
      "Dep. Variable:                  label   R-squared:                       0.904\n",
      "Model:                            OLS   Adj. R-squared:                  0.897\n",
      "Method:                 Least Squares   F-statistic:                     137.9\n",
      "Date:                Thu, 18 Mar 2021   Prob (F-statistic):               0.00\n",
      "Time:                        16:18:02   Log-Likelihood:                 3724.1\n",
      "No. Observations:                8377   AIC:                            -6378.\n",
      "Df Residuals:                    7842   BIC:                            -2616.\n",
      "Df Model:                         534                                         \n",
      "Covariance Type:            nonrobust                                         \n",
      "==============================================================================\n",
      "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
      "------------------------------------------------------------------------------\n",
      "const         -0.0002      0.025     -0.008      0.994      -0.049       0.049\n",
      "x1             0.0421      0.005      8.077      0.000       0.032       0.052\n",
      "x2            -0.7281      0.046    -15.898      0.000      -0.818      -0.638\n",
      "x3             0.0065      0.003      2.482      0.013       0.001       0.012\n",
      "x4             0.0073      0.001      8.278      0.000       0.006       0.009\n",
      "x5             0.0091      0.001      8.401      0.000       0.007       0.011\n",
      "x6            -0.0051      0.001     -5.134      0.000      -0.007      -0.003\n",
      "x7             0.0359      0.001     26.959      0.000       0.033       0.038\n",
      "x8            -0.0002      0.001     -0.177      0.860      -0.002       0.002\n",
      "x9             0.0960      0.002     45.367      0.000       0.092       0.100\n",
      "x10            0.1055      0.006     18.314      0.000       0.094       0.117\n",
      "x11           -0.0437      0.004    -12.268      0.000      -0.051      -0.037\n",
      "x12           -0.0907      0.004    -22.652      0.000      -0.099      -0.083\n",
      "x13           -0.2187      0.119     -1.838      0.066      -0.452       0.015\n",
      "x14            0.1474      0.048      3.042      0.002       0.052       0.242\n",
      "x15            0.0711      0.048      1.468      0.142      -0.024       0.166\n",
      "x16            0.3021      0.081      3.737      0.000       0.144       0.461\n",
      "x17           -0.4847      0.044    -11.070      0.000      -0.570      -0.399\n",
      "x18           -0.4775      0.048    -10.025      0.000      -0.571      -0.384\n",
      "x19           -0.0536      0.062     -0.867      0.386      -0.175       0.068\n",
      "x20           -0.2772      0.052     -5.362      0.000      -0.379      -0.176\n",
      "x21            0.1825      0.064      2.861      0.004       0.057       0.307\n",
      "x22           -0.3299      0.038     -8.745      0.000      -0.404      -0.256\n",
      "x23           -0.1239      0.052     -2.397      0.017      -0.225      -0.023\n",
      "x24           -0.0265      0.040     -0.666      0.505      -0.104       0.051\n",
      "x25           -0.1351      0.052     -2.621      0.009      -0.236      -0.034\n",
      "x26           -0.2627      0.040     -6.627      0.000      -0.340      -0.185\n",
      "x27           -0.5477      0.038    -14.341      0.000      -0.623      -0.473\n",
      "x28            0.0757      0.046      1.660      0.097      -0.014       0.165\n",
      "x29           -0.0770      0.019     -4.084      0.000      -0.114      -0.040\n",
      "x30           -0.0399      0.049     -0.819      0.413      -0.135       0.056\n",
      "x31            0.1692      0.056      3.020      0.003       0.059       0.279\n",
      "x32           -0.1187      0.046     -2.562      0.010      -0.210      -0.028\n",
      "x33           -0.1083      0.043     -2.512      0.012      -0.193      -0.024\n",
      "x34            0.1091      0.045      2.412      0.016       0.020       0.198\n",
      "x35           -0.2402      0.063     -3.828      0.000      -0.363      -0.117\n",
      "x36           -0.0651      0.032     -2.009      0.045      -0.129      -0.002\n",
      "x37            0.0790      0.072      1.102      0.271      -0.062       0.220\n",
      "x38            0.0203      0.042      0.480      0.631      -0.063       0.103\n",
      "x39            0.1923      0.047      4.068      0.000       0.100       0.285\n",
      "x40           -0.3126      0.061     -5.163      0.000      -0.431      -0.194\n",
      "x41           -0.1145      0.072     -1.598      0.110      -0.255       0.026\n",
      "x42           -0.0629      0.056     -1.129      0.259      -0.172       0.046\n",
      "x43           -0.0322      0.060     -0.533      0.594      -0.151       0.086\n",
      "x44           -0.4445      0.114     -3.911      0.000      -0.667      -0.222\n",
      "x45           -0.0347      0.022     -1.543      0.123      -0.079       0.009\n",
      "x46           -0.0479      0.025     -1.915      0.056      -0.097       0.001\n",
      "x47           -0.0969      0.062     -1.572      0.116      -0.218       0.024\n",
      "x48            0.4654      0.068      6.837      0.000       0.332       0.599\n",
      "x49            2.7822      0.184     15.091      0.000       2.421       3.144\n",
      "x50           -0.1074      0.025     -4.264      0.000      -0.157      -0.058\n",
      "x51           -0.2121      0.020    -10.781      0.000      -0.251      -0.174\n",
      "x52           -0.0673      0.065     -1.044      0.297      -0.194       0.059\n",
      "x53            0.1100      0.035      3.116      0.002       0.041       0.179\n",
      "x54           -0.5031      0.045    -11.283      0.000      -0.590      -0.416\n",
      "x55            1.2591      0.076     16.463      0.000       1.109       1.409\n",
      "x56           -0.2967      0.054     -5.514      0.000      -0.402      -0.191\n",
      "x57            0.1454      0.041      3.559      0.000       0.065       0.226\n",
      "x58            0.1889      0.064      2.965      0.003       0.064       0.314\n",
      "x59           -0.2281      0.051     -4.453      0.000      -0.328      -0.128\n",
      "x60           -0.0173      0.047     -0.372      0.710      -0.109       0.074\n",
      "x61           -0.1278      0.062     -2.074      0.038      -0.249      -0.007\n",
      "x62            0.1538      0.055      2.788      0.005       0.046       0.262\n",
      "x63            0.1778      0.038      4.636      0.000       0.103       0.253\n",
      "x64           -0.1403      0.035     -3.962      0.000      -0.210      -0.071\n",
      "x65           -0.0076      0.031     -0.249      0.803      -0.067       0.052\n",
      "x66           -0.1912      0.046     -4.143      0.000      -0.282      -0.101\n",
      "x67           -0.0524      0.024     -2.170      0.030      -0.100      -0.005\n",
      "x68            0.0760      0.109      0.699      0.484      -0.137       0.289\n",
      "x69            0.2778      0.024     11.734      0.000       0.231       0.324\n",
      "x70        -5.311e-16   9.22e-16     -0.576      0.565   -2.34e-15    1.28e-15\n",
      "x71            0.0226      0.184      0.123      0.902      -0.339       0.384\n",
      "x72           -0.1226      0.020     -6.107      0.000      -0.162      -0.083\n",
      "x73            0.1095      0.047      2.339      0.019       0.018       0.201\n",
      "x74           -0.0341      0.018     -1.868      0.062      -0.070       0.002\n",
      "x75            0.0366      0.043      0.850      0.395      -0.048       0.121\n",
      "x76           -0.1963      0.052     -3.791      0.000      -0.298      -0.095\n",
      "x77           -0.0787      0.029     -2.713      0.007      -0.136      -0.022\n",
      "x78            0.0600      0.019      3.176      0.001       0.023       0.097\n",
      "x79           -0.0127      0.057     -0.222      0.825      -0.125       0.099\n",
      "x80           -0.1285      0.047     -2.735      0.006      -0.221      -0.036\n",
      "x81           -0.0312      0.031     -1.001      0.317      -0.092       0.030\n",
      "x82            0.0736      0.036      2.019      0.043       0.002       0.145\n",
      "x83            0.0066      0.013      0.493      0.622      -0.020       0.033\n",
      "x84           -0.0068      0.013     -0.523      0.601      -0.032       0.019\n",
      "x85           -0.0692      0.013     -5.287      0.000      -0.095      -0.044\n",
      "x86            0.0690      0.014      5.010      0.000       0.042       0.096\n",
      "x87            0.0779      0.160      0.486      0.627      -0.236       0.392\n",
      "x88           -0.1104      0.160     -0.691      0.490      -0.423       0.203\n",
      "x89           -0.0028      0.057     -0.049      0.961      -0.115       0.109\n",
      "x90            0.0330      0.075      0.441      0.659      -0.114       0.180\n",
      "x91           -0.0506      0.133     -0.379      0.704      -0.312       0.211\n",
      "x92            0.3380      0.031     10.782      0.000       0.277       0.399\n",
      "x93            0.0503      0.092      0.548      0.584      -0.130       0.230\n",
      "x94            0.0822      0.160      0.513      0.608      -0.232       0.396\n",
      "x95           -0.1649      0.035     -4.686      0.000      -0.234      -0.096\n",
      "x96           -0.0277      0.113     -0.245      0.806      -0.249       0.194\n",
      "x97           -0.1209      0.155     -0.782      0.434      -0.424       0.182\n",
      "x98           -0.0988      0.081     -1.223      0.221      -0.257       0.060\n",
      "x99            0.0429      0.054      0.792      0.428      -0.063       0.149\n",
      "x100           0.1183      0.160      0.738      0.460      -0.196       0.432\n",
      "x101          -0.0615      0.156     -0.395      0.693      -0.367       0.244\n",
      "x102          -0.0465      0.070     -0.665      0.506      -0.183       0.090\n",
      "x103          -0.1011      0.152     -0.665      0.506      -0.399       0.197\n",
      "x104           0.0657      0.143      0.461      0.645      -0.214       0.345\n",
      "x105           0.0987      0.150      0.657      0.511      -0.196       0.393\n",
      "x106          -0.0935      0.126     -0.740      0.459      -0.341       0.154\n",
      "x107          -0.0397      0.052     -0.768      0.443      -0.141       0.062\n",
      "x108           0.0064      0.031      0.204      0.838      -0.055       0.068\n",
      "x109          -0.1395      0.045     -3.070      0.002      -0.229      -0.050\n",
      "x110       -6.668e-17   1.18e-15     -0.057      0.955   -2.38e-15    2.24e-15\n",
      "x111           0.0673      0.079      0.850      0.396      -0.088       0.223\n",
      "x112          -0.0813      0.160     -0.509      0.611      -0.394       0.232\n",
      "x113        4.177e-16   1.26e-15      0.331      0.740   -2.05e-15    2.89e-15\n",
      "x114        7.043e-16   1.02e-15      0.688      0.492    -1.3e-15    2.71e-15\n",
      "x115           0.0060      0.160      0.038      0.970      -0.308       0.320\n",
      "x116          -0.0712      0.034     -2.102      0.036      -0.138      -0.005\n",
      "x117          -0.0777      0.045     -1.711      0.087      -0.167       0.011\n",
      "x118          -0.0739      0.041     -1.789      0.074      -0.155       0.007\n",
      "x119          -0.0029      0.112     -0.026      0.979      -0.223       0.217\n",
      "x120          -0.0847      0.077     -1.092      0.275      -0.237       0.067\n",
      "x121           0.0205      0.142      0.144      0.885      -0.258       0.299\n",
      "x122           0.0205      0.160      0.128      0.898      -0.293       0.334\n",
      "x123        5.506e-16   1.75e-15      0.315      0.753   -2.88e-15    3.98e-15\n",
      "x124           0.0077      0.158      0.048      0.961      -0.302       0.317\n",
      "x125           0.0508      0.160      0.318      0.750      -0.262       0.364\n",
      "x126          -0.0217      0.036     -0.597      0.550      -0.093       0.049\n",
      "x127           0.1477      0.112      1.323      0.186      -0.071       0.366\n",
      "x128       -2.955e-16   1.11e-15     -0.265      0.791   -2.48e-15    1.89e-15\n",
      "x129          -0.0950      0.152     -0.625      0.532      -0.393       0.203\n",
      "x130          -0.0276      0.093     -0.297      0.766      -0.209       0.154\n",
      "x131           0.0225      0.142      0.158      0.874      -0.256       0.301\n",
      "x132       -1.074e-15   8.28e-16     -1.297      0.195    -2.7e-15     5.5e-16\n",
      "x133           0.0256      0.161      0.159      0.873      -0.290       0.341\n",
      "x134           0.1144      0.158      0.724      0.469      -0.195       0.424\n",
      "x135        -4.24e-16   9.24e-16     -0.459      0.646   -2.23e-15    1.39e-15\n",
      "x136        2.313e-16   1.53e-15      0.151      0.880   -2.77e-15    3.23e-15\n",
      "x137           0.0313      0.151      0.207      0.836      -0.265       0.328\n",
      "x138          -0.0282      0.156     -0.181      0.856      -0.334       0.277\n",
      "x139           0.0945      0.137      0.688      0.491      -0.175       0.364\n",
      "x140           0.0127      0.080      0.158      0.874      -0.145       0.170\n",
      "x141        1.929e-16   1.51e-15      0.128      0.898   -2.76e-15    3.15e-15\n",
      "x142          -0.0050      0.128     -0.039      0.969      -0.256       0.246\n",
      "x143           0.0107      0.057      0.187      0.852      -0.102       0.123\n",
      "x144          -0.0806      0.081     -1.000      0.317      -0.239       0.077\n",
      "x145          -0.3380      0.114     -2.974      0.003      -0.561      -0.115\n",
      "x146          -0.0131      0.113     -0.116      0.908      -0.235       0.209\n",
      "x147          -0.0672      0.160     -0.421      0.674      -0.380       0.246\n",
      "x148          -0.0933      0.160     -0.584      0.559      -0.406       0.220\n",
      "x149          -0.0209      0.019     -1.110      0.267      -0.058       0.016\n",
      "x150          -0.1640      0.160     -1.024      0.306      -0.478       0.150\n",
      "x151           0.0095      0.160      0.059      0.953      -0.304       0.323\n",
      "x152          -0.0046      0.111     -0.042      0.967      -0.222       0.213\n",
      "x153          -0.0802      0.054     -1.474      0.140      -0.187       0.026\n",
      "x154          -0.0514      0.083     -0.619      0.536      -0.214       0.111\n",
      "x155           0.0739      0.143      0.518      0.604      -0.206       0.354\n",
      "x156           0.2985      0.082      3.620      0.000       0.137       0.460\n",
      "x157           0.0161      0.047      0.341      0.733      -0.077       0.109\n",
      "x158       -2.817e-16   1.38e-15     -0.204      0.838   -2.99e-15    2.42e-15\n",
      "x159          -0.0849      0.041     -2.061      0.039      -0.166      -0.004\n",
      "x160          -0.1162      0.047     -2.462      0.014      -0.209      -0.024\n",
      "x161           0.1307      0.160      0.817      0.414      -0.183       0.444\n",
      "x162          -0.0895      0.187     -0.479      0.632      -0.455       0.276\n",
      "x163          -0.0050      0.052     -0.096      0.924      -0.106       0.096\n",
      "x164          -0.0141      0.070     -0.202      0.840      -0.151       0.123\n",
      "x165           0.1656      0.160      1.034      0.301      -0.148       0.480\n",
      "x166           0.0395      0.032      1.234      0.217      -0.023       0.102\n",
      "x167          -0.0651      0.032     -2.009      0.045      -0.129      -0.002\n",
      "x168          -0.0528      0.147     -0.359      0.719      -0.340       0.235\n",
      "x169          -0.1025      0.155     -0.663      0.507      -0.405       0.200\n",
      "x170           0.0892      0.148      0.601      0.548      -0.202       0.380\n",
      "x171          -0.0239      0.158     -0.151      0.880      -0.333       0.286\n",
      "x172          -0.0797      0.163     -0.490      0.624      -0.399       0.239\n",
      "x173       -2.583e-16   1.22e-15     -0.212      0.832   -2.64e-15    2.13e-15\n",
      "x174          -0.1729      0.142     -1.215      0.225      -0.452       0.106\n",
      "x175          -0.0806      0.054     -1.488      0.137      -0.187       0.026\n",
      "x176          -0.1296      0.148     -0.874      0.382      -0.421       0.161\n",
      "x177          -0.0745      0.047     -1.576      0.115      -0.167       0.018\n",
      "x178           0.0442      0.230      0.192      0.848      -0.407       0.496\n",
      "x179          -0.2531      0.021    -12.025      0.000      -0.294      -0.212\n",
      "x180           0.0263      0.194      0.136      0.892      -0.354       0.406\n",
      "x181          -0.0382      0.156     -0.245      0.806      -0.343       0.267\n",
      "x182           0.0999      0.147      0.680      0.496      -0.188       0.388\n",
      "x183           0.0057      0.033      0.170      0.865      -0.060       0.071\n",
      "x184          -0.0372      0.160     -0.232      0.816      -0.351       0.277\n",
      "x185          -0.1483      0.066     -2.247      0.025      -0.278      -0.019\n",
      "x186          -0.0081      0.114     -0.071      0.943      -0.231       0.214\n",
      "x187          -0.2366      0.114     -2.082      0.037      -0.459      -0.014\n",
      "x188          -0.1344      0.160     -0.839      0.401      -0.448       0.179\n",
      "x189          -0.1606      0.093     -1.732      0.083      -0.342       0.021\n",
      "x190           0.1044      0.075      1.391      0.164      -0.043       0.252\n",
      "x191          -0.0594      0.160     -0.372      0.710      -0.373       0.254\n",
      "x192          -0.0311      0.153     -0.204      0.839      -0.331       0.268\n",
      "x193          -0.0121      0.156     -0.078      0.938      -0.318       0.293\n",
      "x194          -0.0762      0.109     -0.696      0.486      -0.291       0.138\n",
      "x195           0.0070      0.156      0.045      0.964      -0.298       0.312\n",
      "x196          -0.1010      0.160     -0.631      0.528      -0.415       0.213\n",
      "x197           0.0512      0.151      0.339      0.735      -0.245       0.347\n",
      "x198           0.0842      0.230      0.365      0.715      -0.367       0.536\n",
      "x199           0.0945      0.160      0.590      0.555      -0.219       0.408\n",
      "x200           0.0549      0.052      1.065      0.287      -0.046       0.156\n",
      "x201           0.1008      0.058      1.736      0.083      -0.013       0.215\n",
      "x202          -0.0387      0.112     -0.347      0.729      -0.257       0.180\n",
      "x203          -0.0527      0.150     -0.351      0.726      -0.347       0.242\n",
      "x204           0.2382      0.017     13.849      0.000       0.204       0.272\n",
      "x205          -0.0479      0.025     -1.915      0.056      -0.097       0.001\n",
      "x206          -0.1822      0.160     -1.140      0.254      -0.496       0.131\n",
      "x207           0.0802      0.160      0.501      0.617      -0.234       0.394\n",
      "x208          -0.0350      0.158     -0.222      0.825      -0.345       0.275\n",
      "x209          -0.1425      0.094     -1.515      0.130      -0.327       0.042\n",
      "x210          -0.3776      0.093     -4.066      0.000      -0.560      -0.196\n",
      "x211           0.0595      0.151      0.393      0.694      -0.237       0.356\n",
      "x212          -0.1112      0.111     -1.000      0.317      -0.329       0.107\n",
      "x213          -0.0548      0.066     -0.829      0.407      -0.184       0.075\n",
      "x214          -0.0490      0.031     -1.558      0.119      -0.111       0.013\n",
      "x215           0.0669      0.054      1.239      0.215      -0.039       0.173\n",
      "x216           0.0851      0.081      1.055      0.291      -0.073       0.243\n",
      "x217          -0.0620      0.160     -0.387      0.698      -0.376       0.252\n",
      "x218           0.0268      0.149      0.180      0.857      -0.265       0.318\n",
      "x219          -0.0088      0.158     -0.056      0.956      -0.318       0.301\n",
      "x220          -0.0020      0.066     -0.030      0.976      -0.131       0.127\n",
      "x221          -0.0982      0.068     -1.447      0.148      -0.231       0.035\n",
      "x222          -0.0796      0.115     -0.690      0.490      -0.306       0.147\n",
      "x223           0.0408      0.115      0.353      0.724      -0.186       0.267\n",
      "x224           0.1230      0.160      0.769      0.442      -0.191       0.437\n",
      "x225        2.201e-16   1.19e-15      0.185      0.853   -2.11e-15    2.55e-15\n",
      "x226           0.0174      0.152      0.114      0.909      -0.280       0.315\n",
      "x227           0.0267      0.160      0.167      0.867      -0.287       0.340\n",
      "x228          -0.0183      0.137     -0.134      0.893      -0.286       0.249\n",
      "x229       -4.916e-17   1.12e-15     -0.044      0.965   -2.24e-15    2.14e-15\n",
      "x230          -0.0378      0.106     -0.357      0.721      -0.245       0.170\n",
      "x231           0.0395      0.014      2.852      0.004       0.012       0.067\n",
      "x232           0.1000      0.049      2.044      0.041       0.004       0.196\n",
      "x233          -0.0305      0.140     -0.217      0.828      -0.306       0.245\n",
      "x234           0.0893      0.156      0.573      0.566      -0.216       0.395\n",
      "x235          -0.0428      0.072     -0.593      0.553      -0.184       0.099\n",
      "x236          -0.0311      0.032     -0.965      0.335      -0.094       0.032\n",
      "x237          -0.1572      0.113     -1.385      0.166      -0.380       0.065\n",
      "x238          -0.0711      0.160     -0.444      0.657      -0.385       0.243\n",
      "x239           0.1890      0.190      0.998      0.319      -0.182       0.561\n",
      "x240          -0.1129      0.093     -1.213      0.225      -0.295       0.070\n",
      "x241          -0.0996      0.032     -3.081      0.002      -0.163      -0.036\n",
      "x242           0.0295      0.140      0.210      0.833      -0.246       0.305\n",
      "x243        1.813e-18   7.18e-16      0.003      0.998    -1.4e-15    1.41e-15\n",
      "x244           0.0830      0.189      0.438      0.661      -0.288       0.454\n",
      "x245           0.0188      0.033      0.574      0.566      -0.045       0.083\n",
      "x246       -1.408e-16   1.18e-15     -0.120      0.905   -2.45e-15    2.16e-15\n",
      "x247           0.0399      0.189      0.211      0.833      -0.331       0.411\n",
      "x248           0.0168      0.159      0.106      0.916      -0.294       0.328\n",
      "x249       -1.544e-16   9.17e-16     -0.168      0.866   -1.95e-15    1.64e-15\n",
      "x250           0.0371      0.112      0.332      0.740      -0.182       0.256\n",
      "x251          -0.0304      0.079     -0.384      0.701      -0.186       0.125\n",
      "x252          -0.0388      0.027     -1.429      0.153      -0.092       0.014\n",
      "x253       -1.238e-16   1.58e-15     -0.078      0.938   -3.22e-15    2.97e-15\n",
      "x254           0.0250      0.119      0.209      0.834      -0.209       0.259\n",
      "x255          -0.2285      0.102     -2.241      0.025      -0.428      -0.029\n",
      "x256           0.0693      0.080      0.862      0.389      -0.088       0.227\n",
      "x257          -0.4387      0.072     -6.066      0.000      -0.580      -0.297\n",
      "x258          -0.1870      0.044     -4.249      0.000      -0.273      -0.101\n",
      "x259           0.0220      0.093      0.238      0.812      -0.160       0.204\n",
      "x260           0.0213      0.119      0.178      0.859      -0.213       0.255\n",
      "x261          -0.0937      0.160     -0.585      0.558      -0.407       0.220\n",
      "x262           0.0635      0.143      0.444      0.657      -0.217       0.344\n",
      "x263       -9.863e-17   1.05e-15     -0.094      0.925   -2.17e-15    1.97e-15\n",
      "x264           0.1963      0.150      1.305      0.192      -0.098       0.491\n",
      "x265           0.0318      0.033      0.969      0.332      -0.033       0.096\n",
      "x266           0.0713      0.113      0.633      0.527      -0.149       0.292\n",
      "x267          -0.0810      0.160     -0.506      0.613      -0.395       0.233\n",
      "x268           0.0056      0.116      0.048      0.961      -0.221       0.232\n",
      "x269          -0.0443      0.155     -0.287      0.774      -0.347       0.259\n",
      "x270        2.077e-17   1.18e-15      0.018      0.986   -2.29e-15    2.33e-15\n",
      "x271          -0.0932      0.160     -0.583      0.560      -0.406       0.220\n",
      "x272       -3.155e-17   7.84e-16     -0.040      0.968   -1.57e-15     1.5e-15\n",
      "x273          -0.0365      0.070     -0.522      0.601      -0.173       0.100\n",
      "x274       -1.293e-17   1.03e-15     -0.013      0.990   -2.03e-15    2.01e-15\n",
      "x275          -0.1628      0.061     -2.661      0.008      -0.283      -0.043\n",
      "x276          -0.0938      0.160     -0.587      0.557      -0.407       0.219\n",
      "x277          -0.1679      0.160     -1.046      0.296      -0.482       0.147\n",
      "x278        1.244e-16   1.38e-15      0.090      0.928   -2.58e-15    2.83e-15\n",
      "x279           0.1104      0.065      1.708      0.088      -0.016       0.237\n",
      "x280          -0.0767      0.061     -1.253      0.210      -0.197       0.043\n",
      "x281           0.1484      0.023      6.588      0.000       0.104       0.193\n",
      "x282           0.0160      0.079      0.201      0.840      -0.139       0.171\n",
      "x283         4.67e-16   1.31e-15      0.356      0.722   -2.11e-15    3.04e-15\n",
      "x284          -0.0773      0.072     -1.071      0.284      -0.219       0.064\n",
      "x285          -0.3513      0.027    -13.150      0.000      -0.404      -0.299\n",
      "x286        1.114e-17   1.39e-15      0.008      0.994    -2.7e-15    2.73e-15\n",
      "x287           0.0696      0.062      1.123      0.261      -0.052       0.191\n",
      "x288          -0.0433      0.158     -0.275      0.784      -0.353       0.266\n",
      "x289          -0.1837      0.160     -1.149      0.251      -0.497       0.130\n",
      "x290          -0.0756      0.149     -0.508      0.611      -0.367       0.216\n",
      "x291          -0.0618      0.039     -1.581      0.114      -0.138       0.015\n",
      "x292           0.1401      0.085      1.644      0.100      -0.027       0.307\n",
      "x293          -0.0613      0.156     -0.394      0.694      -0.367       0.244\n",
      "x294          -0.0312      0.158     -0.198      0.843      -0.341       0.278\n",
      "x295         1.14e-16   8.65e-16      0.132      0.895   -1.58e-15    1.81e-15\n",
      "x296          -0.1009      0.153     -0.658      0.511      -0.401       0.200\n",
      "x297        1.244e-17   1.77e-15      0.007      0.994   -3.46e-15    3.48e-15\n",
      "x298           0.0875      0.160      0.547      0.584      -0.226       0.401\n",
      "x299          -0.0895      0.081     -1.110      0.267      -0.247       0.068\n",
      "x300          -0.0127      0.057     -0.222      0.825      -0.125       0.099\n",
      "x301          -0.2783      0.114     -2.451      0.014      -0.501      -0.056\n",
      "x302           0.3027      0.024     12.467      0.000       0.255       0.350\n",
      "x303          -0.1101      0.093     -1.187      0.235      -0.292       0.072\n",
      "x304           0.0273      0.033      0.831      0.406      -0.037       0.092\n",
      "x305           0.2065      0.160      1.289      0.197      -0.108       0.520\n",
      "x306          -0.0527      0.111     -0.473      0.636      -0.271       0.166\n",
      "x307          -0.1655      0.160     -1.034      0.301      -0.479       0.148\n",
      "x308          -0.2403      0.093     -2.583      0.010      -0.423      -0.058\n",
      "x309          -0.0593      0.160     -0.370      0.711      -0.373       0.255\n",
      "x310          -0.1050      0.047     -2.221      0.026      -0.198      -0.012\n",
      "x311          -0.0498      0.049     -1.012      0.312      -0.146       0.047\n",
      "x312          -0.0856      0.112     -0.762      0.446      -0.306       0.135\n",
      "x313          -0.0191      0.052     -0.366      0.714      -0.121       0.083\n",
      "x314       -6.864e-18   1.09e-15     -0.006      0.995   -2.15e-15    2.14e-15\n",
      "x315           0.0414      0.163      0.255      0.799      -0.277       0.360\n",
      "x316          -0.0848      0.079     -1.071      0.284      -0.240       0.070\n",
      "x317          -0.1399      0.114     -1.229      0.219      -0.363       0.083\n",
      "x318           0.0799      0.155      0.517      0.605      -0.223       0.383\n",
      "x319        8.572e-18   1.09e-15      0.008      0.994   -2.13e-15    2.15e-15\n",
      "x320          -0.0906      0.109     -0.828      0.408      -0.305       0.124\n",
      "x321          -0.1242      0.160     -0.776      0.438      -0.438       0.190\n",
      "x322          -0.0461      0.116     -0.398      0.691      -0.273       0.181\n",
      "x323          -0.2609      0.194     -1.345      0.179      -0.641       0.119\n",
      "x324           0.0524      0.138      0.381      0.703      -0.217       0.322\n",
      "x325          -0.1124      0.155     -0.726      0.468      -0.416       0.191\n",
      "x326          -0.1074      0.025     -4.264      0.000      -0.157      -0.058\n",
      "x327          -0.0175      0.113     -0.154      0.877      -0.240       0.205\n",
      "x328           0.0947      0.113      0.835      0.404      -0.128       0.317\n",
      "x329          -0.0070      0.165     -0.043      0.966      -0.330       0.316\n",
      "x330           0.1665      0.014     11.820      0.000       0.139       0.194\n",
      "x331          -0.0632      0.160     -0.395      0.693      -0.377       0.251\n",
      "x332           0.0721      0.011      6.470      0.000       0.050       0.094\n",
      "x333          -0.0407      0.031     -1.325      0.185      -0.101       0.020\n",
      "x334           0.1625      0.160      1.015      0.310      -0.151       0.476\n",
      "x335           0.0537      0.133      0.403      0.687      -0.208       0.315\n",
      "x336           0.1410      0.149      0.947      0.344      -0.151       0.433\n",
      "x337          -0.0448      0.113     -0.396      0.692      -0.266       0.177\n",
      "x338           0.0755      0.102      0.740      0.459      -0.125       0.276\n",
      "x339           0.0275      0.152      0.181      0.856      -0.270       0.325\n",
      "x340           0.0703      0.017      4.240      0.000       0.038       0.103\n",
      "x341        3.329e-21   1.71e-15   1.95e-06      1.000   -3.35e-15    3.35e-15\n",
      "x342          -0.0347      0.022     -1.543      0.123      -0.079       0.009\n",
      "x343          -0.0544      0.109     -0.500      0.617      -0.267       0.159\n",
      "x344           0.0283      0.054      0.520      0.603      -0.078       0.135\n",
      "x345           0.0139      0.147      0.094      0.925      -0.274       0.302\n",
      "x346          -0.0361      0.045     -0.795      0.427      -0.125       0.053\n",
      "x347          -0.0956      0.190     -0.504      0.614      -0.467       0.276\n",
      "x348          -0.1403      0.035     -3.962      0.000      -0.210      -0.071\n",
      "x349          -0.0647      0.149     -0.435      0.664      -0.356       0.227\n",
      "x350          -0.0738      0.135     -0.548      0.584      -0.338       0.190\n",
      "x351           0.1099      0.026      4.288      0.000       0.060       0.160\n",
      "x352          -0.0725      0.156     -0.466      0.642      -0.378       0.233\n",
      "x353        4.738e-27   6.78e-16   6.99e-12      1.000   -1.33e-15    1.33e-15\n",
      "x354        1.563e-26   1.13e-15   1.38e-11      1.000   -2.22e-15    2.22e-15\n",
      "x355           0.0658      0.147      0.449      0.654      -0.222       0.354\n",
      "x356           0.1234      0.155      0.798      0.425      -0.180       0.427\n",
      "x357          -0.0652      0.156     -0.419      0.675      -0.370       0.240\n",
      "x358          -0.0303      0.093     -0.326      0.744      -0.212       0.152\n",
      "x359           0.0681      0.093      0.735      0.463      -0.114       0.250\n",
      "x360          -0.0574      0.160     -0.359      0.720      -0.371       0.256\n",
      "x361          -0.1346      0.113     -1.187      0.235      -0.357       0.088\n",
      "x362        -1.89e-27   1.45e-15  -1.31e-12      1.000   -2.83e-15    2.83e-15\n",
      "x363           0.0064      0.052      0.123      0.902      -0.096       0.109\n",
      "x364       -7.748e-27   1.99e-15  -3.89e-12      1.000   -3.91e-15    3.91e-15\n",
      "x365           0.1006      0.160      0.628      0.530      -0.213       0.415\n",
      "x366           0.0830      0.158      0.525      0.600      -0.227       0.393\n",
      "x367           0.0070      0.113      0.062      0.951      -0.215       0.229\n",
      "x368          -0.2460      0.072     -3.399      0.001      -0.388      -0.104\n",
      "x369           0.3961      0.022     17.725      0.000       0.352       0.440\n",
      "x370           0.0586      0.138      0.425      0.671      -0.212       0.329\n",
      "x371          -0.0810      0.080     -1.007      0.314      -0.239       0.077\n",
      "x372           0.0808      0.158      0.512      0.609      -0.229       0.390\n",
      "x373           0.0514      0.115      0.448      0.654      -0.173       0.276\n",
      "x374           0.1061      0.025      4.187      0.000       0.056       0.156\n",
      "x375          -0.1656      0.061     -2.705      0.007      -0.286      -0.046\n",
      "x376          -0.0239      0.255     -0.094      0.925      -0.524       0.477\n",
      "x377           0.1315      0.158      0.833      0.405      -0.178       0.441\n",
      "x378           0.0156      0.160      0.098      0.922      -0.298       0.330\n",
      "x379           0.0516      0.017      2.978      0.003       0.018       0.085\n",
      "x380           0.1899      0.160      1.186      0.236      -0.124       0.504\n",
      "x381           0.1182      0.158      0.748      0.455      -0.192       0.428\n",
      "x382        1.472e-27   1.24e-15   1.18e-12      1.000   -2.44e-15    2.44e-15\n",
      "x383          -0.0888      0.096     -0.923      0.356      -0.277       0.100\n",
      "x384          -0.0883      0.160     -0.550      0.582      -0.403       0.226\n",
      "x385          -0.0831      0.072     -1.150      0.250      -0.225       0.059\n",
      "x386       -8.427e-27   1.01e-15  -8.33e-12      1.000   -1.98e-15    1.98e-15\n",
      "x387           0.1838      0.189      0.970      0.332      -0.188       0.555\n",
      "x388           0.2003      0.160      1.251      0.211      -0.114       0.514\n",
      "x389          -0.0231      0.082     -0.283      0.778      -0.183       0.137\n",
      "x390           0.0711      0.160      0.445      0.656      -0.242       0.384\n",
      "x391          -0.0034      0.093     -0.037      0.970      -0.185       0.178\n",
      "x392           0.0421      0.138      0.305      0.760      -0.228       0.312\n",
      "x393           0.0262      0.066      0.400      0.689      -0.102       0.155\n",
      "x394           0.0109      0.081      0.134      0.893      -0.148       0.170\n",
      "x395          -0.1150      0.113     -1.014      0.311      -0.337       0.107\n",
      "x396          -0.0459      0.090     -0.507      0.612      -0.223       0.131\n",
      "x397           0.1676      0.142      1.177      0.239      -0.111       0.447\n",
      "x398           0.8799      0.046     19.099      0.000       0.790       0.970\n",
      "x399           0.3125      0.022     14.170      0.000       0.269       0.356\n",
      "x400        4.731e-28   6.22e-16    7.6e-13      1.000   -1.22e-15    1.22e-15\n",
      "x401          -0.0742      0.116     -0.642      0.521      -0.301       0.152\n",
      "x402          -0.0870      0.114     -0.766      0.444      -0.310       0.136\n",
      "x403        4.853e-27   7.53e-16   6.44e-12      1.000   -1.48e-15    1.48e-15\n",
      "x404           0.1174      0.082      1.428      0.153      -0.044       0.279\n",
      "x405          -0.0214      0.079     -0.271      0.787      -0.177       0.134\n",
      "x406           0.0745      0.160      0.466      0.641      -0.239       0.388\n",
      "x407          -0.0444      0.019     -2.388      0.017      -0.081      -0.008\n",
      "x408        -1.06e-26   9.72e-16  -1.09e-11      1.000   -1.91e-15    1.91e-15\n",
      "x409          -0.0770      0.019     -4.084      0.000      -0.114      -0.040\n",
      "x410           0.1730      0.160      1.081      0.280      -0.141       0.487\n",
      "x411         2.18e-27   1.08e-15   2.01e-12      1.000   -2.13e-15    2.13e-15\n",
      "x412           0.1570      0.155      1.015      0.310      -0.146       0.460\n",
      "x413           0.0468      0.093      0.504      0.614      -0.135       0.229\n",
      "x414           0.0027      0.143      0.019      0.985      -0.278       0.283\n",
      "x415          -0.0062      0.117     -0.053      0.958      -0.236       0.223\n",
      "x416          -0.0681      0.160     -0.425      0.671      -0.382       0.246\n",
      "x417           0.0932      0.037      2.511      0.012       0.020       0.166\n",
      "x418          -0.1571      0.019     -8.386      0.000      -0.194      -0.120\n",
      "x419          -0.1349      0.058     -2.313      0.021      -0.249      -0.021\n",
      "x420       -5.183e-27   6.81e-16  -7.61e-12      1.000   -1.33e-15    1.33e-15\n",
      "x421          -0.1531      0.156     -0.983      0.326      -0.458       0.152\n",
      "x422          -0.0076      0.031     -0.249      0.803      -0.067       0.052\n",
      "x423           0.1691      0.152      1.112      0.266      -0.129       0.467\n",
      "x424          -0.0893      0.024     -3.776      0.000      -0.136      -0.043\n",
      "x425          -0.0686      0.081     -0.849      0.396      -0.227       0.090\n",
      "x426       -1.176e-26   1.03e-15  -1.14e-11      1.000   -2.01e-15    2.01e-15\n",
      "x427           0.0210      0.110      0.191      0.849      -0.194       0.236\n",
      "x428           0.0425      0.057      0.741      0.459      -0.070       0.155\n",
      "x429          -0.0885      0.160     -0.552      0.581      -0.403       0.226\n",
      "x430           0.1308      0.160      0.817      0.414      -0.183       0.445\n",
      "x431           0.0598      0.160      0.374      0.709      -0.254       0.374\n",
      "x432           0.0136      0.044      0.310      0.756      -0.072       0.099\n",
      "x433          -0.0338      0.150     -0.225      0.822      -0.328       0.261\n",
      "x434        5.483e-27   9.48e-16   5.79e-12      1.000   -1.86e-15    1.86e-15\n",
      "x435          -0.0609      0.147     -0.414      0.679      -0.349       0.227\n",
      "x436           0.0403      0.152      0.265      0.791      -0.258       0.338\n",
      "x437           0.0268      0.138      0.194      0.846      -0.244       0.297\n",
      "x438           0.0676      0.114      0.592      0.554      -0.156       0.291\n",
      "x439           0.1646      0.160      1.028      0.304      -0.149       0.478\n",
      "x440          -0.0510      0.093     -0.550      0.583      -0.233       0.131\n",
      "x441          -0.0021      0.028     -0.075      0.940      -0.058       0.053\n",
      "x442          -0.0783      0.113     -0.690      0.490      -0.301       0.144\n",
      "x443        -2.96e-27   1.14e-15  -2.59e-12      1.000   -2.24e-15    2.24e-15\n",
      "x444          -0.4624      0.160     -2.883      0.004      -0.777      -0.148\n",
      "x445          -0.0994      0.160     -0.620      0.535      -0.414       0.215\n",
      "x446          -0.0948      0.143     -0.663      0.507      -0.375       0.185\n",
      "x447          -0.0032      0.148     -0.021      0.983      -0.294       0.288\n",
      "x448           0.0363      0.032      1.123      0.261      -0.027       0.100\n",
      "x449          -0.0669      0.156     -0.429      0.668      -0.372       0.239\n",
      "x450           0.0216      0.152      0.142      0.887      -0.277       0.320\n",
      "x451           0.0429      0.114      0.378      0.705      -0.180       0.265\n",
      "x452          -0.0923      0.113     -0.814      0.416      -0.315       0.130\n",
      "x453           0.0446      0.066      0.674      0.501      -0.085       0.174\n",
      "x454          -0.0170      0.025     -0.680      0.497      -0.066       0.032\n",
      "x455        8.539e-27   9.83e-16   8.68e-12      1.000   -1.93e-15    1.93e-15\n",
      "x456          -0.0307      0.160     -0.192      0.848      -0.345       0.283\n",
      "x457          -0.1383      0.107     -1.297      0.195      -0.347       0.071\n",
      "x458           0.0655      0.143      0.459      0.646      -0.214       0.346\n",
      "x459          -0.0586      0.160     -0.367      0.714      -0.372       0.255\n",
      "x460        8.073e-27   1.18e-15   6.87e-12      1.000    -2.3e-15     2.3e-15\n",
      "x461          -0.0345      0.116     -0.298      0.766      -0.261       0.192\n",
      "x462           0.0422      0.154      0.274      0.784      -0.259       0.344\n",
      "x463           0.9630      0.078     12.381      0.000       0.811       1.115\n",
      "x464           0.0834      0.022      3.857      0.000       0.041       0.126\n",
      "x465          -0.0590      0.113     -0.520      0.603      -0.281       0.163\n",
      "x466           0.0780      0.038      2.049      0.040       0.003       0.153\n",
      "x467           0.1540      0.156      0.989      0.323      -0.151       0.459\n",
      "x468        -5.71e-27   1.17e-15  -4.88e-12      1.000   -2.29e-15    2.29e-15\n",
      "x469          -0.0533      0.061     -0.871      0.384      -0.173       0.067\n",
      "x470          -0.0478      0.155     -0.309      0.757      -0.351       0.255\n",
      "x471          -0.1029      0.149     -0.692      0.489      -0.395       0.189\n",
      "x472           0.0406      0.149      0.272      0.785      -0.252       0.333\n",
      "x473           0.0468      0.113      0.412      0.680      -0.176       0.269\n",
      "x474           0.0919      0.163      0.565      0.572      -0.227       0.410\n",
      "x475           0.0264      0.111      0.238      0.812      -0.191       0.244\n",
      "x476          -0.0108      0.094     -0.115      0.908      -0.194       0.173\n",
      "x477          -0.0282      0.026     -1.070      0.285      -0.080       0.023\n",
      "x478          -0.0247      0.160     -0.154      0.878      -0.339       0.290\n",
      "x479           0.3628      0.016     22.656      0.000       0.331       0.394\n",
      "x480           0.3762      0.029     12.786      0.000       0.319       0.434\n",
      "x481          -0.0578      0.081     -0.718      0.473      -0.216       0.100\n",
      "x482          -0.0590      0.160     -0.368      0.713      -0.373       0.255\n",
      "x483           0.1627      0.042      3.865      0.000       0.080       0.245\n",
      "x484          -0.1658      0.114     -1.460      0.144      -0.389       0.057\n",
      "x485          -0.0435      0.160     -0.272      0.786      -0.357       0.270\n",
      "x486          -0.0102      0.160     -0.064      0.949      -0.324       0.304\n",
      "x487           0.0974      0.160      0.608      0.543      -0.217       0.411\n",
      "x488           0.4042      0.023     17.474      0.000       0.359       0.450\n",
      "x489           0.1182      0.160      0.738      0.460      -0.196       0.432\n",
      "x490           0.0130      0.081      0.161      0.872      -0.145       0.171\n",
      "x491           0.0615      0.040      1.532      0.126      -0.017       0.140\n",
      "x492           0.1062      0.160      0.663      0.507      -0.208       0.420\n",
      "x493          -0.0474      0.160     -0.296      0.767      -0.361       0.266\n",
      "x494           0.1553      0.160      0.969      0.332      -0.159       0.469\n",
      "x495           0.1878      0.028      6.816      0.000       0.134       0.242\n",
      "x496          -0.1030      0.151     -0.681      0.496      -0.399       0.193\n",
      "x497          -0.0490      0.160     -0.307      0.759      -0.362       0.264\n",
      "x498          -0.0744      0.102     -0.730      0.466      -0.274       0.125\n",
      "x499          -0.0134      0.152     -0.088      0.930      -0.312       0.285\n",
      "x500           0.0181      0.113      0.160      0.873      -0.204       0.240\n",
      "x501           0.0053      0.150      0.035      0.972      -0.290       0.300\n",
      "x502           0.1100      0.152      0.724      0.469      -0.188       0.408\n",
      "x503        3.963e-27   7.83e-16   5.06e-12      1.000   -1.54e-15    1.54e-15\n",
      "x504          -0.0981      0.151     -0.649      0.516      -0.394       0.198\n",
      "x505           0.1653      0.066      2.491      0.013       0.035       0.295\n",
      "x506           0.1050      0.058      1.816      0.069      -0.008       0.218\n",
      "x507       -3.856e-27    1.1e-15  -3.49e-12      1.000   -2.16e-15    2.16e-15\n",
      "x508           0.0414      0.160      0.258      0.796      -0.273       0.355\n",
      "x509           0.1065      0.133      0.800      0.424      -0.155       0.368\n",
      "x510           0.0193      0.128      0.150      0.881      -0.232       0.271\n",
      "x511           0.0432      0.158      0.273      0.785      -0.267       0.353\n",
      "x512          -0.0940      0.097     -0.973      0.331      -0.283       0.095\n",
      "x513          -0.2174      0.093     -2.343      0.019      -0.399      -0.036\n",
      "x514          -0.0577      0.022     -2.620      0.009      -0.101      -0.015\n",
      "x515          -0.1854      0.151     -1.228      0.219      -0.481       0.111\n",
      "x516        1.073e-26   1.82e-15   5.91e-12      1.000   -3.56e-15    3.56e-15\n",
      "x517           0.1550      0.160      0.967      0.334      -0.159       0.469\n",
      "x518           0.0905      0.106      0.853      0.394      -0.117       0.298\n",
      "x519       -3.562e-27   6.26e-16  -5.69e-12      1.000   -1.23e-15    1.23e-15\n",
      "x520           0.0454      0.093      0.489      0.625      -0.137       0.228\n",
      "x521           0.0246      0.110      0.225      0.822      -0.190       0.240\n",
      "x522           0.2128      0.152      1.396      0.163      -0.086       0.512\n",
      "x523          -0.0498      0.143     -0.349      0.727      -0.330       0.230\n",
      "x524           0.1123      0.081      1.394      0.163      -0.046       0.270\n",
      "x525           0.0699      0.057      1.219      0.223      -0.043       0.182\n",
      "x526        1.339e-27   1.01e-15   1.33e-12      1.000   -1.98e-15    1.98e-15\n",
      "x527          -0.0529      0.110     -0.483      0.629      -0.268       0.162\n",
      "x528          -0.1709      0.149     -1.149      0.251      -0.463       0.121\n",
      "x529       -3.403e-27   1.21e-15   -2.8e-12      1.000   -2.38e-15    2.38e-15\n",
      "x530          -0.0706      0.155     -0.457      0.648      -0.374       0.232\n",
      "x531           0.0669      0.151      0.443      0.658      -0.229       0.363\n",
      "x532           0.1402      0.189      0.740      0.459      -0.231       0.511\n",
      "x533           0.0176      0.159      0.111      0.912      -0.293       0.328\n",
      "x534           0.0133      0.152      0.088      0.930      -0.284       0.311\n",
      "x535          -0.0271      0.093     -0.291      0.771      -0.209       0.155\n",
      "x536          -0.1846      0.114     -1.625      0.104      -0.407       0.038\n",
      "x537          -0.0022      0.049     -0.045      0.964      -0.099       0.095\n",
      "x538           0.0024      0.114      0.021      0.983      -0.221       0.225\n",
      "x539          -0.0665      0.160     -0.416      0.677      -0.380       0.247\n",
      "x540           0.0283      0.139      0.204      0.838      -0.244       0.300\n",
      "x541           0.0794      0.160      0.496      0.620      -0.234       0.393\n",
      "x542           0.1865      0.156      1.197      0.231      -0.119       0.492\n",
      "x543           0.0523      0.019      2.778      0.005       0.015       0.089\n",
      "x544           0.0238      0.057      0.414      0.679      -0.089       0.136\n",
      "x545          -0.0858      0.147     -0.585      0.559      -0.374       0.202\n",
      "x546           0.1306      0.152      0.859      0.390      -0.167       0.429\n",
      "x547           0.0273      0.113      0.241      0.810      -0.195       0.250\n",
      "x548        3.471e-27   1.34e-15    2.6e-12      1.000   -2.62e-15    2.62e-15\n",
      "x549           0.0292      0.093      0.315      0.753      -0.153       0.211\n",
      "x550           0.0084      0.114      0.074      0.941      -0.214       0.231\n",
      "x551          -0.0532      0.158     -0.337      0.736      -0.363       0.256\n",
      "x552          -0.0027      0.093     -0.029      0.977      -0.185       0.179\n",
      "x553           0.0810      0.114      0.713      0.476      -0.142       0.304\n",
      "x554          -0.1343      0.141     -0.956      0.339      -0.410       0.141\n",
      "x555          -0.0432      0.152     -0.283      0.777      -0.342       0.256\n",
      "x556           0.0171      0.093      0.184      0.854      -0.165       0.199\n",
      "x557           0.1704      0.022      7.703      0.000       0.127       0.214\n",
      "x558          -0.0051      0.114     -0.045      0.964      -0.228       0.217\n",
      "x559          -0.0945      0.160     -0.590      0.555      -0.409       0.220\n",
      "x560           0.0887      0.165      0.537      0.592      -0.235       0.413\n",
      "x561           0.0477      0.051      0.926      0.354      -0.053       0.149\n",
      "x562       -4.125e-27   6.77e-16  -6.09e-12      1.000   -1.33e-15    1.33e-15\n",
      "x563        3.674e-27   1.16e-15   3.18e-12      1.000   -2.27e-15    2.27e-15\n",
      "x564           0.0669      0.151      0.443      0.658      -0.229       0.363\n",
      "x565          -0.0641      0.163     -0.393      0.694      -0.384       0.256\n",
      "x566          -0.0277      0.037     -0.748      0.455      -0.100       0.045\n",
      "x567          -0.0746      0.133     -0.560      0.576      -0.336       0.186\n",
      "x568          -0.0615      0.160     -0.384      0.701      -0.375       0.252\n",
      "x569          -0.2347      0.113     -2.069      0.039      -0.457      -0.012\n",
      "x570           0.0228      0.149      0.153      0.879      -0.270       0.315\n",
      "x571          -0.2506      0.158     -1.586      0.113      -0.560       0.059\n",
      "x572       -4.273e-27   6.58e-16  -6.49e-12      1.000   -1.29e-15    1.29e-15\n",
      "x573           0.0361      0.093      0.389      0.697      -0.146       0.218\n",
      "x574           0.0539      0.149      0.361      0.718      -0.239       0.347\n",
      "x575           0.0024      0.049      0.050      0.960      -0.094       0.099\n",
      "x576          -0.0856      0.160     -0.536      0.592      -0.399       0.228\n",
      "x577           0.0238      0.041      0.578      0.563      -0.057       0.104\n",
      "x578        1.327e-27   5.36e-16   2.48e-12      1.000   -1.05e-15    1.05e-15\n",
      "x579          -0.0299      0.097     -0.309      0.757      -0.220       0.160\n",
      "x580          -0.1064      0.216     -0.493      0.622      -0.529       0.316\n",
      "x581          -0.0637      0.155     -0.412      0.680      -0.367       0.239\n",
      "x582          -0.0466      0.143     -0.327      0.744      -0.326       0.233\n",
      "x583           0.0131      0.096      0.137      0.891      -0.175       0.202\n",
      "x584           0.1071      0.158      0.679      0.497      -0.202       0.417\n",
      "x585           0.1499      0.160      0.938      0.348      -0.163       0.463\n",
      "x586          -0.1475      0.027     -5.430      0.000      -0.201      -0.094\n",
      "x587          -0.0237      0.047     -0.502      0.616      -0.116       0.069\n",
      "x588           0.0798      0.160      0.499      0.618      -0.234       0.394\n",
      "x589          -0.0019      0.153     -0.013      0.990      -0.303       0.299\n",
      "x590           0.0779      0.160      0.487      0.627      -0.236       0.392\n",
      "x591          -0.0124      0.160     -0.077      0.938      -0.326       0.301\n",
      "x592       -4.681e-27   9.54e-16  -4.91e-12      1.000   -1.87e-15    1.87e-15\n",
      "x593           0.0560      0.103      0.542      0.588      -0.147       0.258\n",
      "x594           0.1577      0.160      0.985      0.325      -0.156       0.472\n",
      "x595           0.1914      0.160      1.195      0.232      -0.123       0.505\n",
      "x596           0.1181      0.099      1.193      0.233      -0.076       0.312\n",
      "x597        4.966e-27    7.6e-16   6.53e-12      1.000   -1.49e-15    1.49e-15\n",
      "x598           0.0285      0.151      0.188      0.851      -0.268       0.325\n",
      "x599           0.2362      0.160      1.472      0.141      -0.078       0.551\n",
      "x600           0.1586      0.160      0.990      0.322      -0.155       0.472\n",
      "x601          -0.1726      0.074     -2.338      0.019      -0.317      -0.028\n",
      "x602           0.1351      0.058      2.336      0.020       0.022       0.249\n",
      "x603       -7.319e-28   4.13e-16  -1.77e-12      1.000   -8.09e-16    8.09e-16\n",
      "x604           0.1076      0.160      0.672      0.502      -0.206       0.421\n",
      "x605          -0.0988      0.160     -0.617      0.537      -0.413       0.215\n",
      "x606           0.0581      0.093      0.626      0.531      -0.124       0.240\n",
      "x607           0.0101      0.160      0.063      0.949      -0.304       0.324\n",
      "x608           0.1406      0.107      1.320      0.187      -0.068       0.349\n",
      "x609          -0.0749      0.043     -1.732      0.083      -0.160       0.010\n",
      "x610          -0.0574      0.099     -0.581      0.561      -0.251       0.136\n",
      "x611           0.9630      0.078     12.381      0.000       0.811       1.115\n",
      "x612          -0.0417      0.019     -2.205      0.027      -0.079      -0.005\n",
      "x613          -0.1571      0.197     -0.799      0.424      -0.543       0.228\n",
      "x614       -7.367e-28   2.86e-16  -2.57e-12      1.000   -5.61e-16    5.61e-16\n",
      "x615          -0.0086      0.148     -0.058      0.954      -0.299       0.282\n",
      "x616          -0.0331      0.033     -1.004      0.315      -0.098       0.032\n",
      "x617          -0.0564      0.038     -1.486      0.137      -0.131       0.018\n",
      "x618          -0.0418      0.069     -0.607      0.544      -0.177       0.093\n",
      "x619          -0.0231      0.082     -0.283      0.778      -0.183       0.137\n",
      "x620          -0.0223      0.040     -0.563      0.574      -0.100       0.055\n",
      "x621          -0.0627      0.051     -1.234      0.217      -0.162       0.037\n",
      "x622          -0.0724      0.065     -1.116      0.264      -0.199       0.055\n",
      "x623          -0.0848      0.079     -1.071      0.284      -0.240       0.070\n",
      "x624           0.0673      0.079      0.850      0.396      -0.088       0.223\n",
      "x625          -0.0113      0.057     -0.200      0.842      -0.122       0.100\n",
      "x626           0.0036      0.065      0.055      0.956      -0.123       0.131\n",
      "x627          -0.0336      0.053     -0.630      0.528      -0.138       0.071\n",
      "x628          -0.0304      0.079     -0.384      0.701      -0.186       0.125\n",
      "x629           0.0462      0.075      0.619      0.536      -0.100       0.193\n",
      "x630          -0.0371      0.060     -0.621      0.535      -0.154       0.080\n",
      "x631          -0.0214      0.079     -0.271      0.787      -0.177       0.134\n",
      "x632          -0.0613      0.042     -1.442      0.149      -0.145       0.022\n",
      "x633          -0.0152      0.069     -0.220      0.826      -0.151       0.120\n",
      "x634          -0.0030      0.046     -0.066      0.947      -0.092       0.086\n",
      "x635          -0.0108      0.060     -0.181      0.856      -0.128       0.106\n",
      "x636          -0.0071      0.045     -0.157      0.875      -0.095       0.081\n",
      "x637           0.0062      0.061      0.101      0.919      -0.114       0.126\n",
      "x638          -0.0199      0.056     -0.356      0.722      -0.130       0.090\n",
      "x639          -0.1047      0.056     -1.883      0.060      -0.214       0.004\n",
      "x640           0.0160      0.079      0.201      0.840      -0.139       0.171\n",
      "x641          -0.0580      0.065     -0.894      0.371      -0.185       0.069\n",
      "x642          -0.0493      0.033     -1.480      0.139      -0.115       0.016\n",
      "x643           0.0243      0.048      0.506      0.613      -0.070       0.118\n",
      "x644           0.0693      0.080      0.862      0.389      -0.088       0.227\n",
      "x645          -0.1354      0.046     -2.959      0.003      -0.225      -0.046\n",
      "x646          -0.0018      0.046     -0.040      0.968      -0.092       0.088\n",
      "x647                0          0        nan        nan           0           0\n",
      "==============================================================================\n",
      "Omnibus:                     2757.628   Durbin-Watson:                   1.964\n",
      "Prob(Omnibus):                  0.000   Jarque-Bera (JB):            13474.639\n",
      "Skew:                          -1.518   Prob(JB):                         0.00\n",
      "Kurtosis:                       8.421   Cond. No.                     4.52e+18\n",
      "==============================================================================\n",
      "\n",
      "Notes:\n",
      "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
      "[2] The smallest eigenvalue is 1.6e-32. This might indicate that there are\n",
      "strong multicollinearity problems or that the design matrix is singular.\n"
     ]
    }
   ],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X_new = sm.add_constant(X_train)\n",
    "toyregr_sm = sm.OLS(y_train.astype(float), X_new.astype(float))\n",
    "results_sm = toyregr_sm.fit()\n",
    "\n",
    "print(results_sm.summary())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1085,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LogisticRegression\n",
    "\n",
    "# y_temp = y_train.astype('int')\n",
    "\n",
    "log_reg = LogisticRegression(max_iter=1000, multi_class='ovr')\n",
    "log_reg.fit(X_train, y_train)\n",
    "log_predicted = log_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1086,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.06554344147787575"
      ]
     },
     "execution_count": 1086,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mse = mean_squared_error(y_test, log_predicted)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1087,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9828133744852215"
      ]
     },
     "execution_count": 1087,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "r2_score(y_test, log_predicted)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1088,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9957040572792363%\n",
      "roc_auc_score = 0.9957587181903864\n",
      "F1-score = 0.9956668271545499\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1052,    9],\n",
       "       [   0, 1034]])"
      ]
     },
     "execution_count": 1088,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "\n",
    "accuracy = (accuracy_score(y_test, log_predicted))\n",
    "print(\"accuracy = {}%\".format(accuracy))\n",
    "print(\"roc_auc_score = {}\".format(roc_auc_score(y_test, log_predicted)))\n",
    "print(\"F1-score = {}\".format(f1_score(y_test, log_predicted)))\n",
    "\n",
    "confusion_matrix(y_test, log_predicted)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1089,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[23.02403235 14.8292382   4.7524796   3.43137662  1.34095534  0.91074499\n",
      "  0.64874155  0.4554143 ]\n",
      "8\n"
     ]
    }
   ],
   "source": [
    "pca = PCA(n_components=0.95) # Create an instance of PCA model\n",
    "pca.fit(X_train) # Fit X_train to PCA\n",
    "X_train = pca.transform(X_train) # transform training data\n",
    "X_test = pca.transform(X_test) # transform test data\n",
    "X_test_score_new = pca.transform(X_test_score) # transform score test data\n",
    "print(pca.explained_variance_)\n",
    "print(pca.n_components_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1090,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-4.56072222 -0.57757824 -0.18739078 ...  0.37283851 -0.48076528\n",
      "   0.21533659]\n",
      " [ 5.37456543  6.39873191 -6.11833163 ...  1.09087228  0.66087737\n",
      "  -0.20263969]\n",
      " [ 2.88971566  8.39506031 -0.90284581 ... -2.09916304 -1.37083757\n",
      "   0.9057837 ]\n",
      " ...\n",
      " [ 1.63578445 -1.82888682 -0.4267057  ... -0.13569799 -0.05801183\n",
      "  -0.32058679]\n",
      " [-4.19701409  0.18815678 -0.38575999 ...  0.15592229 -0.03875752\n",
      "  -0.03139817]\n",
      " [ 3.8415452  -1.82514819  9.13115583 ...  0.3777867   0.6996488\n",
      "  -0.26273237]]\n"
     ]
    }
   ],
   "source": [
    "print(X_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1091,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[ 2.81515529 -2.39867401  5.66542471 ...  0.36900056 -0.1246603\n",
      "   0.07862968]\n",
      " [ 2.84188191 -1.89420948  0.10792595 ... -0.28184803 -0.80357005\n",
      "   0.30222688]\n",
      " [-4.6407357  -0.56059659 -0.21440874 ...  0.35191414  0.08350152\n",
      "   0.46859202]\n",
      " ...\n",
      " [-3.60017128  0.77364615 -0.59388333 ... -0.22186177 -0.07029444\n",
      "  -0.15169715]\n",
      " [ 3.66627559 -2.98059592  2.46828587 ...  0.43545875 -0.28098249\n",
      "   0.13599173]\n",
      " [ 2.7714826   4.07534974 -3.73233382 ...  2.28801345  0.48994732\n",
      "  -0.22419151]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1092,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[[-3.8845819   0.65643712 -0.0213289  ...  0.28356137 -0.1871374\n",
      "   0.17833302]\n",
      " [-4.04754212 -0.57698529  0.0609847  ...  0.64010924  0.20487844\n",
      "  -0.65435265]\n",
      " [-3.62914434 -0.32193063 -0.75460868 ...  0.45249467 -0.42689509\n",
      "   0.50712167]\n",
      " ...\n",
      " [-4.35941262 -0.51837053 -0.45934686 ...  0.53352694 -0.59794997\n",
      "   0.33805611]\n",
      " [-4.59801611  0.39598001 -0.19308512 ... -0.29584143  2.24377335\n",
      "   1.09539471]\n",
      " [-3.83071435 -0.20358795  0.15808783 ...  0.07165636  0.26965833\n",
      "  -0.68485615]]\n"
     ]
    }
   ],
   "source": [
    "print(X_test_score_new)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1093,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8377, 8) (2095, 8)\n",
      "(8377,) (2095,)\n",
      "(1000, 8) (1000,)\n"
     ]
    }
   ],
   "source": [
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)\n",
    "print(X_test_score_new.shape, y_test_score.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Ensemble"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1094,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.9809037494280239\n",
      "accuracy = 0.9952267303102625%\n",
      "roc_auc_score = 0.9952874646559849\n",
      "F1-score = 0.9951876804619826\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1051,   10],\n",
       "       [   0, 1034]])"
      ]
     },
     "execution_count": 1094,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# assuming we have X_train,X_test,y_train,y_test at this time\n",
    "# I first run Random Forest using random hard coded settings to get a baseline\n",
    "rf = RandomForestClassifier(n_estimators=80,max_depth=7,max_features=3)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "test_score = r2_score(y_test,y_pred)\n",
    "print(test_score)\n",
    "accuracy = (accuracy_score(y_test, y_pred))\n",
    "print(\"accuracy = {}%\".format(accuracy))\n",
    "print(\"roc_auc_score = {}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"F1-score = {}\".format(f1_score(y_test, y_pred)))\n",
    "\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1107,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 100 candidates, totalling 300 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'n_estimators': 148,\n",
       " 'min_samples_split': 5,\n",
       " 'min_samples_leaf': 2,\n",
       " 'max_features': 'sqrt',\n",
       " 'max_depth': 57}"
      ]
     },
     "execution_count": 1107,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "# I then use RandomizedSearchCV to find the optimal hyperparameters\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1500, num = 30)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(5, 100, num = 10)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 7, 10]\n",
    "min_samples_leaf = [2, 5, 7, 10]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf}\n",
    "\n",
    "rf = RandomForestClassifier(class_weight='balanced', random_state=42)\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1108,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "accuracy = 0.9971360381861575%\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier(n_estimators=148,max_depth=57,max_features='sqrt',min_samples_split=5,min_samples_leaf=2,bootstrap=True)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "accuracy = (accuracy_score(y_test, y_pred))\n",
    "print(\"accuracy = {}%\".format(accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1109,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 81 candidates, totalling 405 fits\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "{'bootstrap': True,\n",
       " 'max_depth': 65,\n",
       " 'max_features': 'auto',\n",
       " 'min_samples_leaf': 2,\n",
       " 'min_samples_split': 5,\n",
       " 'n_estimators': 375}"
      ]
     },
     "execution_count": 1109,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we then use the hyperparameters we found from the RandomizedSearchCV to do a second more thorough check around that range\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [65, 68, 71],\n",
    "    'max_features': ['auto'],\n",
    "    'min_samples_leaf': [2, 4, 6],\n",
    "    'min_samples_split': [3, 5, 7],\n",
    "    'n_estimators': [375, 411, 500]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestClassifier()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 5, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1110,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.9885422496568144"
      ]
     },
     "execution_count": 1110,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# we then output the results using the optimal hyperparameters to check that our model has improved\n",
    "rf = RandomForestClassifier(n_estimators=375,max_depth=65,max_features='auto',min_samples_split=5,min_samples_leaf=2,bootstrap=True)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "test_score = r2_score(y_test,y_pred)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1095,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/50\n",
      "419/419 [==============================] - 1s 894us/step - loss: 0.2807 - accuracy: 0.8853 - precision_90: 0.8572 - recall_90: 0.9382 - false_positives_90: 217.3881\n",
      "Epoch 2/50\n",
      "419/419 [==============================] - 0s 789us/step - loss: 0.0462 - accuracy: 0.9858 - precision_90: 0.9872 - recall_90: 0.9847 - false_positives_90: 30.1857\n",
      "Epoch 3/50\n",
      "419/419 [==============================] - 0s 881us/step - loss: 0.0371 - accuracy: 0.9929 - precision_90: 0.9862 - recall_90: 1.0000 - false_positives_90: 27.5119\n",
      "Epoch 4/50\n",
      "419/419 [==============================] - 0s 765us/step - loss: 0.0259 - accuracy: 0.9941 - precision_90: 0.9881 - recall_90: 1.0000 - false_positives_90: 23.2500\n",
      "Epoch 5/50\n",
      "419/419 [==============================] - 0s 752us/step - loss: 0.0251 - accuracy: 0.9951 - precision_90: 0.9904 - recall_90: 1.0000 - false_positives_90: 20.5119\n",
      "Epoch 6/50\n",
      "419/419 [==============================] - 0s 864us/step - loss: 0.0217 - accuracy: 0.9949 - precision_90: 0.9899 - recall_90: 1.0000 - false_positives_90: 22.5786\n",
      "Epoch 7/50\n",
      "419/419 [==============================] - 0s 823us/step - loss: 0.0235 - accuracy: 0.9956 - precision_90: 0.9911 - recall_90: 1.0000 - false_positives_90: 19.1262\n",
      "Epoch 8/50\n",
      "419/419 [==============================] - 0s 777us/step - loss: 0.0181 - accuracy: 0.9959 - precision_90: 0.9918 - recall_90: 1.0000 - false_positives_90: 18.0667\n",
      "Epoch 9/50\n",
      "419/419 [==============================] - 0s 816us/step - loss: 0.0199 - accuracy: 0.9950 - precision_90: 0.9902 - recall_90: 1.0000 - false_positives_90: 21.3238\n",
      "Epoch 10/50\n",
      "419/419 [==============================] - 0s 770us/step - loss: 0.0196 - accuracy: 0.9950 - precision_90: 0.9902 - recall_90: 1.0000 - false_positives_90: 18.3810\n",
      "Epoch 11/50\n",
      "419/419 [==============================] - 0s 748us/step - loss: 0.0203 - accuracy: 0.9961 - precision_90: 0.9922 - recall_90: 1.0000 - false_positives_90: 16.3048\n",
      "Epoch 12/50\n",
      "419/419 [==============================] - 0s 805us/step - loss: 0.0167 - accuracy: 0.9967 - precision_90: 0.9934 - recall_90: 1.0000 - false_positives_90: 15.3952\n",
      "Epoch 13/50\n",
      "419/419 [==============================] - 0s 855us/step - loss: 0.0123 - accuracy: 0.9970 - precision_90: 0.9940 - recall_90: 1.0000 - false_positives_90: 14.0881\n",
      "Epoch 14/50\n",
      "419/419 [==============================] - 0s 748us/step - loss: 0.0152 - accuracy: 0.9973 - precision_90: 0.9947 - recall_90: 1.0000 - false_positives_90: 13.3476\n",
      "Epoch 15/50\n",
      "419/419 [==============================] - 0s 771us/step - loss: 0.0147 - accuracy: 0.9968 - precision_90: 0.9936 - recall_90: 1.0000 - false_positives_90: 14.7786\n",
      "Epoch 16/50\n",
      "419/419 [==============================] - 0s 770us/step - loss: 0.0155 - accuracy: 0.9966 - precision_90: 0.9931 - recall_90: 1.0000 - false_positives_90: 15.0500\n",
      "Epoch 17/50\n",
      "419/419 [==============================] - 0s 755us/step - loss: 0.0187 - accuracy: 0.9960 - precision_90: 0.9920 - recall_90: 1.0000 - false_positives_90: 15.3429\n",
      "Epoch 18/50\n",
      "419/419 [==============================] - 0s 810us/step - loss: 0.0195 - accuracy: 0.9964 - precision_90: 0.9928 - recall_90: 1.0000 - false_positives_90: 12.6571\n",
      "Epoch 19/50\n",
      "419/419 [==============================] - 0s 734us/step - loss: 0.0160 - accuracy: 0.9961 - precision_90: 0.9919 - recall_90: 1.0000 - false_positives_90: 13.2571\n",
      "Epoch 20/50\n",
      "419/419 [==============================] - 0s 771us/step - loss: 0.0152 - accuracy: 0.9962 - precision_90: 0.9926 - recall_90: 1.0000 - false_positives_90: 14.9857\n",
      "Epoch 21/50\n",
      "419/419 [==============================] - 0s 805us/step - loss: 0.0127 - accuracy: 0.9976 - precision_90: 0.9952 - recall_90: 1.0000 - false_positives_90: 11.1357\n",
      "Epoch 22/50\n",
      "419/419 [==============================] - 0s 781us/step - loss: 0.0150 - accuracy: 0.9969 - precision_90: 0.9939 - recall_90: 1.0000 - false_positives_90: 12.2262\n",
      "Epoch 23/50\n",
      "419/419 [==============================] - 0s 772us/step - loss: 0.0132 - accuracy: 0.9977 - precision_90: 0.9955 - recall_90: 1.0000 - false_positives_90: 9.2786\n",
      "Epoch 24/50\n",
      "419/419 [==============================] - 0s 810us/step - loss: 0.0127 - accuracy: 0.9975 - precision_90: 0.9951 - recall_90: 1.0000 - false_positives_90: 10.9667\n",
      "Epoch 25/50\n",
      "419/419 [==============================] - 0s 765us/step - loss: 0.0136 - accuracy: 0.9972 - precision_90: 0.9945 - recall_90: 1.0000 - false_positives_90: 11.4167\n",
      "Epoch 26/50\n",
      "419/419 [==============================] - 0s 769us/step - loss: 0.0108 - accuracy: 0.9979 - precision_90: 0.9959 - recall_90: 1.0000 - false_positives_90: 10.0786\n",
      "Epoch 27/50\n",
      "419/419 [==============================] - 0s 785us/step - loss: 0.0100 - accuracy: 0.9983 - precision_90: 0.9966 - recall_90: 1.0000 - false_positives_90: 8.2571\n",
      "Epoch 28/50\n",
      "419/419 [==============================] - 0s 783us/step - loss: 0.0061 - accuracy: 0.9989 - precision_90: 0.9978 - recall_90: 1.0000 - false_positives_90: 6.4500\n",
      "Epoch 29/50\n",
      "419/419 [==============================] - 0s 764us/step - loss: 0.0084 - accuracy: 0.9984 - precision_90: 0.9977 - recall_90: 0.9991 - false_positives_90: 6.1143\n",
      "Epoch 30/50\n",
      "419/419 [==============================] - 0s 799us/step - loss: 0.0075 - accuracy: 0.9985 - precision_90: 0.9971 - recall_90: 1.0000 - false_positives_90: 7.3333\n",
      "Epoch 31/50\n",
      "419/419 [==============================] - 0s 761us/step - loss: 0.0100 - accuracy: 0.9983 - precision_90: 0.9966 - recall_90: 1.0000 - false_positives_90: 8.5095\n",
      "Epoch 32/50\n",
      "419/419 [==============================] - 0s 766us/step - loss: 0.0083 - accuracy: 0.9983 - precision_90: 0.9967 - recall_90: 1.0000 - false_positives_90: 7.3714\n",
      "Epoch 33/50\n",
      "419/419 [==============================] - 0s 789us/step - loss: 0.0092 - accuracy: 0.9981 - precision_90: 0.9970 - recall_90: 0.9993 - false_positives_90: 7.6048\n",
      "Epoch 34/50\n",
      "419/419 [==============================] - 0s 813us/step - loss: 0.0101 - accuracy: 0.9984 - precision_90: 0.9968 - recall_90: 1.0000 - false_positives_90: 7.5643\n",
      "Epoch 35/50\n",
      "419/419 [==============================] - 0s 779us/step - loss: 0.0135 - accuracy: 0.9972 - precision_90: 0.9946 - recall_90: 1.0000 - false_positives_90: 10.0738\n",
      "Epoch 36/50\n",
      "419/419 [==============================] - 0s 774us/step - loss: 0.0117 - accuracy: 0.9975 - precision_90: 0.9950 - recall_90: 1.0000 - false_positives_90: 9.0262\n",
      "Epoch 37/50\n",
      "419/419 [==============================] - 0s 780us/step - loss: 0.0053 - accuracy: 0.9991 - precision_90: 0.9981 - recall_90: 1.0000 - false_positives_90: 5.2476\n",
      "Epoch 38/50\n",
      "419/419 [==============================] - 0s 732us/step - loss: 0.0080 - accuracy: 0.9984 - precision_90: 0.9970 - recall_90: 0.9997 - false_positives_90: 6.8810\n",
      "Epoch 39/50\n",
      "419/419 [==============================] - 0s 757us/step - loss: 0.0086 - accuracy: 0.9984 - precision_90: 0.9968 - recall_90: 1.0000 - false_positives_90: 7.4976\n",
      "Epoch 40/50\n",
      "419/419 [==============================] - 0s 787us/step - loss: 0.0058 - accuracy: 0.9991 - precision_90: 0.9983 - recall_90: 0.9999 - false_positives_90: 5.0143\n",
      "Epoch 41/50\n",
      "419/419 [==============================] - 0s 735us/step - loss: 0.0100 - accuracy: 0.9979 - precision_90: 0.9958 - recall_90: 1.0000 - false_positives_90: 9.7190\n",
      "Epoch 42/50\n",
      "419/419 [==============================] - 0s 729us/step - loss: 0.0073 - accuracy: 0.9981 - precision_90: 0.9966 - recall_90: 0.9996 - false_positives_90: 7.4167\n",
      "Epoch 43/50\n",
      "419/419 [==============================] - 0s 765us/step - loss: 0.0070 - accuracy: 0.9988 - precision_90: 0.9976 - recall_90: 1.0000 - false_positives_90: 6.0952\n",
      "Epoch 44/50\n",
      "419/419 [==============================] - 0s 712us/step - loss: 0.0065 - accuracy: 0.9985 - precision_90: 0.9971 - recall_90: 1.0000 - false_positives_90: 6.4238\n",
      "Epoch 45/50\n",
      "419/419 [==============================] - 0s 733us/step - loss: 0.0098 - accuracy: 0.9980 - precision_90: 0.9963 - recall_90: 0.9999 - false_positives_90: 7.5190\n",
      "Epoch 46/50\n",
      "419/419 [==============================] - 0s 896us/step - loss: 0.0089 - accuracy: 0.9982 - precision_90: 0.9966 - recall_90: 0.9999 - false_positives_90: 7.3833\n",
      "Epoch 47/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419/419 [==============================] - 0s 740us/step - loss: 0.0068 - accuracy: 0.9988 - precision_90: 0.9977 - recall_90: 1.0000 - false_positives_90: 4.9429\n",
      "Epoch 48/50\n",
      "419/419 [==============================] - 0s 724us/step - loss: 0.0061 - accuracy: 0.9988 - precision_90: 0.9978 - recall_90: 0.9999 - false_positives_90: 4.9833\n",
      "Epoch 49/50\n",
      "419/419 [==============================] - 0s 762us/step - loss: 0.0074 - accuracy: 0.9987 - precision_90: 0.9974 - recall_90: 1.0000 - false_positives_90: 6.3405\n",
      "Epoch 50/50\n",
      "419/419 [==============================] - 0s 713us/step - loss: 0.0071 - accuracy: 0.9987 - precision_90: 0.9975 - recall_90: 1.0000 - false_positives_90: 4.8738\n",
      "accuracy = 0.9966587112171837%\n",
      "roc_auc_score = 0.9967012252591895\n",
      "F1-score = 0.9966265060240964\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1054,    7],\n",
       "       [   0, 1034]])"
      ]
     },
     "execution_count": 1095,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Neural network\n",
    "def create_model():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(16, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dense(12, activation='relu'))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(),\n",
    "                                                                        keras.metrics.Recall(), \n",
    "                                                                         keras.metrics.FalsePositives()])\n",
    "    return model\n",
    "\n",
    "model = create_model()\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=20, epochs=50)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "accuracy = (accuracy_score(y_test, y_pred))\n",
    "print(\"accuracy = {}%\".format(accuracy))\n",
    "print(\"roc_auc_score = {}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"F1-score = {}\".format(f1_score(y_test, y_pred)))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1096,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1000\n",
      "accuracy = 0.915%\n",
      "roc_auc_score = 0.7200713783497539\n",
      "F1-score = 0.5812807881773399\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[856,  15],\n",
       "       [ 70,  59]])"
      ]
     },
     "execution_count": 1096,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred = model.predict(X_test_score_new)\n",
    "y_pred = (y_pred > 0.5)\n",
    "print(len(y_pred))\n",
    "accuracy = (accuracy_score(y_test_score, y_pred))\n",
    "print(\"accuracy = {}%\".format(accuracy))\n",
    "print(\"roc_auc_score = {}\".format(roc_auc_score(y_test_score, y_pred)))\n",
    "print(\"F1-score = {}\".format(f1_score(y_test_score, y_pred)))\n",
    "confusion_matrix(y_test_score, y_pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Cross-Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1097,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95) # Create an instance of PCA model\n",
    "pca.fit(X) # Fit X_train to PCA\n",
    "X_pca = pca.transform(X) # transform training data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1098,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RF Accuracy: 99.56%\n",
      "NN Accuracy: 99.72%\n"
     ]
    }
   ],
   "source": [
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from keras.wrappers.scikit_learn import KerasClassifier\n",
    "\n",
    "kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "rf_model_kfold = RandomForestClassifier(n_estimators=80,max_depth=7,max_features=3)\n",
    "\n",
    "rf_results_kfold = cross_val_score(rf_model_kfold, X_pca, y, cv=kfold)\n",
    "\n",
    "print(\"RF Accuracy: %.2f%%\" % (rf_results_kfold.mean()*100.0)) \n",
    "\n",
    "nn = KerasClassifier(build_fn=create_model, epochs=50, batch_size=20, verbose=0)\n",
    "\n",
    "nn_results_kfold = cross_val_score(nn, X_pca, y, cv=kfold)\n",
    "\n",
    "print(\"NN Accuracy: %.2f%%\" % (nn_results_kfold.mean()*100.0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 10. Custom Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1099,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "def create_custom_model(train_data, d1, d2):\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim=train_data.shape[1], activation='relu'))\n",
    "    model.add(Dropout(d1))\n",
    "    model.add(Dense(12, activation='selu'))\n",
    "    model.add(Dropout(d2))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(),\n",
    "                                                                        keras.metrics.Recall(), \n",
    "                                                                         keras.metrics.FalsePositives()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1100,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "419/419 [==============================] - 2s 982us/step - loss: 0.4070 - accuracy: 0.8027 - precision_101: 0.7773 - recall_101: 0.8897 - false_positives_101: 351.1857\n",
      "Epoch 2/75\n",
      "419/419 [==============================] - 0s 759us/step - loss: 0.0565 - accuracy: 0.9846 - precision_101: 0.9840 - recall_101: 0.9852 - false_positives_101: 37.2119\n",
      "Epoch 3/75\n",
      "419/419 [==============================] - 0s 838us/step - loss: 0.0446 - accuracy: 0.9917 - precision_101: 0.9847 - recall_101: 0.9986 - false_positives_101: 31.6810\n",
      "Epoch 4/75\n",
      "419/419 [==============================] - 0s 788us/step - loss: 0.0445 - accuracy: 0.9893 - precision_101: 0.9828 - recall_101: 0.9960 - false_positives_101: 33.6905\n",
      "Epoch 5/75\n",
      "419/419 [==============================] - 0s 792us/step - loss: 0.0382 - accuracy: 0.9926 - precision_101: 0.9863 - recall_101: 0.9988 - false_positives_101: 25.6048\n",
      "Epoch 6/75\n",
      "419/419 [==============================] - 0s 814us/step - loss: 0.0306 - accuracy: 0.9936 - precision_101: 0.9887 - recall_101: 0.9989 - false_positives_101: 23.2929\n",
      "Epoch 7/75\n",
      "419/419 [==============================] - 0s 761us/step - loss: 0.0298 - accuracy: 0.9934 - precision_101: 0.9886 - recall_101: 0.9983 - false_positives_101: 23.4667\n",
      "Epoch 8/75\n",
      "419/419 [==============================] - 0s 837us/step - loss: 0.0289 - accuracy: 0.9934 - precision_101: 0.9883 - recall_101: 0.9983 - false_positives_101: 22.4952\n",
      "Epoch 9/75\n",
      "419/419 [==============================] - 0s 825us/step - loss: 0.0216 - accuracy: 0.9950 - precision_101: 0.9906 - recall_101: 0.9995 - false_positives_101: 21.0190\n",
      "Epoch 10/75\n",
      "419/419 [==============================] - 0s 789us/step - loss: 0.0292 - accuracy: 0.9941 - precision_101: 0.9890 - recall_101: 0.9994 - false_positives_101: 21.3119\n",
      "Epoch 11/75\n",
      "419/419 [==============================] - 0s 835us/step - loss: 0.0265 - accuracy: 0.9941 - precision_101: 0.9888 - recall_101: 0.9996 - false_positives_101: 19.7619\n",
      "Epoch 12/75\n",
      "419/419 [==============================] - 0s 877us/step - loss: 0.0192 - accuracy: 0.9956 - precision_101: 0.9924 - recall_101: 0.9987 - false_positives_101: 17.9286\n",
      "Epoch 13/75\n",
      "419/419 [==============================] - 0s 859us/step - loss: 0.0214 - accuracy: 0.9954 - precision_101: 0.9911 - recall_101: 1.0000 - false_positives_101: 16.3905\n",
      "Epoch 14/75\n",
      "419/419 [==============================] - 0s 823us/step - loss: 0.0217 - accuracy: 0.9952 - precision_101: 0.9914 - recall_101: 0.9993 - false_positives_101: 18.0619\n",
      "Epoch 15/75\n",
      "419/419 [==============================] - 0s 844us/step - loss: 0.0168 - accuracy: 0.9966 - precision_101: 0.9938 - recall_101: 0.9993 - false_positives_101: 15.3000\n",
      "Epoch 16/75\n",
      "419/419 [==============================] - 0s 795us/step - loss: 0.0188 - accuracy: 0.9961 - precision_101: 0.9926 - recall_101: 0.9998 - false_positives_101: 17.0786\n",
      "Epoch 17/75\n",
      "419/419 [==============================] - 0s 773us/step - loss: 0.0224 - accuracy: 0.9947 - precision_101: 0.9921 - recall_101: 0.9974 - false_positives_101: 17.7714\n",
      "Epoch 18/75\n",
      "419/419 [==============================] - 0s 847us/step - loss: 0.0286 - accuracy: 0.9937 - precision_101: 0.9875 - recall_101: 0.9999 - false_positives_101: 20.4786\n",
      "Epoch 19/75\n",
      "419/419 [==============================] - 0s 874us/step - loss: 0.0177 - accuracy: 0.9958 - precision_101: 0.9918 - recall_101: 0.9996 - false_positives_101: 15.0405\n",
      "Epoch 20/75\n",
      "419/419 [==============================] - 0s 773us/step - loss: 0.0169 - accuracy: 0.9960 - precision_101: 0.9922 - recall_101: 0.9999 - false_positives_101: 14.4905\n",
      "Epoch 21/75\n",
      "419/419 [==============================] - 0s 873us/step - loss: 0.0157 - accuracy: 0.9966 - precision_101: 0.9938 - recall_101: 0.9996 - false_positives_101: 13.2167\n",
      "Epoch 22/75\n",
      "419/419 [==============================] - 0s 821us/step - loss: 0.0120 - accuracy: 0.9977 - precision_101: 0.9959 - recall_101: 0.9995 - false_positives_101: 10.5333\n",
      "Epoch 23/75\n",
      "419/419 [==============================] - 0s 785us/step - loss: 0.0203 - accuracy: 0.9952 - precision_101: 0.9912 - recall_101: 0.9993 - false_positives_101: 15.8905\n",
      "Epoch 24/75\n",
      "419/419 [==============================] - 0s 787us/step - loss: 0.0162 - accuracy: 0.9971 - precision_101: 0.9944 - recall_101: 0.9999 - false_positives_101: 14.2095\n",
      "Epoch 25/75\n",
      "419/419 [==============================] - 0s 771us/step - loss: 0.0191 - accuracy: 0.9957 - precision_101: 0.9923 - recall_101: 0.9992 - false_positives_101: 15.8786\n",
      "Epoch 26/75\n",
      "419/419 [==============================] - 0s 797us/step - loss: 0.0162 - accuracy: 0.9968 - precision_101: 0.9937 - recall_101: 0.9999 - false_positives_101: 12.0667\n",
      "Epoch 27/75\n",
      "419/419 [==============================] - 0s 1ms/step - loss: 0.0135 - accuracy: 0.9972 - precision_101: 0.9950 - recall_101: 0.9994 - false_positives_101: 13.3476\n",
      "Epoch 28/75\n",
      "419/419 [==============================] - 0s 793us/step - loss: 0.0134 - accuracy: 0.9966 - precision_101: 0.9944 - recall_101: 0.9988 - false_positives_101: 11.1167\n",
      "Epoch 29/75\n",
      "419/419 [==============================] - 0s 853us/step - loss: 0.0156 - accuracy: 0.9967 - precision_101: 0.9934 - recall_101: 0.9999 - false_positives_101: 14.6762\n",
      "Epoch 30/75\n",
      "419/419 [==============================] - 0s 861us/step - loss: 0.0172 - accuracy: 0.9970 - precision_101: 0.9940 - recall_101: 1.0000 - false_positives_101: 13.4143\n",
      "Epoch 31/75\n",
      "419/419 [==============================] - 0s 784us/step - loss: 0.0139 - accuracy: 0.9970 - precision_101: 0.9945 - recall_101: 0.9996 - false_positives_101: 12.6952\n",
      "Epoch 32/75\n",
      "419/419 [==============================] - 0s 793us/step - loss: 0.0155 - accuracy: 0.9958 - precision_101: 0.9929 - recall_101: 0.9988 - false_positives_101: 15.1143\n",
      "Epoch 33/75\n",
      "419/419 [==============================] - 0s 842us/step - loss: 0.0122 - accuracy: 0.9968 - precision_101: 0.9946 - recall_101: 0.9992 - false_positives_101: 12.9786\n",
      "Epoch 34/75\n",
      "419/419 [==============================] - 0s 797us/step - loss: 0.0127 - accuracy: 0.9965 - precision_101: 0.9942 - recall_101: 0.9988 - false_positives_101: 14.6000\n",
      "Epoch 35/75\n",
      "419/419 [==============================] - 0s 818us/step - loss: 0.0160 - accuracy: 0.9969 - precision_101: 0.9940 - recall_101: 0.9999 - false_positives_101: 12.9262\n",
      "Epoch 36/75\n",
      "419/419 [==============================] - 0s 981us/step - loss: 0.0161 - accuracy: 0.9962 - precision_101: 0.9930 - recall_101: 0.9996 - false_positives_101: 12.9643\n",
      "Epoch 37/75\n",
      "419/419 [==============================] - 0s 789us/step - loss: 0.0161 - accuracy: 0.9967 - precision_101: 0.9938 - recall_101: 0.9996 - false_positives_101: 13.0667\n",
      "Epoch 38/75\n",
      "419/419 [==============================] - 0s 802us/step - loss: 0.0092 - accuracy: 0.9987 - precision_101: 0.9974 - recall_101: 1.0000 - false_positives_101: 6.7833\n",
      "Epoch 39/75\n",
      "419/419 [==============================] - 0s 798us/step - loss: 0.0112 - accuracy: 0.9980 - precision_101: 0.9961 - recall_101: 1.0000 - false_positives_101: 10.2595\n",
      "Epoch 40/75\n",
      "419/419 [==============================] - 0s 798us/step - loss: 0.0108 - accuracy: 0.9976 - precision_101: 0.9961 - recall_101: 0.9991 - false_positives_101: 9.9571\n",
      "Epoch 41/75\n",
      "419/419 [==============================] - 0s 819us/step - loss: 0.0124 - accuracy: 0.9976 - precision_101: 0.9952 - recall_101: 1.0000 - false_positives_101: 10.5929\n",
      "Epoch 42/75\n",
      "419/419 [==============================] - 0s 775us/step - loss: 0.0128 - accuracy: 0.9976 - precision_101: 0.9953 - recall_101: 1.0000 - false_positives_101: 11.1714\n",
      "Epoch 43/75\n",
      "419/419 [==============================] - 0s 779us/step - loss: 0.0121 - accuracy: 0.9973 - precision_101: 0.9955 - recall_101: 0.9992 - false_positives_101: 11.1810\n",
      "Epoch 44/75\n",
      "419/419 [==============================] - 0s 905us/step - loss: 0.0139 - accuracy: 0.9966 - precision_101: 0.9938 - recall_101: 0.9996 - false_positives_101: 13.2738\n",
      "Epoch 45/75\n",
      "419/419 [==============================] - 0s 827us/step - loss: 0.0160 - accuracy: 0.9962 - precision_101: 0.9925 - recall_101: 1.0000 - false_positives_101: 12.4881\n",
      "Epoch 46/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "419/419 [==============================] - 0s 801us/step - loss: 0.0185 - accuracy: 0.9968 - precision_101: 0.9939 - recall_101: 0.9999 - false_positives_101: 13.3786\n",
      "Epoch 47/75\n",
      "419/419 [==============================] - 0s 831us/step - loss: 0.0158 - accuracy: 0.9970 - precision_101: 0.9941 - recall_101: 1.0000 - false_positives_101: 12.7571\n",
      "Epoch 48/75\n",
      "419/419 [==============================] - 0s 856us/step - loss: 0.0104 - accuracy: 0.9977 - precision_101: 0.9959 - recall_101: 0.9996 - false_positives_101: 10.2048\n",
      "Epoch 49/75\n",
      "419/419 [==============================] - 0s 813us/step - loss: 0.0185 - accuracy: 0.9962 - precision_101: 0.9931 - recall_101: 0.9994 - false_positives_101: 12.3524\n",
      "Epoch 50/75\n",
      "419/419 [==============================] - 0s 874us/step - loss: 0.0184 - accuracy: 0.9957 - precision_101: 0.9932 - recall_101: 0.9985 - false_positives_101: 13.7857\n",
      "Epoch 51/75\n",
      "419/419 [==============================] - 0s 798us/step - loss: 0.0186 - accuracy: 0.9962 - precision_101: 0.9932 - recall_101: 0.9991 - false_positives_101: 12.1190\n",
      "Epoch 52/75\n",
      "419/419 [==============================] - 0s 799us/step - loss: 0.0142 - accuracy: 0.9969 - precision_101: 0.9940 - recall_101: 0.9998 - false_positives_101: 13.9952\n",
      "Epoch 53/75\n",
      "419/419 [==============================] - 0s 804us/step - loss: 0.0135 - accuracy: 0.9969 - precision_101: 0.9945 - recall_101: 0.9994 - false_positives_101: 11.5048\n",
      "Epoch 54/75\n",
      "419/419 [==============================] - 0s 754us/step - loss: 0.0093 - accuracy: 0.9981 - precision_101: 0.9966 - recall_101: 0.9996 - false_positives_101: 8.1476\n",
      "Epoch 55/75\n",
      "419/419 [==============================] - 0s 767us/step - loss: 0.0110 - accuracy: 0.9973 - precision_101: 0.9954 - recall_101: 0.9993 - false_positives_101: 10.4571\n",
      "Epoch 56/75\n",
      "419/419 [==============================] - 0s 808us/step - loss: 0.0105 - accuracy: 0.9978 - precision_101: 0.9959 - recall_101: 0.9996 - false_positives_101: 9.3262\n",
      "Epoch 57/75\n",
      "419/419 [==============================] - 0s 823us/step - loss: 0.0129 - accuracy: 0.9966 - precision_101: 0.9934 - recall_101: 1.0000 - false_positives_101: 11.6833\n",
      "Epoch 58/75\n",
      "419/419 [==============================] - 0s 835us/step - loss: 0.0100 - accuracy: 0.9976 - precision_101: 0.9958 - recall_101: 0.9994 - false_positives_101: 9.9214\n",
      "Epoch 59/75\n",
      "419/419 [==============================] - 0s 771us/step - loss: 0.0168 - accuracy: 0.9963 - precision_101: 0.9938 - recall_101: 0.9989 - false_positives_101: 11.9048\n",
      "Epoch 60/75\n",
      "419/419 [==============================] - 0s 762us/step - loss: 0.0107 - accuracy: 0.9981 - precision_101: 0.9966 - recall_101: 0.9997 - false_positives_101: 8.0738\n",
      "Epoch 61/75\n",
      "419/419 [==============================] - 0s 866us/step - loss: 0.0113 - accuracy: 0.9978 - precision_101: 0.9962 - recall_101: 0.9995 - false_positives_101: 9.4333\n",
      "Epoch 62/75\n",
      "419/419 [==============================] - 0s 762us/step - loss: 0.0092 - accuracy: 0.9982 - precision_101: 0.9965 - recall_101: 1.0000 - false_positives_101: 9.2714\n",
      "Epoch 63/75\n",
      "419/419 [==============================] - 0s 799us/step - loss: 0.0089 - accuracy: 0.9976 - precision_101: 0.9958 - recall_101: 0.9994 - false_positives_101: 9.8643\n",
      "Epoch 64/75\n",
      "419/419 [==============================] - 0s 823us/step - loss: 0.0127 - accuracy: 0.9968 - precision_101: 0.9942 - recall_101: 0.9993 - false_positives_101: 12.5405\n",
      "Epoch 65/75\n",
      "419/419 [==============================] - 0s 755us/step - loss: 0.0076 - accuracy: 0.9979 - precision_101: 0.9962 - recall_101: 0.9996 - false_positives_101: 9.6071\n",
      "Epoch 66/75\n",
      "419/419 [==============================] - 0s 923us/step - loss: 0.0122 - accuracy: 0.9977 - precision_101: 0.9956 - recall_101: 0.9999 - false_positives_101: 9.6333\n",
      "Epoch 67/75\n",
      "419/419 [==============================] - 0s 813us/step - loss: 0.0116 - accuracy: 0.9975 - precision_101: 0.9953 - recall_101: 0.9997 - false_positives_101: 9.8071\n",
      "Epoch 68/75\n",
      "419/419 [==============================] - 0s 828us/step - loss: 0.0104 - accuracy: 0.9977 - precision_101: 0.9962 - recall_101: 0.9992 - false_positives_101: 8.2476\n",
      "Epoch 69/75\n",
      "419/419 [==============================] - 0s 800us/step - loss: 0.0161 - accuracy: 0.9966 - precision_101: 0.9936 - recall_101: 0.9998 - false_positives_101: 12.1762\n",
      "Epoch 70/75\n",
      "419/419 [==============================] - 0s 820us/step - loss: 0.0096 - accuracy: 0.9978 - precision_101: 0.9960 - recall_101: 0.9997 - false_positives_101: 8.6214\n",
      "Epoch 71/75\n",
      "419/419 [==============================] - 0s 769us/step - loss: 0.0109 - accuracy: 0.9973 - precision_101: 0.9957 - recall_101: 0.9989 - false_positives_101: 9.9952\n",
      "Epoch 72/75\n",
      "419/419 [==============================] - 0s 769us/step - loss: 0.0097 - accuracy: 0.9985 - precision_101: 0.9973 - recall_101: 0.9998 - false_positives_101: 7.1310\n",
      "Epoch 73/75\n",
      "419/419 [==============================] - 0s 817us/step - loss: 0.0070 - accuracy: 0.9984 - precision_101: 0.9972 - recall_101: 0.9994 - false_positives_101: 7.1833\n",
      "Epoch 74/75\n",
      "419/419 [==============================] - 0s 779us/step - loss: 0.0091 - accuracy: 0.9978 - precision_101: 0.9956 - recall_101: 0.9999 - false_positives_101: 9.9643\n",
      "Epoch 75/75\n",
      "419/419 [==============================] - 0s 778us/step - loss: 0.0121 - accuracy: 0.9976 - precision_101: 0.9959 - recall_101: 0.9994 - false_positives_101: 9.7190\n",
      "accuracy = 0.9976133651551312%\n",
      "roc_auc_score = 0.9976437323279925\n",
      "F1-score = 0.9975880366618427\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([[1056,    5],\n",
       "       [   0, 1034]])"
      ]
     },
     "execution_count": 1100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model = create_custom_model(X_train, 0.2, 0.1)\n",
    "\n",
    "model.fit(X_train, y_train, batch_size=20, epochs=75)\n",
    "\n",
    "y_pred = model.predict(X_test)\n",
    "y_pred = (y_pred > 0.5)\n",
    "accuracy = (accuracy_score(y_test, y_pred))\n",
    "print(\"accuracy = {}%\".format(accuracy))\n",
    "print(\"roc_auc_score = {}\".format(roc_auc_score(y_test, y_pred)))\n",
    "print(\"F1-score = {}\".format(f1_score(y_test, y_pred)))\n",
    "confusion_matrix(y_test, y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1101,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Neural network\n",
    "def create_custom_model_cv():\n",
    "    model = Sequential()\n",
    "    model.add(Dense(25, input_dim=X_train.shape[1], activation='relu'))\n",
    "    model.add(Dropout(0.2))\n",
    "    model.add(Dense(12, activation='selu'))\n",
    "    model.add(Dropout(0.1))\n",
    "    model.add(Dense(4, activation='relu'))\n",
    "#     model.add(Dropout(0.2))\n",
    "    model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "    model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy', keras.metrics.Precision(),\n",
    "                                                                        keras.metrics.Recall(), \n",
    "                                                                         keras.metrics.FalsePositives()])\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1102,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Custom NN Accuracy: 99.66%\n"
     ]
    }
   ],
   "source": [
    "kfold = KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "custom_nn = KerasClassifier(build_fn=create_custom_model_cv, epochs=50, batch_size=20, verbose=0)\n",
    "\n",
    "custom_nn_results_kfold = cross_val_score(custom_nn, X_pca, y, cv=kfold)\n",
    "\n",
    "print(\"Custom NN Accuracy: %.2f%%\" % (custom_nn_results_kfold.mean()*100.0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1103,
   "metadata": {},
   "outputs": [],
   "source": [
    "pca = PCA(n_components=0.95) # Create an instance of PCA model\n",
    "pca.fit(X) # Fit X_train to PCA\n",
    "X_pca = pca.transform(X)\n",
    "X_test_score_kaggle = pca.transform(X_test_score) # transform score test data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1104,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.3442 - accuracy: 0.8264 - precision_112: 0.8644 - recall_112: 0.7681 - false_positives_112: 177.5714\n",
      "Epoch 2/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0463 - accuracy: 0.9885 - precision_112: 0.9848 - recall_112: 0.9924 - false_positives_112: 41.3581\n",
      "Epoch 3/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0397 - accuracy: 0.9918 - precision_112: 0.9852 - recall_112: 0.9986 - false_positives_112: 40.3257\n",
      "Epoch 4/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0303 - accuracy: 0.9937 - precision_112: 0.9888 - recall_112: 0.9990 - false_positives_112: 29.6648\n",
      "Epoch 5/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0320 - accuracy: 0.9938 - precision_112: 0.9885 - recall_112: 0.9994 - false_positives_112: 29.4990\n",
      "Epoch 6/75\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0297 - accuracy: 0.9941 - precision_112: 0.9894 - recall_112: 0.9990 - false_positives_112: 27.4686\n",
      "Epoch 7/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0239 - accuracy: 0.9952 - precision_112: 0.9910 - recall_112: 0.9996 - false_positives_112: 25.0724\n",
      "Epoch 8/75\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0243 - accuracy: 0.9944 - precision_112: 0.9898 - recall_112: 0.9988 - false_positives_112: 28.0019\n",
      "Epoch 9/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0221 - accuracy: 0.9953 - precision_112: 0.9912 - recall_112: 0.9994 - false_positives_112: 22.8552\n",
      "Epoch 10/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0218 - accuracy: 0.9952 - precision_112: 0.9916 - recall_112: 0.9991 - false_positives_112: 23.7390\n",
      "Epoch 11/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0294 - accuracy: 0.9935 - precision_112: 0.9879 - recall_112: 0.9997 - false_positives_112: 28.7486\n",
      "Epoch 12/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0196 - accuracy: 0.9959 - precision_112: 0.9928 - recall_112: 0.9991 - false_positives_112: 19.5714\n",
      "Epoch 13/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0229 - accuracy: 0.9949 - precision_112: 0.9910 - recall_112: 0.9991 - false_positives_112: 22.1143\n",
      "Epoch 14/75\n",
      "524/524 [==============================] - 0s 873us/step - loss: 0.0262 - accuracy: 0.9933 - precision_112: 0.9881 - recall_112: 0.9986 - false_positives_112: 26.6800\n",
      "Epoch 15/75\n",
      "524/524 [==============================] - 1s 957us/step - loss: 0.0209 - accuracy: 0.9952 - precision_112: 0.9907 - recall_112: 0.9996 - false_positives_112: 24.2495\n",
      "Epoch 16/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0207 - accuracy: 0.9956 - precision_112: 0.9916 - recall_112: 0.9996 - false_positives_112: 23.5448\n",
      "Epoch 17/75\n",
      "524/524 [==============================] - 0s 905us/step - loss: 0.0182 - accuracy: 0.9961 - precision_112: 0.9928 - recall_112: 0.9994 - false_positives_112: 21.3086\n",
      "Epoch 18/75\n",
      "524/524 [==============================] - 0s 874us/step - loss: 0.0188 - accuracy: 0.9960 - precision_112: 0.9926 - recall_112: 0.9995 - false_positives_112: 18.9581\n",
      "Epoch 19/75\n",
      "524/524 [==============================] - 0s 881us/step - loss: 0.0180 - accuracy: 0.9960 - precision_112: 0.9928 - recall_112: 0.9992 - false_positives_112: 18.8971\n",
      "Epoch 20/75\n",
      "524/524 [==============================] - 0s 881us/step - loss: 0.0190 - accuracy: 0.9963 - precision_112: 0.9931 - recall_112: 0.9994 - false_positives_112: 18.4514\n",
      "Epoch 21/75\n",
      "524/524 [==============================] - 1s 975us/step - loss: 0.0202 - accuracy: 0.9957 - precision_112: 0.9914 - recall_112: 1.0000 - false_positives_112: 19.4819\n",
      "Epoch 22/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0201 - accuracy: 0.9957 - precision_112: 0.9917 - recall_112: 0.9997 - false_positives_112: 19.1924\n",
      "Epoch 23/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0193 - accuracy: 0.9957 - precision_112: 0.9918 - recall_112: 0.9996 - false_positives_112: 21.2724\n",
      "Epoch 24/75\n",
      "524/524 [==============================] - 0s 899us/step - loss: 0.0191 - accuracy: 0.9958 - precision_112: 0.9923 - recall_112: 0.9995 - false_positives_112: 20.3295\n",
      "Epoch 25/75\n",
      "524/524 [==============================] - 0s 899us/step - loss: 0.0200 - accuracy: 0.9959 - precision_112: 0.9928 - recall_112: 0.9992 - false_positives_112: 18.9943\n",
      "Epoch 26/75\n",
      "524/524 [==============================] - 0s 931us/step - loss: 0.0141 - accuracy: 0.9970 - precision_112: 0.9942 - recall_112: 1.0000 - false_positives_112: 17.0514\n",
      "Epoch 27/75\n",
      "524/524 [==============================] - 0s 910us/step - loss: 0.0196 - accuracy: 0.9957 - precision_112: 0.9918 - recall_112: 0.9997 - false_positives_112: 19.2381\n",
      "Epoch 28/75\n",
      "524/524 [==============================] - 0s 953us/step - loss: 0.0182 - accuracy: 0.9965 - precision_112: 0.9936 - recall_112: 0.9994 - false_positives_112: 17.9505\n",
      "Epoch 29/75\n",
      "524/524 [==============================] - 0s 874us/step - loss: 0.0156 - accuracy: 0.9967 - precision_112: 0.9936 - recall_112: 0.9997 - false_positives_112: 17.0019\n",
      "Epoch 30/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0161 - accuracy: 0.9963 - precision_112: 0.9928 - recall_112: 0.9999 - false_positives_112: 18.7562\n",
      "Epoch 31/75\n",
      "524/524 [==============================] - 0s 948us/step - loss: 0.0163 - accuracy: 0.9969 - precision_112: 0.9942 - recall_112: 0.9996 - false_positives_112: 15.8933\n",
      "Epoch 32/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0116 - accuracy: 0.9977 - precision_112: 0.9954 - recall_112: 1.0000 - false_positives_112: 13.1790\n",
      "Epoch 33/75\n",
      "524/524 [==============================] - 0s 925us/step - loss: 0.0168 - accuracy: 0.9963 - precision_112: 0.9933 - recall_112: 0.9992 - false_positives_112: 16.2857\n",
      "Epoch 34/75\n",
      "524/524 [==============================] - 0s 858us/step - loss: 0.0158 - accuracy: 0.9968 - precision_112: 0.9936 - recall_112: 0.9999 - false_positives_112: 16.7238 0s - loss: 0.0159 - accuracy: 0.9967 - precision_112: 0.9935 - recall_112: 0.9999 - false_positives_112: 13.\n",
      "Epoch 35/75\n",
      "524/524 [==============================] - 0s 863us/step - loss: 0.0147 - accuracy: 0.9969 - precision_112: 0.9944 - recall_112: 0.9995 - false_positives_112: 15.1981\n",
      "Epoch 36/75\n",
      "524/524 [==============================] - 0s 846us/step - loss: 0.0132 - accuracy: 0.9969 - precision_112: 0.9942 - recall_112: 0.9999 - false_positives_112: 15.5429\n",
      "Epoch 37/75\n",
      "524/524 [==============================] - 0s 837us/step - loss: 0.0147 - accuracy: 0.9962 - precision_112: 0.9933 - recall_112: 0.9993 - false_positives_112: 18.0800\n",
      "Epoch 38/75\n",
      "524/524 [==============================] - 0s 838us/step - loss: 0.0115 - accuracy: 0.9976 - precision_112: 0.9952 - recall_112: 1.0000 - false_positives_112: 13.4381\n",
      "Epoch 39/75\n",
      "524/524 [==============================] - 0s 763us/step - loss: 0.0161 - accuracy: 0.9965 - precision_112: 0.9942 - recall_112: 0.9989 - false_positives_112: 16.1162\n",
      "Epoch 40/75\n",
      "524/524 [==============================] - 0s 861us/step - loss: 0.0217 - accuracy: 0.9949 - precision_112: 0.9911 - recall_112: 0.9986 - false_positives_112: 17.7924\n",
      "Epoch 41/75\n",
      "524/524 [==============================] - 0s 774us/step - loss: 0.0113 - accuracy: 0.9978 - precision_112: 0.9958 - recall_112: 1.0000 - false_positives_112: 12.5581\n",
      "Epoch 42/75\n",
      "524/524 [==============================] - 0s 864us/step - loss: 0.0099 - accuracy: 0.9977 - precision_112: 0.9955 - recall_112: 1.0000 - false_positives_112: 14.7086\n",
      "Epoch 43/75\n",
      "524/524 [==============================] - 0s 796us/step - loss: 0.0172 - accuracy: 0.9963 - precision_112: 0.9939 - recall_112: 0.9987 - false_positives_112: 14.8133\n",
      "Epoch 44/75\n",
      "524/524 [==============================] - 0s 775us/step - loss: 0.0133 - accuracy: 0.9971 - precision_112: 0.9946 - recall_112: 0.9996 - false_positives_112: 13.4933\n",
      "Epoch 45/75\n",
      "524/524 [==============================] - 0s 779us/step - loss: 0.0111 - accuracy: 0.9972 - precision_112: 0.9943 - recall_112: 1.0000 - false_positives_112: 13.9238\n",
      "Epoch 46/75\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 0s 853us/step - loss: 0.0149 - accuracy: 0.9972 - precision_112: 0.9944 - recall_112: 1.0000 - false_positives_112: 14.1638\n",
      "Epoch 47/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0140 - accuracy: 0.9970 - precision_112: 0.9943 - recall_112: 0.9999 - false_positives_112: 13.5162\n",
      "Epoch 48/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0120 - accuracy: 0.9967 - precision_112: 0.9943 - recall_112: 0.9991 - false_positives_112: 13.6476\n",
      "Epoch 49/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0096 - accuracy: 0.9984 - precision_112: 0.9970 - recall_112: 0.9998 - false_positives_112: 9.6743\n",
      "Epoch 50/75\n",
      "524/524 [==============================] - 0s 785us/step - loss: 0.0116 - accuracy: 0.9975 - precision_112: 0.9958 - recall_112: 0.9992 - false_positives_112: 12.5257\n",
      "Epoch 51/75\n",
      "524/524 [==============================] - 0s 809us/step - loss: 0.0105 - accuracy: 0.9977 - precision_112: 0.9954 - recall_112: 0.9999 - false_positives_112: 12.7543\n",
      "Epoch 52/75\n",
      "524/524 [==============================] - 0s 872us/step - loss: 0.0097 - accuracy: 0.9979 - precision_112: 0.9959 - recall_112: 0.9999 - false_positives_112: 12.7676\n",
      "Epoch 53/75\n",
      "524/524 [==============================] - 0s 824us/step - loss: 0.0106 - accuracy: 0.9981 - precision_112: 0.9967 - recall_112: 0.9996 - false_positives_112: 9.9848\n",
      "Epoch 54/75\n",
      "524/524 [==============================] - 0s 789us/step - loss: 0.0117 - accuracy: 0.9977 - precision_112: 0.9959 - recall_112: 0.9995 - false_positives_112: 12.0648\n",
      "Epoch 55/75\n",
      "524/524 [==============================] - 0s 811us/step - loss: 0.0133 - accuracy: 0.9965 - precision_112: 0.9935 - recall_112: 0.9994 - false_positives_112: 15.1276\n",
      "Epoch 56/75\n",
      "524/524 [==============================] - 0s 775us/step - loss: 0.0119 - accuracy: 0.9974 - precision_112: 0.9954 - recall_112: 0.9994 - false_positives_112: 12.6438\n",
      "Epoch 57/75\n",
      "524/524 [==============================] - 0s 775us/step - loss: 0.0113 - accuracy: 0.9976 - precision_112: 0.9955 - recall_112: 0.9997 - false_positives_112: 12.6229\n",
      "Epoch 58/75\n",
      "524/524 [==============================] - 0s 865us/step - loss: 0.0108 - accuracy: 0.9974 - precision_112: 0.9958 - recall_112: 0.9990 - false_positives_112: 13.2667\n",
      "Epoch 59/75\n",
      "524/524 [==============================] - 0s 804us/step - loss: 0.0106 - accuracy: 0.9981 - precision_112: 0.9963 - recall_112: 0.9999 - false_positives_112: 11.2248\n",
      "Epoch 60/75\n",
      "524/524 [==============================] - 0s 834us/step - loss: 0.0120 - accuracy: 0.9969 - precision_112: 0.9942 - recall_112: 0.9997 - false_positives_112: 15.0095\n",
      "Epoch 61/75\n",
      "524/524 [==============================] - 0s 838us/step - loss: 0.0149 - accuracy: 0.9975 - precision_112: 0.9951 - recall_112: 0.9999 - false_positives_112: 11.8152\n",
      "Epoch 62/75\n",
      "524/524 [==============================] - 0s 871us/step - loss: 0.0120 - accuracy: 0.9980 - precision_112: 0.9962 - recall_112: 0.9998 - false_positives_112: 11.0857\n",
      "Epoch 63/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0160 - accuracy: 0.9972 - precision_112: 0.9949 - recall_112: 0.9995 - false_positives_112: 13.1600\n",
      "Epoch 64/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0113 - accuracy: 0.9971 - precision_112: 0.9957 - recall_112: 0.9984 - false_positives_112: 11.7105\n",
      "Epoch 65/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0117 - accuracy: 0.9977 - precision_112: 0.9955 - recall_112: 1.0000 - false_positives_112: 11.4190\n",
      "Epoch 66/75\n",
      "524/524 [==============================] - 0s 847us/step - loss: 0.0105 - accuracy: 0.9974 - precision_112: 0.9954 - recall_112: 0.9995 - false_positives_112: 13.3524\n",
      "Epoch 67/75\n",
      "524/524 [==============================] - 0s 831us/step - loss: 0.0149 - accuracy: 0.9965 - precision_112: 0.9936 - recall_112: 0.9993 - false_positives_112: 16.1943\n",
      "Epoch 68/75\n",
      "524/524 [==============================] - 0s 861us/step - loss: 0.0110 - accuracy: 0.9975 - precision_112: 0.9953 - recall_112: 0.9996 - false_positives_112: 14.2533\n",
      "Epoch 69/75\n",
      "524/524 [==============================] - 0s 835us/step - loss: 0.0179 - accuracy: 0.9966 - precision_112: 0.9932 - recall_112: 0.9999 - false_positives_112: 12.7029\n",
      "Epoch 70/75\n",
      "524/524 [==============================] - 0s 861us/step - loss: 0.0133 - accuracy: 0.9976 - precision_112: 0.9953 - recall_112: 0.9999 - false_positives_112: 11.9524\n",
      "Epoch 71/75\n",
      "524/524 [==============================] - 0s 851us/step - loss: 0.0112 - accuracy: 0.9971 - precision_112: 0.9958 - recall_112: 0.9984 - false_positives_112: 12.4171\n",
      "Epoch 72/75\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0157 - accuracy: 0.9968 - precision_112: 0.9945 - recall_112: 0.9991 - false_positives_112: 14.2514\n",
      "Epoch 73/75\n",
      "524/524 [==============================] - 0s 917us/step - loss: 0.0122 - accuracy: 0.9972 - precision_112: 0.9951 - recall_112: 0.9994 - false_positives_112: 12.9581\n",
      "Epoch 74/75\n",
      "524/524 [==============================] - 0s 949us/step - loss: 0.0099 - accuracy: 0.9979 - precision_112: 0.9963 - recall_112: 0.9995 - false_positives_112: 11.1676\n",
      "Epoch 75/75\n",
      "524/524 [==============================] - 0s 817us/step - loss: 0.0172 - accuracy: 0.9963 - precision_112: 0.9933 - recall_112: 0.9993 - false_positives_112: 14.0914\n",
      "Epoch 1/10\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.3865 - accuracy: 0.8202 - precision_113: 0.7762 - recall_113: 0.9461 - false_positives_113: 530.7943\n",
      "Epoch 2/10\n",
      "524/524 [==============================] - 1s 974us/step - loss: 0.0678 - accuracy: 0.9843 - precision_113: 0.9816 - recall_113: 0.9875 - false_positives_113: 53.0324\n",
      "Epoch 3/10\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0621 - accuracy: 0.9865 - precision_113: 0.9824 - recall_113: 0.9909 - false_positives_113: 49.9638\n",
      "Epoch 4/10\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0636 - accuracy: 0.9860 - precision_113: 0.9811 - recall_113: 0.9913 - false_positives_113: 48.8705\n",
      "Epoch 5/10\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0470 - accuracy: 0.9900 - precision_113: 0.9839 - recall_113: 0.9962 - false_positives_113: 40.7714\n",
      "Epoch 6/10\n",
      "524/524 [==============================] - 0s 830us/step - loss: 0.0393 - accuracy: 0.9921 - precision_113: 0.9871 - recall_113: 0.9972 - false_positives_113: 36.6952\n",
      "Epoch 7/10\n",
      "524/524 [==============================] - 0s 799us/step - loss: 0.0430 - accuracy: 0.9912 - precision_113: 0.9855 - recall_113: 0.9969 - false_positives_113: 38.7295\n",
      "Epoch 8/10\n",
      "524/524 [==============================] - 0s 808us/step - loss: 0.0366 - accuracy: 0.9933 - precision_113: 0.9881 - recall_113: 0.9987 - false_positives_113: 29.9352\n",
      "Epoch 9/10\n",
      "524/524 [==============================] - 0s 831us/step - loss: 0.0329 - accuracy: 0.9931 - precision_113: 0.9872 - recall_113: 0.9992 - false_positives_113: 32.5390\n",
      "Epoch 10/10\n",
      "524/524 [==============================] - 0s 813us/step - loss: 0.0354 - accuracy: 0.9928 - precision_113: 0.9879 - recall_113: 0.9980 - false_positives_113: 32.3790\n",
      "Epoch 1/28\n",
      "524/524 [==============================] - 1s 829us/step - loss: 0.3907 - accuracy: 0.8632 - precision_114: 0.9313 - recall_114: 0.7762 - false_positives_114: 96.3810\n",
      "Epoch 2/28\n",
      "524/524 [==============================] - 0s 880us/step - loss: 0.0651 - accuracy: 0.9859 - precision_114: 0.9795 - recall_114: 0.9929 - false_positives_114: 54.8971\n",
      "Epoch 3/28\n",
      "524/524 [==============================] - 0s 810us/step - loss: 0.0448 - accuracy: 0.9920 - precision_114: 0.9871 - recall_114: 0.9970 - false_positives_114: 37.3105\n",
      "Epoch 4/28\n",
      "524/524 [==============================] - 0s 814us/step - loss: 0.0424 - accuracy: 0.9919 - precision_114: 0.9870 - recall_114: 0.9967 - false_positives_114: 33.3562\n",
      "Epoch 5/28\n",
      "524/524 [==============================] - 0s 840us/step - loss: 0.0308 - accuracy: 0.9935 - precision_114: 0.9883 - recall_114: 0.9987 - false_positives_114: 31.0171\n",
      "Epoch 6/28\n",
      "524/524 [==============================] - 0s 788us/step - loss: 0.0253 - accuracy: 0.9953 - precision_114: 0.9913 - recall_114: 0.9994 - false_positives_114: 25.3695\n",
      "Epoch 7/28\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 0s 765us/step - loss: 0.0269 - accuracy: 0.9955 - precision_114: 0.9916 - recall_114: 0.9994 - false_positives_114: 25.8133\n",
      "Epoch 8/28\n",
      "524/524 [==============================] - 0s 791us/step - loss: 0.0300 - accuracy: 0.9950 - precision_114: 0.9906 - recall_114: 0.9994 - false_positives_114: 24.7010\n",
      "Epoch 9/28\n",
      "524/524 [==============================] - 0s 813us/step - loss: 0.0229 - accuracy: 0.9960 - precision_114: 0.9920 - recall_114: 0.9999 - false_positives_114: 23.6076\n",
      "Epoch 10/28\n",
      "524/524 [==============================] - 0s 768us/step - loss: 0.0335 - accuracy: 0.9933 - precision_114: 0.9875 - recall_114: 0.9995 - false_positives_114: 31.1219\n",
      "Epoch 11/28\n",
      "524/524 [==============================] - 0s 802us/step - loss: 0.0277 - accuracy: 0.9951 - precision_114: 0.9916 - recall_114: 0.9989 - false_positives_114: 23.6362\n",
      "Epoch 12/28\n",
      "524/524 [==============================] - 0s 771us/step - loss: 0.0289 - accuracy: 0.9949 - precision_114: 0.9900 - recall_114: 1.0000 - false_positives_114: 24.7924\n",
      "Epoch 13/28\n",
      "524/524 [==============================] - 0s 809us/step - loss: 0.0248 - accuracy: 0.9953 - precision_114: 0.9906 - recall_114: 1.0000 - false_positives_114: 21.9543\n",
      "Epoch 14/28\n",
      "524/524 [==============================] - 0s 797us/step - loss: 0.0284 - accuracy: 0.9956 - precision_114: 0.9911 - recall_114: 1.0000 - false_positives_114: 21.7162\n",
      "Epoch 15/28\n",
      "524/524 [==============================] - 0s 838us/step - loss: 0.0253 - accuracy: 0.9947 - precision_114: 0.9904 - recall_114: 0.9990 - false_positives_114: 24.3295\n",
      "Epoch 16/28\n",
      "524/524 [==============================] - 0s 750us/step - loss: 0.0204 - accuracy: 0.9970 - precision_114: 0.9942 - recall_114: 0.9999 - false_positives_114: 17.7524\n",
      "Epoch 17/28\n",
      "524/524 [==============================] - 0s 786us/step - loss: 0.0173 - accuracy: 0.9966 - precision_114: 0.9946 - recall_114: 0.9988 - false_positives_114: 16.8229\n",
      "Epoch 18/28\n",
      "524/524 [==============================] - 0s 892us/step - loss: 0.0217 - accuracy: 0.9961 - precision_114: 0.9921 - recall_114: 1.0000 - false_positives_114: 20.3181\n",
      "Epoch 19/28\n",
      "524/524 [==============================] - 0s 820us/step - loss: 0.0230 - accuracy: 0.9960 - precision_114: 0.9925 - recall_114: 0.9995 - false_positives_114: 21.1619\n",
      "Epoch 20/28\n",
      "524/524 [==============================] - 0s 809us/step - loss: 0.0225 - accuracy: 0.9959 - precision_114: 0.9921 - recall_114: 0.9999 - false_positives_114: 18.5562\n",
      "Epoch 21/28\n",
      "524/524 [==============================] - 0s 808us/step - loss: 0.0256 - accuracy: 0.9945 - precision_114: 0.9900 - recall_114: 0.9992 - false_positives_114: 22.4933\n",
      "Epoch 22/28\n",
      "524/524 [==============================] - 0s 842us/step - loss: 0.0224 - accuracy: 0.9958 - precision_114: 0.9924 - recall_114: 0.9995 - false_positives_114: 19.2990\n",
      "Epoch 23/28\n",
      "524/524 [==============================] - 0s 839us/step - loss: 0.0188 - accuracy: 0.9961 - precision_114: 0.9929 - recall_114: 0.9994 - false_positives_114: 19.0152\n",
      "Epoch 24/28\n",
      "524/524 [==============================] - 0s 842us/step - loss: 0.0172 - accuracy: 0.9967 - precision_114: 0.9939 - recall_114: 0.9995 - false_positives_114: 17.2800\n",
      "Epoch 25/28\n",
      "524/524 [==============================] - 0s 832us/step - loss: 0.0185 - accuracy: 0.9968 - precision_114: 0.9940 - recall_114: 0.9998 - false_positives_114: 16.5790\n",
      "Epoch 26/28\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0241 - accuracy: 0.9951 - precision_114: 0.9910 - recall_114: 0.9992 - false_positives_114: 22.4400\n",
      "Epoch 27/28\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0105 - accuracy: 0.9984 - precision_114: 0.9969 - recall_114: 0.9999 - false_positives_114: 10.5562\n",
      "Epoch 28/28\n",
      "524/524 [==============================] - 0s 924us/step - loss: 0.0184 - accuracy: 0.9965 - precision_114: 0.9935 - recall_114: 0.9995 - false_positives_114: 17.2838\n",
      "Epoch 1/120\n",
      "524/524 [==============================] - 1s 815us/step - loss: 0.4407 - accuracy: 0.7692 - precision_115: 0.7312 - recall_115: 0.8962 - false_positives_115: 619.8800\n",
      "Epoch 2/120\n",
      "524/524 [==============================] - 0s 811us/step - loss: 0.0978 - accuracy: 0.9761 - precision_115: 0.9771 - recall_115: 0.9748 - false_positives_115: 55.7448\n",
      "Epoch 3/120\n",
      "524/524 [==============================] - 0s 782us/step - loss: 0.0760 - accuracy: 0.9818 - precision_115: 0.9806 - recall_115: 0.9831 - false_positives_115: 51.8686\n",
      "Epoch 4/120\n",
      "524/524 [==============================] - 0s 846us/step - loss: 0.0657 - accuracy: 0.9846 - precision_115: 0.9823 - recall_115: 0.9870 - false_positives_115: 50.3029\n",
      "Epoch 5/120\n",
      "524/524 [==============================] - 0s 844us/step - loss: 0.0549 - accuracy: 0.9865 - precision_115: 0.9827 - recall_115: 0.9905 - false_positives_115: 42.6667\n",
      "Epoch 6/120\n",
      "524/524 [==============================] - 0s 790us/step - loss: 0.0476 - accuracy: 0.9888 - precision_115: 0.9860 - recall_115: 0.9921 - false_positives_115: 37.1257\n",
      "Epoch 7/120\n",
      "524/524 [==============================] - 0s 764us/step - loss: 0.0388 - accuracy: 0.9906 - precision_115: 0.9860 - recall_115: 0.9955 - false_positives_115: 37.6533\n",
      "Epoch 8/120\n",
      "524/524 [==============================] - 0s 840us/step - loss: 0.0335 - accuracy: 0.9922 - precision_115: 0.9888 - recall_115: 0.9959 - false_positives_115: 29.6533\n",
      "Epoch 9/120\n",
      "524/524 [==============================] - 0s 832us/step - loss: 0.0397 - accuracy: 0.9918 - precision_115: 0.9866 - recall_115: 0.9971 - false_positives_115: 34.5257\n",
      "Epoch 10/120\n",
      "524/524 [==============================] - 0s 798us/step - loss: 0.0379 - accuracy: 0.9917 - precision_115: 0.9870 - recall_115: 0.9963 - false_positives_115: 32.3790\n",
      "Epoch 11/120\n",
      "524/524 [==============================] - 0s 797us/step - loss: 0.0275 - accuracy: 0.9936 - precision_115: 0.9901 - recall_115: 0.9973 - false_positives_115: 26.3086\n",
      "Epoch 12/120\n",
      "524/524 [==============================] - 0s 824us/step - loss: 0.0378 - accuracy: 0.9910 - precision_115: 0.9867 - recall_115: 0.9950 - false_positives_115: 32.1600\n",
      "Epoch 13/120\n",
      "524/524 [==============================] - 0s 855us/step - loss: 0.0279 - accuracy: 0.9943 - precision_115: 0.9909 - recall_115: 0.9979 - false_positives_115: 25.0514\n",
      "Epoch 14/120\n",
      "524/524 [==============================] - 0s 865us/step - loss: 0.0307 - accuracy: 0.9939 - precision_115: 0.9903 - recall_115: 0.9976 - false_positives_115: 26.8952\n",
      "Epoch 15/120\n",
      "524/524 [==============================] - 0s 770us/step - loss: 0.0323 - accuracy: 0.9925 - precision_115: 0.9887 - recall_115: 0.9968 - false_positives_115: 29.2514\n",
      "Epoch 16/120\n",
      "524/524 [==============================] - 0s 779us/step - loss: 0.0302 - accuracy: 0.9931 - precision_115: 0.9897 - recall_115: 0.9965 - false_positives_115: 28.3657\n",
      "Epoch 17/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0329 - accuracy: 0.9925 - precision_115: 0.9898 - recall_115: 0.9954 - false_positives_115: 25.8971\n",
      "Epoch 18/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0311 - accuracy: 0.9934 - precision_115: 0.9891 - recall_115: 0.9974 - false_positives_115: 26.9143\n",
      "Epoch 19/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0339 - accuracy: 0.9930 - precision_115: 0.9881 - recall_115: 0.9980 - false_positives_115: 29.2743\n",
      "Epoch 20/120\n",
      "524/524 [==============================] - 1s 967us/step - loss: 0.0275 - accuracy: 0.9940 - precision_115: 0.9915 - recall_115: 0.9964 - false_positives_115: 23.9219\n",
      "Epoch 21/120\n",
      "524/524 [==============================] - 0s 861us/step - loss: 0.0308 - accuracy: 0.9925 - precision_115: 0.9892 - recall_115: 0.9960 - false_positives_115: 26.9410\n",
      "Epoch 22/120\n",
      "524/524 [==============================] - 0s 849us/step - loss: 0.0251 - accuracy: 0.9941 - precision_115: 0.9912 - recall_115: 0.9970 - false_positives_115: 23.7524\n",
      "Epoch 23/120\n",
      "524/524 [==============================] - 0s 830us/step - loss: 0.0306 - accuracy: 0.9937 - precision_115: 0.9903 - recall_115: 0.9974 - false_positives_115: 22.6514\n",
      "Epoch 24/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 0s 898us/step - loss: 0.0286 - accuracy: 0.9941 - precision_115: 0.9900 - recall_115: 0.9983 - false_positives_115: 26.2190\n",
      "Epoch 25/120\n",
      "524/524 [==============================] - 0s 826us/step - loss: 0.0270 - accuracy: 0.9941 - precision_115: 0.9915 - recall_115: 0.9969 - false_positives_115: 23.4610\n",
      "Epoch 26/120\n",
      "524/524 [==============================] - 0s 859us/step - loss: 0.0321 - accuracy: 0.9937 - precision_115: 0.9895 - recall_115: 0.9977 - false_positives_115: 27.0019\n",
      "Epoch 27/120\n",
      "524/524 [==============================] - 0s 824us/step - loss: 0.0248 - accuracy: 0.9946 - precision_115: 0.9916 - recall_115: 0.9975 - false_positives_115: 20.8419\n",
      "Epoch 28/120\n",
      "524/524 [==============================] - 0s 849us/step - loss: 0.0255 - accuracy: 0.9941 - precision_115: 0.9916 - recall_115: 0.9965 - false_positives_115: 24.8248\n",
      "Epoch 29/120\n",
      "524/524 [==============================] - 0s 820us/step - loss: 0.0322 - accuracy: 0.9932 - precision_115: 0.9893 - recall_115: 0.9969 - false_positives_115: 27.7638\n",
      "Epoch 30/120\n",
      "524/524 [==============================] - 0s 825us/step - loss: 0.0331 - accuracy: 0.9931 - precision_115: 0.9884 - recall_115: 0.9978 - false_positives_115: 29.5219\n",
      "Epoch 31/120\n",
      "524/524 [==============================] - 0s 930us/step - loss: 0.0273 - accuracy: 0.9947 - precision_115: 0.9907 - recall_115: 0.9988 - false_positives_115: 25.3733\n",
      "Epoch 32/120\n",
      "524/524 [==============================] - 0s 856us/step - loss: 0.0270 - accuracy: 0.9937 - precision_115: 0.9909 - recall_115: 0.9963 - false_positives_115: 23.3048\n",
      "Epoch 33/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0277 - accuracy: 0.9937 - precision_115: 0.9910 - recall_115: 0.9963 - false_positives_115: 24.1181\n",
      "Epoch 34/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0292 - accuracy: 0.9932 - precision_115: 0.9905 - recall_115: 0.9960 - false_positives_115: 25.7162\n",
      "Epoch 35/120\n",
      "524/524 [==============================] - 0s 752us/step - loss: 0.0303 - accuracy: 0.9925 - precision_115: 0.9895 - recall_115: 0.9956 - false_positives_115: 23.9905\n",
      "Epoch 36/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0263 - accuracy: 0.9946 - precision_115: 0.9916 - recall_115: 0.9977 - false_positives_115: 22.3581\n",
      "Epoch 37/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0229 - accuracy: 0.9952 - precision_115: 0.9929 - recall_115: 0.9975 - false_positives_115: 21.0724\n",
      "Epoch 38/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0218 - accuracy: 0.9945 - precision_115: 0.9928 - recall_115: 0.9961 - false_positives_115: 21.6952\n",
      "Epoch 39/120\n",
      "524/524 [==============================] - 0s 812us/step - loss: 0.0300 - accuracy: 0.9931 - precision_115: 0.9891 - recall_115: 0.9974 - false_positives_115: 27.5829\n",
      "Epoch 40/120\n",
      "524/524 [==============================] - 0s 874us/step - loss: 0.0236 - accuracy: 0.9949 - precision_115: 0.9933 - recall_115: 0.9965 - false_positives_115: 20.7048\n",
      "Epoch 41/120\n",
      "524/524 [==============================] - 0s 800us/step - loss: 0.0307 - accuracy: 0.9935 - precision_115: 0.9907 - recall_115: 0.9965 - false_positives_115: 24.4495\n",
      "Epoch 42/120\n",
      "524/524 [==============================] - 0s 801us/step - loss: 0.0258 - accuracy: 0.9941 - precision_115: 0.9925 - recall_115: 0.9958 - false_positives_115: 20.8686\n",
      "Epoch 43/120\n",
      "524/524 [==============================] - 0s 789us/step - loss: 0.0246 - accuracy: 0.9942 - precision_115: 0.9925 - recall_115: 0.9959 - false_positives_115: 22.0343\n",
      "Epoch 44/120\n",
      "524/524 [==============================] - 0s 808us/step - loss: 0.0281 - accuracy: 0.9937 - precision_115: 0.9913 - recall_115: 0.9960 - false_positives_115: 22.0324\n",
      "Epoch 45/120\n",
      "524/524 [==============================] - 0s 817us/step - loss: 0.0298 - accuracy: 0.9937 - precision_115: 0.9901 - recall_115: 0.9972 - false_positives_115: 26.7429\n",
      "Epoch 46/120\n",
      "524/524 [==============================] - 0s 837us/step - loss: 0.0262 - accuracy: 0.9945 - precision_115: 0.9914 - recall_115: 0.9977 - false_positives_115: 22.1371\n",
      "Epoch 47/120\n",
      "524/524 [==============================] - 0s 750us/step - loss: 0.0232 - accuracy: 0.9952 - precision_115: 0.9927 - recall_115: 0.9977 - false_positives_115: 18.6705\n",
      "Epoch 48/120\n",
      "524/524 [==============================] - 0s 862us/step - loss: 0.0276 - accuracy: 0.9940 - precision_115: 0.9901 - recall_115: 0.9978 - false_positives_115: 22.7600\n",
      "Epoch 49/120\n",
      "524/524 [==============================] - 0s 835us/step - loss: 0.0267 - accuracy: 0.9936 - precision_115: 0.9911 - recall_115: 0.9965 - false_positives_115: 23.5524\n",
      "Epoch 50/120\n",
      "524/524 [==============================] - 0s 798us/step - loss: 0.0298 - accuracy: 0.9943 - precision_115: 0.9908 - recall_115: 0.9978 - false_positives_115: 23.9295\n",
      "Epoch 51/120\n",
      "524/524 [==============================] - 0s 789us/step - loss: 0.0270 - accuracy: 0.9939 - precision_115: 0.9909 - recall_115: 0.9966 - false_positives_115: 19.8514\n",
      "Epoch 52/120\n",
      "524/524 [==============================] - 0s 831us/step - loss: 0.0310 - accuracy: 0.9930 - precision_115: 0.9893 - recall_115: 0.9966 - false_positives_115: 24.1771\n",
      "Epoch 53/120\n",
      "524/524 [==============================] - 0s 788us/step - loss: 0.0309 - accuracy: 0.9940 - precision_115: 0.9901 - recall_115: 0.9980 - false_positives_115: 25.0629\n",
      "Epoch 54/120\n",
      "524/524 [==============================] - 0s 848us/step - loss: 0.0258 - accuracy: 0.9940 - precision_115: 0.9911 - recall_115: 0.9968 - false_positives_115: 23.8210\n",
      "Epoch 55/120\n",
      "524/524 [==============================] - 0s 773us/step - loss: 0.0246 - accuracy: 0.9952 - precision_115: 0.9924 - recall_115: 0.9980 - false_positives_115: 21.4800\n",
      "Epoch 56/120\n",
      "524/524 [==============================] - 0s 755us/step - loss: 0.0315 - accuracy: 0.9926 - precision_115: 0.9896 - recall_115: 0.9958 - false_positives_115: 26.4038\n",
      "Epoch 57/120\n",
      "524/524 [==============================] - 0s 829us/step - loss: 0.0293 - accuracy: 0.9933 - precision_115: 0.9897 - recall_115: 0.9971 - false_positives_115: 25.9638\n",
      "Epoch 58/120\n",
      "524/524 [==============================] - 0s 810us/step - loss: 0.0235 - accuracy: 0.9947 - precision_115: 0.9921 - recall_115: 0.9975 - false_positives_115: 22.6133\n",
      "Epoch 59/120\n",
      "524/524 [==============================] - 0s 800us/step - loss: 0.0270 - accuracy: 0.9944 - precision_115: 0.9908 - recall_115: 0.9981 - false_positives_115: 23.6743\n",
      "Epoch 60/120\n",
      "524/524 [==============================] - 0s 808us/step - loss: 0.0265 - accuracy: 0.9940 - precision_115: 0.9912 - recall_115: 0.9971 - false_positives_115: 21.9181\n",
      "Epoch 61/120\n",
      "524/524 [==============================] - 0s 822us/step - loss: 0.0209 - accuracy: 0.9952 - precision_115: 0.9933 - recall_115: 0.9973 - false_positives_115: 19.7810\n",
      "Epoch 62/120\n",
      "524/524 [==============================] - 0s 781us/step - loss: 0.0212 - accuracy: 0.9946 - precision_115: 0.9931 - recall_115: 0.9960 - false_positives_115: 20.7219\n",
      "Epoch 63/120\n",
      "524/524 [==============================] - 0s 838us/step - loss: 0.0325 - accuracy: 0.9931 - precision_115: 0.9894 - recall_115: 0.9969 - false_positives_115: 25.6819\n",
      "Epoch 64/120\n",
      "524/524 [==============================] - 0s 767us/step - loss: 0.0249 - accuracy: 0.9940 - precision_115: 0.9914 - recall_115: 0.9967 - false_positives_115: 22.9790\n",
      "Epoch 65/120\n",
      "524/524 [==============================] - 0s 777us/step - loss: 0.0281 - accuracy: 0.9937 - precision_115: 0.9904 - recall_115: 0.9971 - false_positives_115: 23.7086\n",
      "Epoch 66/120\n",
      "524/524 [==============================] - 0s 813us/step - loss: 0.0234 - accuracy: 0.9948 - precision_115: 0.9924 - recall_115: 0.9975 - false_positives_115: 20.3124\n",
      "Epoch 67/120\n",
      "524/524 [==============================] - 0s 842us/step - loss: 0.0262 - accuracy: 0.9939 - precision_115: 0.9918 - recall_115: 0.9961 - false_positives_115: 22.4667\n",
      "Epoch 68/120\n",
      "524/524 [==============================] - 0s 854us/step - loss: 0.0336 - accuracy: 0.9911 - precision_115: 0.9892 - recall_115: 0.9929 - false_positives_115: 27.5295\n",
      "Epoch 69/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 0s 822us/step - loss: 0.0267 - accuracy: 0.9934 - precision_115: 0.9916 - recall_115: 0.9953 - false_positives_115: 24.4114\n",
      "Epoch 70/120\n",
      "524/524 [==============================] - 0s 883us/step - loss: 0.0248 - accuracy: 0.9948 - precision_115: 0.9925 - recall_115: 0.9970 - false_positives_115: 20.6857\n",
      "Epoch 71/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0323 - accuracy: 0.9934 - precision_115: 0.9900 - recall_115: 0.9970 - false_positives_115: 22.6419\n",
      "Epoch 72/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0251 - accuracy: 0.9943 - precision_115: 0.9909 - recall_115: 0.9975 - false_positives_115: 22.1219\n",
      "Epoch 73/120\n",
      "524/524 [==============================] - 0s 875us/step - loss: 0.0212 - accuracy: 0.9960 - precision_115: 0.9934 - recall_115: 0.9988 - false_positives_115: 19.6952\n",
      "Epoch 74/120\n",
      "524/524 [==============================] - 0s 928us/step - loss: 0.0171 - accuracy: 0.9957 - precision_115: 0.9944 - recall_115: 0.9970 - false_positives_115: 17.8038\n",
      "Epoch 75/120\n",
      "524/524 [==============================] - 1s 968us/step - loss: 0.0236 - accuracy: 0.9942 - precision_115: 0.9922 - recall_115: 0.9965 - false_positives_115: 21.0724\n",
      "Epoch 76/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0278 - accuracy: 0.9939 - precision_115: 0.9901 - recall_115: 0.9977 - false_positives_115: 24.5810\n",
      "Epoch 77/120\n",
      "524/524 [==============================] - 0s 879us/step - loss: 0.0270 - accuracy: 0.9938 - precision_115: 0.9906 - recall_115: 0.9968 - false_positives_115: 23.1867\n",
      "Epoch 78/120\n",
      "524/524 [==============================] - 0s 812us/step - loss: 0.0288 - accuracy: 0.9937 - precision_115: 0.9902 - recall_115: 0.9973 - false_positives_115: 27.4438\n",
      "Epoch 79/120\n",
      "524/524 [==============================] - 0s 808us/step - loss: 0.0251 - accuracy: 0.9939 - precision_115: 0.9925 - recall_115: 0.9954 - false_positives_115: 20.3314\n",
      "Epoch 80/120\n",
      "524/524 [==============================] - 0s 800us/step - loss: 0.0252 - accuracy: 0.9947 - precision_115: 0.9924 - recall_115: 0.9973 - false_positives_115: 20.1314\n",
      "Epoch 81/120\n",
      "524/524 [==============================] - 0s 789us/step - loss: 0.0282 - accuracy: 0.9937 - precision_115: 0.9915 - recall_115: 0.9960 - false_positives_115: 22.4629\n",
      "Epoch 82/120\n",
      "524/524 [==============================] - 0s 901us/step - loss: 0.0282 - accuracy: 0.9939 - precision_115: 0.9897 - recall_115: 0.9979 - false_positives_115: 24.7733\n",
      "Epoch 83/120\n",
      "524/524 [==============================] - 0s 848us/step - loss: 0.0315 - accuracy: 0.9922 - precision_115: 0.9882 - recall_115: 0.9961 - false_positives_115: 26.0057\n",
      "Epoch 84/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0285 - accuracy: 0.9937 - precision_115: 0.9903 - recall_115: 0.9971 - false_positives_115: 22.2171\n",
      "Epoch 85/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0231 - accuracy: 0.9946 - precision_115: 0.9920 - recall_115: 0.9973 - false_positives_115: 22.2476\n",
      "Epoch 86/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0273 - accuracy: 0.9940 - precision_115: 0.9911 - recall_115: 0.9970 - false_positives_115: 21.7733: 0s - loss: 0.0279 - accuracy: 0.9941 - precision_115: 0.9906 - recall_115: 0.9976 - false_positive\n",
      "Epoch 87/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0250 - accuracy: 0.9941 - precision_115: 0.9922 - recall_115: 0.9960 - false_positives_115: 19.8000\n",
      "Epoch 88/120\n",
      "524/524 [==============================] - 0s 897us/step - loss: 0.0334 - accuracy: 0.9931 - precision_115: 0.9896 - recall_115: 0.9964 - false_positives_115: 23.5314\n",
      "Epoch 89/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0231 - accuracy: 0.9944 - precision_115: 0.9934 - recall_115: 0.9955 - false_positives_115: 19.1086\n",
      "Epoch 90/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0246 - accuracy: 0.9943 - precision_115: 0.9917 - recall_115: 0.9970 - false_positives_115: 22.5600\n",
      "Epoch 91/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0241 - accuracy: 0.9946 - precision_115: 0.9926 - recall_115: 0.9967 - false_positives_115: 20.4762\n",
      "Epoch 92/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0236 - accuracy: 0.9952 - precision_115: 0.9932 - recall_115: 0.9974 - false_positives_115: 18.5714\n",
      "Epoch 93/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0253 - accuracy: 0.9938 - precision_115: 0.9918 - recall_115: 0.9960 - false_positives_115: 23.6610\n",
      "Epoch 94/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0214 - accuracy: 0.9949 - precision_115: 0.9930 - recall_115: 0.9968 - false_positives_115: 19.2590\n",
      "Epoch 95/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0213 - accuracy: 0.9958 - precision_115: 0.9937 - recall_115: 0.9981 - false_positives_115: 18.1410\n",
      "Epoch 96/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0277 - accuracy: 0.9940 - precision_115: 0.9895 - recall_115: 0.9984 - false_positives_115: 23.2990\n",
      "Epoch 97/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0269 - accuracy: 0.9946 - precision_115: 0.9918 - recall_115: 0.9974 - false_positives_115: 19.0533\n",
      "Epoch 98/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0287 - accuracy: 0.9932 - precision_115: 0.9915 - recall_115: 0.9946 - false_positives_115: 20.7981\n",
      "Epoch 99/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0247 - accuracy: 0.9943 - precision_115: 0.9922 - recall_115: 0.9964 - false_positives_115: 20.5371\n",
      "Epoch 100/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0240 - accuracy: 0.9938 - precision_115: 0.9911 - recall_115: 0.9965 - false_positives_115: 21.0933\n",
      "Epoch 101/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0318 - accuracy: 0.9928 - precision_115: 0.9894 - recall_115: 0.9961 - false_positives_115: 23.9676\n",
      "Epoch 102/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0219 - accuracy: 0.9945 - precision_115: 0.9924 - recall_115: 0.9965 - false_positives_115: 21.2952\n",
      "Epoch 103/120\n",
      "524/524 [==============================] - 0s 933us/step - loss: 0.0258 - accuracy: 0.9945 - precision_115: 0.9920 - recall_115: 0.9971 - false_positives_115: 19.8952\n",
      "Epoch 104/120\n",
      "524/524 [==============================] - 0s 944us/step - loss: 0.0253 - accuracy: 0.9948 - precision_115: 0.9926 - recall_115: 0.9973 - false_positives_115: 21.0171\n",
      "Epoch 105/120\n",
      "524/524 [==============================] - 0s 948us/step - loss: 0.0293 - accuracy: 0.9936 - precision_115: 0.9904 - recall_115: 0.9970 - false_positives_115: 24.2667\n",
      "Epoch 106/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0278 - accuracy: 0.9940 - precision_115: 0.9912 - recall_115: 0.9967 - false_positives_115: 21.5333\n",
      "Epoch 107/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0341 - accuracy: 0.9929 - precision_115: 0.9887 - recall_115: 0.9968 - false_positives_115: 24.2762\n",
      "Epoch 108/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0239 - accuracy: 0.9946 - precision_115: 0.9930 - recall_115: 0.9964 - false_positives_115: 21.6514\n",
      "Epoch 109/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0252 - accuracy: 0.9932 - precision_115: 0.9916 - recall_115: 0.9949 - false_positives_115: 23.8857\n",
      "Epoch 110/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0240 - accuracy: 0.9951 - precision_115: 0.9926 - recall_115: 0.9975 - false_positives_115: 20.4667\n",
      "Epoch 111/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0229 - accuracy: 0.9947 - precision_115: 0.9929 - recall_115: 0.9965 - false_positives_115: 19.6667\n",
      "Epoch 112/120\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0248 - accuracy: 0.9949 - precision_115: 0.9914 - recall_115: 0.9983 - false_positives_115: 20.5410\n",
      "Epoch 113/120\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0199 - accuracy: 0.9956 - precision_115: 0.9937 - recall_115: 0.9975 - false_positives_115: 17.4438\n",
      "Epoch 114/120\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 0s 934us/step - loss: 0.0214 - accuracy: 0.9953 - precision_115: 0.9939 - recall_115: 0.9968 - false_positives_115: 17.5086\n",
      "Epoch 115/120\n",
      "524/524 [==============================] - 0s 946us/step - loss: 0.0219 - accuracy: 0.9956 - precision_115: 0.9930 - recall_115: 0.9983 - false_positives_115: 18.8190\n",
      "Epoch 116/120\n",
      "524/524 [==============================] - 0s 822us/step - loss: 0.0304 - accuracy: 0.9930 - precision_115: 0.9894 - recall_115: 0.9964 - false_positives_115: 23.5105\n",
      "Epoch 117/120\n",
      "524/524 [==============================] - 0s 844us/step - loss: 0.0252 - accuracy: 0.9944 - precision_115: 0.9926 - recall_115: 0.9963 - false_positives_115: 20.2038\n",
      "Epoch 118/120\n",
      "524/524 [==============================] - 0s 878us/step - loss: 0.0262 - accuracy: 0.9936 - precision_115: 0.9923 - recall_115: 0.9950 - false_positives_115: 21.1105\n",
      "Epoch 119/120\n",
      "524/524 [==============================] - 0s 812us/step - loss: 0.0296 - accuracy: 0.9935 - precision_115: 0.9906 - recall_115: 0.9968 - false_positives_115: 22.5333\n",
      "Epoch 120/120\n",
      "524/524 [==============================] - 0s 863us/step - loss: 0.0228 - accuracy: 0.9948 - precision_115: 0.9932 - recall_115: 0.9965 - false_positives_115: 19.7390\n",
      "Epoch 1/50\n",
      "524/524 [==============================] - 1s 897us/step - loss: 0.5696 - accuracy: 0.7066 - precision_116: 0.6418 - recall_116: 0.9845 - false_positives_116: 1196.6210\n",
      "Epoch 2/50\n",
      "524/524 [==============================] - 0s 903us/step - loss: 0.2961 - accuracy: 0.9746 - precision_116: 0.9697 - recall_116: 0.9804 - false_positives_116: 76.8114\n",
      "Epoch 3/50\n",
      "524/524 [==============================] - 0s 861us/step - loss: 0.2334 - accuracy: 0.9799 - precision_116: 0.9792 - recall_116: 0.9811 - false_positives_116: 56.7981\n",
      "Epoch 4/50\n",
      "524/524 [==============================] - 0s 893us/step - loss: 0.1793 - accuracy: 0.9855 - precision_116: 0.9805 - recall_116: 0.9910 - false_positives_116: 46.0743\n",
      "Epoch 5/50\n",
      "524/524 [==============================] - 1s 972us/step - loss: 0.1452 - accuracy: 0.9864 - precision_116: 0.9847 - recall_116: 0.9882 - false_positives_116: 40.8133\n",
      "Epoch 6/50\n",
      "524/524 [==============================] - 0s 887us/step - loss: 0.1154 - accuracy: 0.9887 - precision_116: 0.9876 - recall_116: 0.9901 - false_positives_116: 32.2114\n",
      "Epoch 7/50\n",
      "524/524 [==============================] - 0s 858us/step - loss: 0.1101 - accuracy: 0.9853 - precision_116: 0.9866 - recall_116: 0.9850 - false_positives_116: 32.3200\n",
      "Epoch 8/50\n",
      "524/524 [==============================] - 1s 992us/step - loss: 0.0914 - accuracy: 0.9899 - precision_116: 0.9875 - recall_116: 0.9923 - false_positives_116: 32.5276\n",
      "Epoch 9/50\n",
      "524/524 [==============================] - 0s 951us/step - loss: 0.0769 - accuracy: 0.9920 - precision_116: 0.9912 - recall_116: 0.9930 - false_positives_116: 26.8819\n",
      "Epoch 10/50\n",
      "524/524 [==============================] - 0s 860us/step - loss: 0.0748 - accuracy: 0.9903 - precision_116: 0.9884 - recall_116: 0.9923 - false_positives_116: 31.8990\n",
      "Epoch 11/50\n",
      "524/524 [==============================] - 0s 822us/step - loss: 0.0648 - accuracy: 0.9909 - precision_116: 0.9877 - recall_116: 0.9947 - false_positives_116: 31.0438\n",
      "Epoch 12/50\n",
      "524/524 [==============================] - 0s 830us/step - loss: 0.0689 - accuracy: 0.9908 - precision_116: 0.9895 - recall_116: 0.9924 - false_positives_116: 27.0381\n",
      "Epoch 13/50\n",
      "524/524 [==============================] - 0s 857us/step - loss: 0.0511 - accuracy: 0.9932 - precision_116: 0.9912 - recall_116: 0.9954 - false_positives_116: 23.2210\n",
      "Epoch 14/50\n",
      "524/524 [==============================] - 0s 808us/step - loss: 0.0497 - accuracy: 0.9924 - precision_116: 0.9912 - recall_116: 0.9935 - false_positives_116: 26.4400\n",
      "Epoch 15/50\n",
      "524/524 [==============================] - 0s 850us/step - loss: 0.0456 - accuracy: 0.9934 - precision_116: 0.9917 - recall_116: 0.9952 - false_positives_116: 22.2552\n",
      "Epoch 16/50\n",
      "524/524 [==============================] - 0s 825us/step - loss: 0.0655 - accuracy: 0.9892 - precision_116: 0.9871 - recall_116: 0.9913 - false_positives_116: 28.3219\n",
      "Epoch 17/50\n",
      "524/524 [==============================] - 0s 877us/step - loss: 0.0470 - accuracy: 0.9926 - precision_116: 0.9914 - recall_116: 0.9938 - false_positives_116: 24.4267\n",
      "Epoch 18/50\n",
      "524/524 [==============================] - 0s 805us/step - loss: 0.0453 - accuracy: 0.9941 - precision_116: 0.9923 - recall_116: 0.9959 - false_positives_116: 19.6400\n",
      "Epoch 19/50\n",
      "524/524 [==============================] - 0s 827us/step - loss: 0.0418 - accuracy: 0.9935 - precision_116: 0.9920 - recall_116: 0.9950 - false_positives_116: 22.1390\n",
      "Epoch 20/50\n",
      "524/524 [==============================] - 0s 908us/step - loss: 0.0362 - accuracy: 0.9948 - precision_116: 0.9920 - recall_116: 0.9977 - false_positives_116: 21.6400\n",
      "Epoch 21/50\n",
      "524/524 [==============================] - 0s 847us/step - loss: 0.0337 - accuracy: 0.9965 - precision_116: 0.9940 - recall_116: 0.9990 - false_positives_116: 19.3371\n",
      "Epoch 22/50\n",
      "524/524 [==============================] - 0s 913us/step - loss: 0.0346 - accuracy: 0.9943 - precision_116: 0.9917 - recall_116: 0.9969 - false_positives_116: 23.1562\n",
      "Epoch 23/50\n",
      "524/524 [==============================] - 0s 851us/step - loss: 0.0443 - accuracy: 0.9931 - precision_116: 0.9891 - recall_116: 0.9966 - false_positives_116: 25.7867\n",
      "Epoch 24/50\n",
      "524/524 [==============================] - 0s 864us/step - loss: 0.0373 - accuracy: 0.9928 - precision_116: 0.9895 - recall_116: 0.9961 - false_positives_116: 24.5429\n",
      "Epoch 25/50\n",
      "524/524 [==============================] - 1s 952us/step - loss: 0.0335 - accuracy: 0.9953 - precision_116: 0.9925 - recall_116: 0.9982 - false_positives_116: 20.2914\n",
      "Epoch 26/50\n",
      "524/524 [==============================] - 0s 853us/step - loss: 0.0328 - accuracy: 0.9951 - precision_116: 0.9922 - recall_116: 0.9980 - false_positives_116: 21.7010\n",
      "Epoch 27/50\n",
      "524/524 [==============================] - 0s 904us/step - loss: 0.0392 - accuracy: 0.9944 - precision_116: 0.9919 - recall_116: 0.9971 - false_positives_116: 21.3238\n",
      "Epoch 28/50\n",
      "524/524 [==============================] - 0s 863us/step - loss: 0.0340 - accuracy: 0.9937 - precision_116: 0.9905 - recall_116: 0.9973 - false_positives_116: 24.0114\n",
      "Epoch 29/50\n",
      "524/524 [==============================] - 0s 851us/step - loss: 0.0283 - accuracy: 0.9948 - precision_116: 0.9908 - recall_116: 0.9989 - false_positives_116: 23.7867\n",
      "Epoch 30/50\n",
      "524/524 [==============================] - 0s 909us/step - loss: 0.0317 - accuracy: 0.9957 - precision_116: 0.9931 - recall_116: 0.9983 - false_positives_116: 18.6286\n",
      "Epoch 31/50\n",
      "524/524 [==============================] - 0s 829us/step - loss: 0.0309 - accuracy: 0.9953 - precision_116: 0.9929 - recall_116: 0.9975 - false_positives_116: 17.3295\n",
      "Epoch 32/50\n",
      "524/524 [==============================] - 0s 827us/step - loss: 0.0311 - accuracy: 0.9953 - precision_116: 0.9931 - recall_116: 0.9976 - false_positives_116: 19.8076\n",
      "Epoch 33/50\n",
      "524/524 [==============================] - 0s 902us/step - loss: 0.0334 - accuracy: 0.9955 - precision_116: 0.9925 - recall_116: 0.9987 - false_positives_116: 19.6819\n",
      "Epoch 34/50\n",
      "524/524 [==============================] - 0s 827us/step - loss: 0.0273 - accuracy: 0.9957 - precision_116: 0.9933 - recall_116: 0.9981 - false_positives_116: 17.5143\n",
      "Epoch 35/50\n",
      "524/524 [==============================] - 0s 844us/step - loss: 0.0277 - accuracy: 0.9953 - precision_116: 0.9924 - recall_116: 0.9984 - false_positives_116: 18.0343\n",
      "Epoch 36/50\n",
      "524/524 [==============================] - 0s 796us/step - loss: 0.0270 - accuracy: 0.9968 - precision_116: 0.9941 - recall_116: 0.9995 - false_positives_116: 15.6724\n",
      "Epoch 37/50\n",
      "524/524 [==============================] - 0s 873us/step - loss: 0.0285 - accuracy: 0.9959 - precision_116: 0.9926 - recall_116: 0.9992 - false_positives_116: 19.7048\n",
      "Epoch 38/50\n",
      "524/524 [==============================] - 0s 826us/step - loss: 0.0324 - accuracy: 0.9953 - precision_116: 0.9907 - recall_116: 0.9999 - false_positives_116: 21.5733\n",
      "Epoch 39/50\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 0s 867us/step - loss: 0.0217 - accuracy: 0.9961 - precision_116: 0.9935 - recall_116: 0.9986 - false_positives_116: 19.4190\n",
      "Epoch 40/50\n",
      "524/524 [==============================] - 0s 818us/step - loss: 0.0290 - accuracy: 0.9946 - precision_116: 0.9906 - recall_116: 0.9985 - false_positives_116: 21.5067\n",
      "Epoch 41/50\n",
      "524/524 [==============================] - 0s 829us/step - loss: 0.0191 - accuracy: 0.9962 - precision_116: 0.9932 - recall_116: 0.9992 - false_positives_116: 20.1238\n",
      "Epoch 42/50\n",
      "524/524 [==============================] - 0s 853us/step - loss: 0.0198 - accuracy: 0.9962 - precision_116: 0.9936 - recall_116: 0.9989 - false_positives_116: 18.5200\n",
      "Epoch 43/50\n",
      "524/524 [==============================] - 0s 822us/step - loss: 0.0315 - accuracy: 0.9948 - precision_116: 0.9910 - recall_116: 0.9988 - false_positives_116: 20.4571\n",
      "Epoch 44/50\n",
      "524/524 [==============================] - 0s 872us/step - loss: 0.0190 - accuracy: 0.9967 - precision_116: 0.9937 - recall_116: 0.9996 - false_positives_116: 19.3505\n",
      "Epoch 45/50\n",
      "524/524 [==============================] - 0s 820us/step - loss: 0.0298 - accuracy: 0.9947 - precision_116: 0.9904 - recall_116: 0.9990 - false_positives_116: 22.6686\n",
      "Epoch 46/50\n",
      "524/524 [==============================] - 0s 887us/step - loss: 0.0215 - accuracy: 0.9967 - precision_116: 0.9938 - recall_116: 0.9997 - false_positives_116: 17.9410\n",
      "Epoch 47/50\n",
      "524/524 [==============================] - 0s 813us/step - loss: 0.0242 - accuracy: 0.9958 - precision_116: 0.9920 - recall_116: 0.9996 - false_positives_116: 20.4019\n",
      "Epoch 48/50\n",
      "524/524 [==============================] - 0s 861us/step - loss: 0.0268 - accuracy: 0.9960 - precision_116: 0.9925 - recall_116: 0.9995 - false_positives_116: 19.1924\n",
      "Epoch 49/50\n",
      "524/524 [==============================] - 0s 836us/step - loss: 0.0247 - accuracy: 0.9953 - precision_116: 0.9918 - recall_116: 0.9988 - false_positives_116: 23.7276\n",
      "Epoch 50/50\n",
      "524/524 [==============================] - 0s 852us/step - loss: 0.0242 - accuracy: 0.9962 - precision_116: 0.9928 - recall_116: 0.9996 - false_positives_116: 19.5886\n",
      "Epoch 1/90\n",
      "524/524 [==============================] - 1s 913us/step - loss: 0.2776 - accuracy: 0.8875 - precision_117: 0.9302 - recall_117: 0.8282 - false_positives_117: 95.0019\n",
      "Epoch 2/90\n",
      "524/524 [==============================] - 0s 931us/step - loss: 0.0434 - accuracy: 0.9895 - precision_117: 0.9828 - recall_117: 0.9961 - false_positives_117: 45.4095\n",
      "Epoch 3/90\n",
      "524/524 [==============================] - 0s 868us/step - loss: 0.0372 - accuracy: 0.9926 - precision_117: 0.9871 - recall_117: 0.9984 - false_positives_117: 35.2400\n",
      "Epoch 4/90\n",
      "524/524 [==============================] - 0s 847us/step - loss: 0.0296 - accuracy: 0.9932 - precision_117: 0.9885 - recall_117: 0.9981 - false_positives_117: 32.2552\n",
      "Epoch 5/90\n",
      "524/524 [==============================] - 0s 824us/step - loss: 0.0302 - accuracy: 0.9938 - precision_117: 0.9890 - recall_117: 0.9989 - false_positives_117: 32.6971\n",
      "Epoch 6/90\n",
      "524/524 [==============================] - 0s 871us/step - loss: 0.0243 - accuracy: 0.9949 - precision_117: 0.9905 - recall_117: 0.9995 - false_positives_117: 24.7086\n",
      "Epoch 7/90\n",
      "524/524 [==============================] - 0s 830us/step - loss: 0.0257 - accuracy: 0.9949 - precision_117: 0.9907 - recall_117: 0.9992 - false_positives_117: 24.1848\n",
      "Epoch 8/90\n",
      "524/524 [==============================] - 0s 833us/step - loss: 0.0251 - accuracy: 0.9948 - precision_117: 0.9901 - recall_117: 0.9996 - false_positives_117: 25.5219\n",
      "Epoch 9/90\n",
      "524/524 [==============================] - 1s 960us/step - loss: 0.0221 - accuracy: 0.9950 - precision_117: 0.9909 - recall_117: 0.9992 - false_positives_117: 25.4495\n",
      "Epoch 10/90\n",
      "524/524 [==============================] - 0s 859us/step - loss: 0.0221 - accuracy: 0.9959 - precision_117: 0.9918 - recall_117: 1.0000 - false_positives_117: 20.4476\n",
      "Epoch 11/90\n",
      "524/524 [==============================] - 0s 863us/step - loss: 0.0261 - accuracy: 0.9947 - precision_117: 0.9904 - recall_117: 0.9991 - false_positives_117: 23.6990\n",
      "Epoch 12/90\n",
      "524/524 [==============================] - 0s 826us/step - loss: 0.0199 - accuracy: 0.9963 - precision_117: 0.9932 - recall_117: 0.9995 - false_positives_117: 19.5943\n",
      "Epoch 13/90\n",
      "524/524 [==============================] - 0s 852us/step - loss: 0.0226 - accuracy: 0.9950 - precision_117: 0.9914 - recall_117: 0.9986 - false_positives_117: 23.2305\n",
      "Epoch 14/90\n",
      "524/524 [==============================] - 0s 809us/step - loss: 0.0228 - accuracy: 0.9952 - precision_117: 0.9908 - recall_117: 0.9996 - false_positives_117: 21.8171\n",
      "Epoch 15/90\n",
      "524/524 [==============================] - 0s 904us/step - loss: 0.0218 - accuracy: 0.9950 - precision_117: 0.9903 - recall_117: 0.9998 - false_positives_117: 23.1867\n",
      "Epoch 16/90\n",
      "524/524 [==============================] - 0s 828us/step - loss: 0.0246 - accuracy: 0.9944 - precision_117: 0.9889 - recall_117: 0.9998 - false_positives_117: 23.2324\n",
      "Epoch 17/90\n",
      "524/524 [==============================] - 0s 865us/step - loss: 0.0151 - accuracy: 0.9968 - precision_117: 0.9937 - recall_117: 0.9999 - false_positives_117: 16.3086\n",
      "Epoch 18/90\n",
      "524/524 [==============================] - 0s 815us/step - loss: 0.0185 - accuracy: 0.9952 - precision_117: 0.9924 - recall_117: 0.9985 - false_positives_117: 19.0095\n",
      "Epoch 19/90\n",
      "524/524 [==============================] - 0s 839us/step - loss: 0.0179 - accuracy: 0.9963 - precision_117: 0.9927 - recall_117: 1.0000 - false_positives_117: 17.7181\n",
      "Epoch 20/90\n",
      "524/524 [==============================] - 0s 869us/step - loss: 0.0208 - accuracy: 0.9954 - precision_117: 0.9914 - recall_117: 0.9993 - false_positives_117: 19.9371\n",
      "Epoch 21/90\n",
      "524/524 [==============================] - 1s 995us/step - loss: 0.0189 - accuracy: 0.9962 - precision_117: 0.9926 - recall_117: 0.9998 - false_positives_117: 19.6838\n",
      "Epoch 22/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0204 - accuracy: 0.9960 - precision_117: 0.9922 - recall_117: 0.9998 - false_positives_117: 18.2381\n",
      "Epoch 23/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0189 - accuracy: 0.9968 - precision_117: 0.9937 - recall_117: 1.0000 - false_positives_117: 16.8667\n",
      "Epoch 24/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0178 - accuracy: 0.9960 - precision_117: 0.9926 - recall_117: 0.9993 - false_positives_117: 18.0495\n",
      "Epoch 25/90\n",
      "524/524 [==============================] - 0s 891us/step - loss: 0.0167 - accuracy: 0.9970 - precision_117: 0.9944 - recall_117: 0.9996 - false_positives_117: 14.2286\n",
      "Epoch 26/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0185 - accuracy: 0.9965 - precision_117: 0.9933 - recall_117: 0.9996 - false_positives_117: 14.6495\n",
      "Epoch 27/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0151 - accuracy: 0.9970 - precision_117: 0.9942 - recall_117: 0.9998 - false_positives_117: 16.2400\n",
      "Epoch 28/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0152 - accuracy: 0.9962 - precision_117: 0.9940 - recall_117: 0.9984 - false_positives_117: 15.0838\n",
      "Epoch 29/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0187 - accuracy: 0.9958 - precision_117: 0.9921 - recall_117: 0.9994 - false_positives_117: 18.5829\n",
      "Epoch 30/90\n",
      "524/524 [==============================] - 0s 927us/step - loss: 0.0142 - accuracy: 0.9972 - precision_117: 0.9947 - recall_117: 0.9997 - false_positives_117: 15.4152\n",
      "Epoch 31/90\n",
      "524/524 [==============================] - 0s 750us/step - loss: 0.0160 - accuracy: 0.9964 - precision_117: 0.9929 - recall_117: 0.9998 - false_positives_117: 17.4000\n",
      "Epoch 32/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0128 - accuracy: 0.9973 - precision_117: 0.9946 - recall_117: 1.0000 - false_positives_117: 15.0514\n",
      "Epoch 33/90\n",
      "524/524 [==============================] - 1s 987us/step - loss: 0.0178 - accuracy: 0.9957 - precision_117: 0.9932 - recall_117: 0.9984 - false_positives_117: 17.5752\n",
      "Epoch 34/90\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0138 - accuracy: 0.9973 - precision_117: 0.9948 - recall_117: 0.9999 - false_positives_117: 13.8571\n",
      "Epoch 35/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0145 - accuracy: 0.9971 - precision_117: 0.9950 - recall_117: 0.9992 - false_positives_117: 14.4590\n",
      "Epoch 36/90\n",
      "524/524 [==============================] - 0s 931us/step - loss: 0.0133 - accuracy: 0.9975 - precision_117: 0.9956 - recall_117: 0.9995 - false_positives_117: 12.7181\n",
      "Epoch 37/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0136 - accuracy: 0.9969 - precision_117: 0.9957 - recall_117: 0.9982 - false_positives_117: 13.2838\n",
      "Epoch 38/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0130 - accuracy: 0.9977 - precision_117: 0.9955 - recall_117: 0.9999 - false_positives_117: 11.6971\n",
      "Epoch 39/90\n",
      "524/524 [==============================] - 0s 940us/step - loss: 0.0131 - accuracy: 0.9976 - precision_117: 0.9956 - recall_117: 0.9997 - false_positives_117: 14.2971\n",
      "Epoch 40/90\n",
      "524/524 [==============================] - 1s 972us/step - loss: 0.0114 - accuracy: 0.9975 - precision_117: 0.9956 - recall_117: 0.9994 - false_positives_117: 13.0495\n",
      "Epoch 41/90\n",
      "524/524 [==============================] - 0s 921us/step - loss: 0.0137 - accuracy: 0.9965 - precision_117: 0.9949 - recall_117: 0.9980 - false_positives_117: 14.6895\n",
      "Epoch 42/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0152 - accuracy: 0.9969 - precision_117: 0.9940 - recall_117: 0.9998 - false_positives_117: 13.7371\n",
      "Epoch 43/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0104 - accuracy: 0.9977 - precision_117: 0.9956 - recall_117: 0.9998 - false_positives_117: 12.6514\n",
      "Epoch 44/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0145 - accuracy: 0.9971 - precision_117: 0.9948 - recall_117: 0.9994 - false_positives_117: 15.1790\n",
      "Epoch 45/90\n",
      "524/524 [==============================] - 0s 846us/step - loss: 0.0126 - accuracy: 0.9975 - precision_117: 0.9951 - recall_117: 0.9999 - false_positives_117: 13.8419\n",
      "Epoch 46/90\n",
      "524/524 [==============================] - 1s 974us/step - loss: 0.0195 - accuracy: 0.9964 - precision_117: 0.9931 - recall_117: 0.9998 - false_positives_117: 16.3486\n",
      "Epoch 47/90\n",
      "524/524 [==============================] - 0s 904us/step - loss: 0.0139 - accuracy: 0.9973 - precision_117: 0.9950 - recall_117: 0.9997 - false_positives_117: 12.5981\n",
      "Epoch 48/90\n",
      "524/524 [==============================] - 0s 924us/step - loss: 0.0141 - accuracy: 0.9973 - precision_117: 0.9949 - recall_117: 0.9997 - false_positives_117: 14.2743\n",
      "Epoch 49/90\n",
      "524/524 [==============================] - 1s 991us/step - loss: 0.0108 - accuracy: 0.9976 - precision_117: 0.9959 - recall_117: 0.9994 - false_positives_117: 13.1086\n",
      "Epoch 50/90\n",
      "524/524 [==============================] - 0s 887us/step - loss: 0.0132 - accuracy: 0.9966 - precision_117: 0.9944 - recall_117: 0.9988 - false_positives_117: 11.2438\n",
      "Epoch 51/90\n",
      "524/524 [==============================] - 0s 774us/step - loss: 0.0082 - accuracy: 0.9989 - precision_117: 0.9978 - recall_117: 0.9999 - false_positives_117: 8.3714\n",
      "Epoch 52/90\n",
      "524/524 [==============================] - 0s 761us/step - loss: 0.0101 - accuracy: 0.9973 - precision_117: 0.9955 - recall_117: 0.9990 - false_positives_117: 11.4990\n",
      "Epoch 53/90\n",
      "524/524 [==============================] - 0s 899us/step - loss: 0.0153 - accuracy: 0.9971 - precision_117: 0.9950 - recall_117: 0.9992 - false_positives_117: 13.2819\n",
      "Epoch 54/90\n",
      "524/524 [==============================] - 0s 770us/step - loss: 0.0126 - accuracy: 0.9976 - precision_117: 0.9956 - recall_117: 0.9996 - false_positives_117: 12.2629\n",
      "Epoch 55/90\n",
      "524/524 [==============================] - 0s 744us/step - loss: 0.0113 - accuracy: 0.9978 - precision_117: 0.9958 - recall_117: 0.9998 - false_positives_117: 11.4400\n",
      "Epoch 56/90\n",
      "524/524 [==============================] - 0s 790us/step - loss: 0.0135 - accuracy: 0.9980 - precision_117: 0.9963 - recall_117: 0.9997 - false_positives_117: 10.9219\n",
      "Epoch 57/90\n",
      "524/524 [==============================] - 0s 744us/step - loss: 0.0115 - accuracy: 0.9972 - precision_117: 0.9953 - recall_117: 0.9992 - false_positives_117: 14.6476\n",
      "Epoch 58/90\n",
      "524/524 [==============================] - 0s 778us/step - loss: 0.0123 - accuracy: 0.9977 - precision_117: 0.9955 - recall_117: 0.9998 - false_positives_117: 12.1790\n",
      "Epoch 59/90\n",
      "524/524 [==============================] - 0s 781us/step - loss: 0.0131 - accuracy: 0.9972 - precision_117: 0.9950 - recall_117: 0.9995 - false_positives_117: 12.8552\n",
      "Epoch 60/90\n",
      "524/524 [==============================] - 0s 744us/step - loss: 0.0126 - accuracy: 0.9969 - precision_117: 0.9940 - recall_117: 1.0000 - false_positives_117: 15.7771\n",
      "Epoch 61/90\n",
      "524/524 [==============================] - 0s 795us/step - loss: 0.0110 - accuracy: 0.9977 - precision_117: 0.9958 - recall_117: 0.9996 - false_positives_117: 12.5448\n",
      "Epoch 62/90\n",
      "524/524 [==============================] - 1s 991us/step - loss: 0.0140 - accuracy: 0.9970 - precision_117: 0.9940 - recall_117: 1.0000 - false_positives_117: 13.3029\n",
      "Epoch 63/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0114 - accuracy: 0.9976 - precision_117: 0.9953 - recall_117: 0.9998 - false_positives_117: 12.1981\n",
      "Epoch 64/90\n",
      "524/524 [==============================] - 0s 768us/step - loss: 0.0171 - accuracy: 0.9954 - precision_117: 0.9918 - recall_117: 0.9992 - false_positives_117: 15.4248\n",
      "Epoch 65/90\n",
      "524/524 [==============================] - 0s 785us/step - loss: 0.0121 - accuracy: 0.9972 - precision_117: 0.9961 - recall_117: 0.9983 - false_positives_117: 11.7086\n",
      "Epoch 66/90\n",
      "524/524 [==============================] - 0s 745us/step - loss: 0.0091 - accuracy: 0.9984 - precision_117: 0.9969 - recall_117: 0.9999 - false_positives_117: 10.1390\n",
      "Epoch 67/90\n",
      "524/524 [==============================] - 0s 794us/step - loss: 0.0156 - accuracy: 0.9966 - precision_117: 0.9938 - recall_117: 0.9993 - false_positives_117: 15.5714\n",
      "Epoch 68/90\n",
      "524/524 [==============================] - 0s 778us/step - loss: 0.0129 - accuracy: 0.9971 - precision_117: 0.9942 - recall_117: 1.0000 - false_positives_117: 13.3810\n",
      "Epoch 69/90\n",
      "524/524 [==============================] - 0s 763us/step - loss: 0.0126 - accuracy: 0.9970 - precision_117: 0.9949 - recall_117: 0.9991 - false_positives_117: 13.9829\n",
      "Epoch 70/90\n",
      "524/524 [==============================] - 0s 851us/step - loss: 0.0125 - accuracy: 0.9975 - precision_117: 0.9954 - recall_117: 0.9996 - false_positives_117: 12.5295\n",
      "Epoch 71/90\n",
      "524/524 [==============================] - 0s 781us/step - loss: 0.0116 - accuracy: 0.9976 - precision_117: 0.9957 - recall_117: 0.9995 - false_positives_117: 10.6324\n",
      "Epoch 72/90\n",
      "524/524 [==============================] - 0s 791us/step - loss: 0.0132 - accuracy: 0.9969 - precision_117: 0.9942 - recall_117: 0.9996 - false_positives_117: 14.0781\n",
      "Epoch 73/90\n",
      "524/524 [==============================] - 0s 785us/step - loss: 0.0133 - accuracy: 0.9970 - precision_117: 0.9949 - recall_117: 0.9992 - false_positives_117: 13.2229\n",
      "Epoch 74/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0088 - accuracy: 0.9982 - precision_117: 0.9967 - recall_117: 0.9996 - false_positives_117: 9.9086\n",
      "Epoch 75/90\n",
      "524/524 [==============================] - 0s 942us/step - loss: 0.0091 - accuracy: 0.9982 - precision_117: 0.9970 - recall_117: 0.9995 - false_positives_117: 9.5962\n",
      "Epoch 76/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0118 - accuracy: 0.9971 - precision_117: 0.9953 - recall_117: 0.9989 - false_positives_117: 13.0000\n",
      "Epoch 77/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0129 - accuracy: 0.9971 - precision_117: 0.9949 - recall_117: 0.9993 - false_positives_117: 11.3905\n",
      "Epoch 78/90\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0101 - accuracy: 0.9979 - precision_117: 0.9963 - recall_117: 0.9996 - false_positives_117: 10.2838\n",
      "Epoch 79/90\n",
      "524/524 [==============================] - 0s 870us/step - loss: 0.0095 - accuracy: 0.9975 - precision_117: 0.9961 - recall_117: 0.9990 - false_positives_117: 10.8629\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 80/90\n",
      "524/524 [==============================] - 0s 890us/step - loss: 0.0088 - accuracy: 0.9981 - precision_117: 0.9966 - recall_117: 0.9996 - false_positives_117: 8.8571\n",
      "Epoch 81/90\n",
      "524/524 [==============================] - 0s 918us/step - loss: 0.0118 - accuracy: 0.9974 - precision_117: 0.9953 - recall_117: 0.9996 - false_positives_117: 13.0343\n",
      "Epoch 82/90\n",
      "524/524 [==============================] - 0s 895us/step - loss: 0.0163 - accuracy: 0.9962 - precision_117: 0.9933 - recall_117: 0.9990 - false_positives_117: 14.3600\n",
      "Epoch 83/90\n",
      "524/524 [==============================] - 1s 969us/step - loss: 0.0128 - accuracy: 0.9972 - precision_117: 0.9945 - recall_117: 0.9999 - false_positives_117: 11.8286\n",
      "Epoch 84/90\n",
      "524/524 [==============================] - 0s 787us/step - loss: 0.0122 - accuracy: 0.9971 - precision_117: 0.9948 - recall_117: 0.9994 - false_positives_117: 15.0571\n",
      "Epoch 85/90\n",
      "524/524 [==============================] - 0s 760us/step - loss: 0.0103 - accuracy: 0.9970 - precision_117: 0.9943 - recall_117: 0.9996 - false_positives_117: 11.9867\n",
      "Epoch 86/90\n",
      "524/524 [==============================] - 0s 817us/step - loss: 0.0108 - accuracy: 0.9980 - precision_117: 0.9962 - recall_117: 1.0000 - false_positives_117: 10.7181\n",
      "Epoch 87/90\n",
      "524/524 [==============================] - 0s 761us/step - loss: 0.0146 - accuracy: 0.9973 - precision_117: 0.9947 - recall_117: 1.0000 - false_positives_117: 13.2876\n",
      "Epoch 88/90\n",
      "524/524 [==============================] - 0s 748us/step - loss: 0.0116 - accuracy: 0.9968 - precision_117: 0.9952 - recall_117: 0.9983 - false_positives_117: 13.5848\n",
      "Epoch 89/90\n",
      "524/524 [==============================] - 0s 806us/step - loss: 0.0104 - accuracy: 0.9982 - precision_117: 0.9966 - recall_117: 0.9998 - false_positives_117: 9.8000\n",
      "Epoch 90/90\n",
      "524/524 [==============================] - 1s 982us/step - loss: 0.0106 - accuracy: 0.9972 - precision_117: 0.9952 - recall_117: 0.9990 - false_positives_117: 12.1695\n",
      "Epoch 1/42\n",
      "524/524 [==============================] - 2s 1ms/step - loss: 0.2907 - accuracy: 0.8690 - precision_118: 0.8441 - recall_118: 0.9237 - false_positives_118: 281.0590\n",
      "Epoch 2/42\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0525 - accuracy: 0.9882 - precision_118: 0.9853 - recall_118: 0.9909 - false_positives_118: 38.6476\n",
      "Epoch 3/42\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0463 - accuracy: 0.9905 - precision_118: 0.9845 - recall_118: 0.9966 - false_positives_118: 41.5257\n",
      "Epoch 4/42\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0388 - accuracy: 0.9912 - precision_118: 0.9856 - recall_118: 0.9966 - false_positives_118: 36.1848: 0s - loss: 0.0378 - accuracy: 0.9910 - precision_118: 0.9852 - recall_118: 0.9965 - false_positive\n",
      "Epoch 5/42\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0315 - accuracy: 0.9934 - precision_118: 0.9889 - recall_118: 0.9981 - false_positives_118: 31.8895\n",
      "Epoch 6/42\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0301 - accuracy: 0.9943 - precision_118: 0.9897 - recall_118: 0.9990 - false_positives_118: 28.9790\n",
      "Epoch 7/42\n",
      "524/524 [==============================] - 0s 798us/step - loss: 0.0256 - accuracy: 0.9938 - precision_118: 0.9899 - recall_118: 0.9978 - false_positives_118: 29.7333\n",
      "Epoch 8/42\n",
      "524/524 [==============================] - 0s 783us/step - loss: 0.0269 - accuracy: 0.9946 - precision_118: 0.9904 - recall_118: 0.9988 - false_positives_118: 25.0476\n",
      "Epoch 9/42\n",
      "524/524 [==============================] - 0s 805us/step - loss: 0.0287 - accuracy: 0.9934 - precision_118: 0.9892 - recall_118: 0.9978 - false_positives_118: 27.7790\n",
      "Epoch 10/42\n",
      "524/524 [==============================] - 0s 767us/step - loss: 0.0218 - accuracy: 0.9956 - precision_118: 0.9919 - recall_118: 0.9993 - false_positives_118: 24.4095\n",
      "Epoch 11/42\n",
      "524/524 [==============================] - 0s 770us/step - loss: 0.0216 - accuracy: 0.9954 - precision_118: 0.9919 - recall_118: 0.9992 - false_positives_118: 22.2533\n",
      "Epoch 12/42\n",
      "524/524 [==============================] - 1s 2ms/step - loss: 0.0235 - accuracy: 0.9956 - precision_118: 0.9920 - recall_118: 0.9993 - false_positives_118: 22.3467\n",
      "Epoch 13/42\n",
      "524/524 [==============================] - 0s 943us/step - loss: 0.0222 - accuracy: 0.9950 - precision_118: 0.9916 - recall_118: 0.9985 - false_positives_118: 23.8362\n",
      "Epoch 14/42\n",
      "524/524 [==============================] - 0s 859us/step - loss: 0.0306 - accuracy: 0.9938 - precision_118: 0.9881 - recall_118: 0.9993 - false_positives_118: 26.1029\n",
      "Epoch 15/42\n",
      "524/524 [==============================] - 0s 815us/step - loss: 0.0242 - accuracy: 0.9953 - precision_118: 0.9914 - recall_118: 0.9994 - false_positives_118: 22.6190\n",
      "Epoch 16/42\n",
      "524/524 [==============================] - 0s 876us/step - loss: 0.0200 - accuracy: 0.9955 - precision_118: 0.9922 - recall_118: 0.9986 - false_positives_118: 21.8705\n",
      "Epoch 17/42\n",
      "524/524 [==============================] - 0s 784us/step - loss: 0.0228 - accuracy: 0.9946 - precision_118: 0.9899 - recall_118: 0.9993 - false_positives_118: 24.7010\n",
      "Epoch 18/42\n",
      "524/524 [==============================] - 0s 757us/step - loss: 0.0182 - accuracy: 0.9957 - precision_118: 0.9921 - recall_118: 0.9995 - false_positives_118: 22.1600\n",
      "Epoch 19/42\n",
      "524/524 [==============================] - 0s 761us/step - loss: 0.0249 - accuracy: 0.9945 - precision_118: 0.9894 - recall_118: 0.9997 - false_positives_118: 25.6305\n",
      "Epoch 20/42\n",
      "524/524 [==============================] - 0s 783us/step - loss: 0.0227 - accuracy: 0.9952 - precision_118: 0.9908 - recall_118: 0.9996 - false_positives_118: 22.4952\n",
      "Epoch 21/42\n",
      "524/524 [==============================] - 0s 827us/step - loss: 0.0196 - accuracy: 0.9956 - precision_118: 0.9918 - recall_118: 0.9994 - false_positives_118: 21.8971\n",
      "Epoch 22/42\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0173 - accuracy: 0.9965 - precision_118: 0.9932 - recall_118: 0.9998 - false_positives_118: 19.0971\n",
      "Epoch 23/42\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0241 - accuracy: 0.9956 - precision_118: 0.9914 - recall_118: 0.9999 - false_positives_118: 22.1143\n",
      "Epoch 24/42\n",
      "524/524 [==============================] - 0s 915us/step - loss: 0.0263 - accuracy: 0.9945 - precision_118: 0.9889 - recall_118: 0.9999 - false_positives_118: 24.4495\n",
      "Epoch 25/42\n",
      "524/524 [==============================] - 0s 841us/step - loss: 0.0184 - accuracy: 0.9967 - precision_118: 0.9940 - recall_118: 0.9996 - false_positives_118: 17.5067\n",
      "Epoch 26/42\n",
      "524/524 [==============================] - 0s 848us/step - loss: 0.0218 - accuracy: 0.9959 - precision_118: 0.9926 - recall_118: 0.9991 - false_positives_118: 20.4457\n",
      "Epoch 27/42\n",
      "524/524 [==============================] - 0s 819us/step - loss: 0.0193 - accuracy: 0.9965 - precision_118: 0.9931 - recall_118: 1.0000 - false_positives_118: 18.4190\n",
      "Epoch 28/42\n",
      "524/524 [==============================] - 0s 779us/step - loss: 0.0180 - accuracy: 0.9963 - precision_118: 0.9933 - recall_118: 0.9995 - false_positives_118: 16.3143\n",
      "Epoch 29/42\n",
      "524/524 [==============================] - 0s 795us/step - loss: 0.0187 - accuracy: 0.9961 - precision_118: 0.9934 - recall_118: 0.9990 - false_positives_118: 19.2381\n",
      "Epoch 30/42\n",
      "524/524 [==============================] - 0s 753us/step - loss: 0.0193 - accuracy: 0.9957 - precision_118: 0.9920 - recall_118: 0.9995 - false_positives_118: 19.3029\n",
      "Epoch 31/42\n",
      "524/524 [==============================] - 0s 795us/step - loss: 0.0195 - accuracy: 0.9962 - precision_118: 0.9927 - recall_118: 0.9998 - false_positives_118: 18.9410\n",
      "Epoch 32/42\n",
      "524/524 [==============================] - 0s 747us/step - loss: 0.0183 - accuracy: 0.9960 - precision_118: 0.9920 - recall_118: 0.9999 - false_positives_118: 19.1790\n",
      "Epoch 33/42\n",
      "524/524 [==============================] - 0s 816us/step - loss: 0.0167 - accuracy: 0.9966 - precision_118: 0.9937 - recall_118: 0.9995 - false_positives_118: 18.0629\n",
      "Epoch 34/42\n",
      "524/524 [==============================] - 0s 747us/step - loss: 0.0198 - accuracy: 0.9957 - precision_118: 0.9925 - recall_118: 0.9991 - false_positives_118: 19.2705\n",
      "Epoch 35/42\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 0s 760us/step - loss: 0.0168 - accuracy: 0.9966 - precision_118: 0.9937 - recall_118: 0.9997 - false_positives_118: 16.8343\n",
      "Epoch 36/42\n",
      "524/524 [==============================] - 0s 882us/step - loss: 0.0184 - accuracy: 0.9966 - precision_118: 0.9935 - recall_118: 0.9999 - false_positives_118: 17.5790\n",
      "Epoch 37/42\n",
      "524/524 [==============================] - 0s 820us/step - loss: 0.0146 - accuracy: 0.9975 - precision_118: 0.9951 - recall_118: 0.9999 - false_positives_118: 14.7562\n",
      "Epoch 38/42\n",
      "524/524 [==============================] - 0s 855us/step - loss: 0.0145 - accuracy: 0.9968 - precision_118: 0.9941 - recall_118: 0.9996 - false_positives_118: 17.5524\n",
      "Epoch 39/42\n",
      "524/524 [==============================] - 0s 793us/step - loss: 0.0126 - accuracy: 0.9976 - precision_118: 0.9954 - recall_118: 0.9999 - false_positives_118: 14.0362\n",
      "Epoch 40/42\n",
      "524/524 [==============================] - 0s 798us/step - loss: 0.0132 - accuracy: 0.9969 - precision_118: 0.9939 - recall_118: 1.0000 - false_positives_118: 17.4762\n",
      "Epoch 41/42\n",
      "524/524 [==============================] - 0s 751us/step - loss: 0.0164 - accuracy: 0.9964 - precision_118: 0.9934 - recall_118: 0.9995 - false_positives_118: 17.5505\n",
      "Epoch 42/42\n",
      "524/524 [==============================] - 0s 755us/step - loss: 0.0130 - accuracy: 0.9969 - precision_118: 0.9941 - recall_118: 0.9998 - false_positives_118: 17.3733\n",
      "Epoch 1/72\n",
      "524/524 [==============================] - 1s 825us/step - loss: 0.5414 - accuracy: 0.7778 - precision_119: 0.8138 - recall_119: 0.7078 - false_positives_119: 249.8952\n",
      "Epoch 2/72\n",
      "524/524 [==============================] - 0s 792us/step - loss: 0.0562 - accuracy: 0.9862 - precision_119: 0.9769 - recall_119: 0.9960 - false_positives_119: 59.7829\n",
      "Epoch 3/72\n",
      "524/524 [==============================] - 0s 800us/step - loss: 0.0461 - accuracy: 0.9903 - precision_119: 0.9829 - recall_119: 0.9977 - false_positives_119: 44.2514\n",
      "Epoch 4/72\n",
      "524/524 [==============================] - 0s 762us/step - loss: 0.0365 - accuracy: 0.9922 - precision_119: 0.9857 - recall_119: 0.9991 - false_positives_119: 38.9924\n",
      "Epoch 5/72\n",
      "524/524 [==============================] - 0s 785us/step - loss: 0.0346 - accuracy: 0.9937 - precision_119: 0.9886 - recall_119: 0.9989 - false_positives_119: 31.8095\n",
      "Epoch 6/72\n",
      "524/524 [==============================] - 0s 785us/step - loss: 0.0308 - accuracy: 0.9937 - precision_119: 0.9891 - recall_119: 0.9985 - false_positives_119: 30.1390\n",
      "Epoch 7/72\n",
      "524/524 [==============================] - 0s 769us/step - loss: 0.0296 - accuracy: 0.9938 - precision_119: 0.9893 - recall_119: 0.9983 - false_positives_119: 29.4248\n",
      "Epoch 8/72\n",
      "524/524 [==============================] - 0s 787us/step - loss: 0.0264 - accuracy: 0.9950 - precision_119: 0.9913 - recall_119: 0.9986 - false_positives_119: 25.1562\n",
      "Epoch 9/72\n",
      "524/524 [==============================] - 0s 794us/step - loss: 0.0285 - accuracy: 0.9941 - precision_119: 0.9888 - recall_119: 0.9995 - false_positives_119: 28.2952\n",
      "Epoch 10/72\n",
      "524/524 [==============================] - 0s 766us/step - loss: 0.0271 - accuracy: 0.9950 - precision_119: 0.9904 - recall_119: 0.9999 - false_positives_119: 24.6800\n",
      "Epoch 11/72\n",
      "524/524 [==============================] - 0s 797us/step - loss: 0.0251 - accuracy: 0.9952 - precision_119: 0.9911 - recall_119: 0.9994 - false_positives_119: 24.2571\n",
      "Epoch 12/72\n",
      "524/524 [==============================] - 0s 787us/step - loss: 0.0235 - accuracy: 0.9957 - precision_119: 0.9922 - recall_119: 0.9994 - false_positives_119: 22.8571\n",
      "Epoch 13/72\n",
      "524/524 [==============================] - 0s 873us/step - loss: 0.0234 - accuracy: 0.9955 - precision_119: 0.9919 - recall_119: 0.9992 - false_positives_119: 25.1314\n",
      "Epoch 14/72\n",
      "524/524 [==============================] - 0s 842us/step - loss: 0.0238 - accuracy: 0.9950 - precision_119: 0.9905 - recall_119: 0.9997 - false_positives_119: 27.2152\n",
      "Epoch 15/72\n",
      "524/524 [==============================] - 0s 790us/step - loss: 0.0207 - accuracy: 0.9964 - precision_119: 0.9928 - recall_119: 1.0000 - false_positives_119: 19.8286\n",
      "Epoch 16/72\n",
      "524/524 [==============================] - 0s 789us/step - loss: 0.0244 - accuracy: 0.9953 - precision_119: 0.9913 - recall_119: 0.9995 - false_positives_119: 21.1924\n",
      "Epoch 17/72\n",
      "524/524 [==============================] - 0s 765us/step - loss: 0.0189 - accuracy: 0.9960 - precision_119: 0.9922 - recall_119: 0.9997 - false_positives_119: 18.8971\n",
      "Epoch 18/72\n",
      "524/524 [==============================] - 0s 845us/step - loss: 0.0234 - accuracy: 0.9958 - precision_119: 0.9916 - recall_119: 1.0000 - false_positives_119: 22.4190\n",
      "Epoch 19/72\n",
      "524/524 [==============================] - 0s 810us/step - loss: 0.0219 - accuracy: 0.9954 - precision_119: 0.9916 - recall_119: 0.9991 - false_positives_119: 22.3086\n",
      "Epoch 20/72\n",
      "524/524 [==============================] - 0s 780us/step - loss: 0.0213 - accuracy: 0.9958 - precision_119: 0.9921 - recall_119: 0.9995 - false_positives_119: 20.5429\n",
      "Epoch 21/72\n",
      "524/524 [==============================] - 0s 834us/step - loss: 0.0201 - accuracy: 0.9962 - precision_119: 0.9925 - recall_119: 1.0000 - false_positives_119: 19.6038\n",
      "Epoch 22/72\n",
      "524/524 [==============================] - 0s 816us/step - loss: 0.0152 - accuracy: 0.9969 - precision_119: 0.9943 - recall_119: 0.9995 - false_positives_119: 17.8857\n",
      "Epoch 23/72\n",
      "524/524 [==============================] - 1s 989us/step - loss: 0.0196 - accuracy: 0.9960 - precision_119: 0.9925 - recall_119: 0.9994 - false_positives_119: 20.5848\n",
      "Epoch 24/72\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0187 - accuracy: 0.9968 - precision_119: 0.9940 - recall_119: 0.9998 - false_positives_119: 17.5543\n",
      "Epoch 25/72\n",
      "524/524 [==============================] - 0s 813us/step - loss: 0.0164 - accuracy: 0.9968 - precision_119: 0.9943 - recall_119: 0.9993 - false_positives_119: 16.7543\n",
      "Epoch 26/72\n",
      "524/524 [==============================] - 0s 932us/step - loss: 0.0190 - accuracy: 0.9959 - precision_119: 0.9921 - recall_119: 0.9998 - false_positives_119: 19.6686\n",
      "Epoch 27/72\n",
      "524/524 [==============================] - 0s 798us/step - loss: 0.0228 - accuracy: 0.9950 - precision_119: 0.9905 - recall_119: 0.9997 - false_positives_119: 22.6057\n",
      "Epoch 28/72\n",
      "524/524 [==============================] - 0s 824us/step - loss: 0.0159 - accuracy: 0.9970 - precision_119: 0.9945 - recall_119: 0.9995 - false_positives_119: 17.1295\n",
      "Epoch 29/72\n",
      "524/524 [==============================] - 0s 898us/step - loss: 0.0168 - accuracy: 0.9966 - precision_119: 0.9933 - recall_119: 0.9999 - false_positives_119: 17.6857\n",
      "Epoch 30/72\n",
      "524/524 [==============================] - 0s 853us/step - loss: 0.0156 - accuracy: 0.9970 - precision_119: 0.9942 - recall_119: 0.9997 - false_positives_119: 17.3124\n",
      "Epoch 31/72\n",
      "524/524 [==============================] - 0s 856us/step - loss: 0.0135 - accuracy: 0.9974 - precision_119: 0.9948 - recall_119: 0.9999 - false_positives_119: 15.1162\n",
      "Epoch 32/72\n",
      "524/524 [==============================] - 0s 805us/step - loss: 0.0143 - accuracy: 0.9970 - precision_119: 0.9942 - recall_119: 0.9999 - false_positives_119: 15.9752\n",
      "Epoch 33/72\n",
      "524/524 [==============================] - 0s 836us/step - loss: 0.0205 - accuracy: 0.9952 - precision_119: 0.9919 - recall_119: 0.9986 - false_positives_119: 18.2667\n",
      "Epoch 34/72\n",
      "524/524 [==============================] - 0s 776us/step - loss: 0.0141 - accuracy: 0.9964 - precision_119: 0.9937 - recall_119: 0.9991 - false_positives_119: 15.9086\n",
      "Epoch 35/72\n",
      "524/524 [==============================] - 0s 860us/step - loss: 0.0179 - accuracy: 0.9960 - precision_119: 0.9930 - recall_119: 0.9991 - false_positives_119: 18.1905\n",
      "Epoch 36/72\n",
      "524/524 [==============================] - 0s 855us/step - loss: 0.0184 - accuracy: 0.9966 - precision_119: 0.9940 - recall_119: 0.9991 - false_positives_119: 17.2343\n",
      "Epoch 37/72\n",
      "524/524 [==============================] - 0s 829us/step - loss: 0.0144 - accuracy: 0.9971 - precision_119: 0.9943 - recall_119: 0.9999 - false_positives_119: 16.4914\n",
      "Epoch 38/72\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 0s 761us/step - loss: 0.0175 - accuracy: 0.9967 - precision_119: 0.9939 - recall_119: 0.9996 - false_positives_119: 17.4362\n",
      "Epoch 39/72\n",
      "524/524 [==============================] - 0s 819us/step - loss: 0.0135 - accuracy: 0.9968 - precision_119: 0.9940 - recall_119: 0.9998 - false_positives_119: 17.6933\n",
      "Epoch 40/72\n",
      "524/524 [==============================] - 0s 910us/step - loss: 0.0185 - accuracy: 0.9959 - precision_119: 0.9929 - recall_119: 0.9989 - false_positives_119: 17.2762\n",
      "Epoch 41/72\n",
      "524/524 [==============================] - 0s 892us/step - loss: 0.0120 - accuracy: 0.9979 - precision_119: 0.9959 - recall_119: 1.0000 - false_positives_119: 13.1524\n",
      "Epoch 42/72\n",
      "524/524 [==============================] - 1s 965us/step - loss: 0.0225 - accuracy: 0.9943 - precision_119: 0.9901 - recall_119: 0.9985 - false_positives_119: 21.6914\n",
      "Epoch 43/72\n",
      "524/524 [==============================] - 0s 896us/step - loss: 0.0161 - accuracy: 0.9961 - precision_119: 0.9933 - recall_119: 0.9989 - false_positives_119: 15.7829\n",
      "Epoch 44/72\n",
      "524/524 [==============================] - 0s 781us/step - loss: 0.0188 - accuracy: 0.9965 - precision_119: 0.9933 - recall_119: 0.9998 - false_positives_119: 19.0895\n",
      "Epoch 45/72\n",
      "524/524 [==============================] - 0s 818us/step - loss: 0.0124 - accuracy: 0.9977 - precision_119: 0.9955 - recall_119: 0.9998 - false_positives_119: 14.2971\n",
      "Epoch 46/72\n",
      "524/524 [==============================] - 0s 791us/step - loss: 0.0204 - accuracy: 0.9959 - precision_119: 0.9931 - recall_119: 0.9989 - false_positives_119: 18.9924\n",
      "Epoch 47/72\n",
      "524/524 [==============================] - 0s 852us/step - loss: 0.0161 - accuracy: 0.9971 - precision_119: 0.9942 - recall_119: 0.9999 - false_positives_119: 16.2933\n",
      "Epoch 48/72\n",
      "524/524 [==============================] - 0s 857us/step - loss: 0.0118 - accuracy: 0.9972 - precision_119: 0.9958 - recall_119: 0.9986 - false_positives_119: 13.9448\n",
      "Epoch 49/72\n",
      "524/524 [==============================] - 0s 825us/step - loss: 0.0140 - accuracy: 0.9971 - precision_119: 0.9945 - recall_119: 0.9996 - false_positives_119: 14.7010\n",
      "Epoch 50/72\n",
      "524/524 [==============================] - 0s 782us/step - loss: 0.0149 - accuracy: 0.9970 - precision_119: 0.9945 - recall_119: 0.9996 - false_positives_119: 15.1029\n",
      "Epoch 51/72\n",
      "524/524 [==============================] - 0s 812us/step - loss: 0.0175 - accuracy: 0.9968 - precision_119: 0.9936 - recall_119: 1.0000 - false_positives_119: 16.3257\n",
      "Epoch 52/72\n",
      "524/524 [==============================] - 0s 777us/step - loss: 0.0208 - accuracy: 0.9964 - precision_119: 0.9929 - recall_119: 1.0000 - false_positives_119: 18.5257\n",
      "Epoch 53/72\n",
      "524/524 [==============================] - 0s 857us/step - loss: 0.0132 - accuracy: 0.9979 - precision_119: 0.9962 - recall_119: 0.9995 - false_positives_119: 10.9562\n",
      "Epoch 54/72\n",
      "524/524 [==============================] - 1s 976us/step - loss: 0.0151 - accuracy: 0.9973 - precision_119: 0.9946 - recall_119: 1.0000 - false_positives_119: 14.0952\n",
      "Epoch 55/72\n",
      "524/524 [==============================] - 0s 886us/step - loss: 0.0180 - accuracy: 0.9962 - precision_119: 0.9930 - recall_119: 0.9996 - false_positives_119: 16.6629\n",
      "Epoch 56/72\n",
      "524/524 [==============================] - 0s 804us/step - loss: 0.0218 - accuracy: 0.9955 - precision_119: 0.9928 - recall_119: 0.9985 - false_positives_119: 17.9619\n",
      "Epoch 57/72\n",
      "524/524 [==============================] - 0s 841us/step - loss: 0.0210 - accuracy: 0.9961 - precision_119: 0.9928 - recall_119: 0.9994 - false_positives_119: 17.6610\n",
      "Epoch 58/72\n",
      "524/524 [==============================] - 0s 825us/step - loss: 0.0135 - accuracy: 0.9971 - precision_119: 0.9948 - recall_119: 0.9994 - false_positives_119: 14.6324\n",
      "Epoch 59/72\n",
      "524/524 [==============================] - 0s 808us/step - loss: 0.0125 - accuracy: 0.9973 - precision_119: 0.9954 - recall_119: 0.9993 - false_positives_119: 12.0571\n",
      "Epoch 60/72\n",
      "524/524 [==============================] - 0s 850us/step - loss: 0.0162 - accuracy: 0.9969 - precision_119: 0.9941 - recall_119: 0.9996 - false_positives_119: 16.3219\n",
      "Epoch 61/72\n",
      "524/524 [==============================] - 0s 791us/step - loss: 0.0116 - accuracy: 0.9975 - precision_119: 0.9958 - recall_119: 0.9992 - false_positives_119: 13.8114\n",
      "Epoch 62/72\n",
      "524/524 [==============================] - 0s 784us/step - loss: 0.0126 - accuracy: 0.9975 - precision_119: 0.9952 - recall_119: 0.9999 - false_positives_119: 11.5448\n",
      "Epoch 63/72\n",
      "524/524 [==============================] - 0s 751us/step - loss: 0.0141 - accuracy: 0.9971 - precision_119: 0.9949 - recall_119: 0.9993 - false_positives_119: 14.1905\n",
      "Epoch 64/72\n",
      "524/524 [==============================] - 0s 815us/step - loss: 0.0166 - accuracy: 0.9969 - precision_119: 0.9943 - recall_119: 0.9994 - false_positives_119: 14.3790\n",
      "Epoch 65/72\n",
      "524/524 [==============================] - 0s 838us/step - loss: 0.0111 - accuracy: 0.9977 - precision_119: 0.9956 - recall_119: 0.9999 - false_positives_119: 11.5771\n",
      "Epoch 66/72\n",
      "524/524 [==============================] - 0s 796us/step - loss: 0.0153 - accuracy: 0.9974 - precision_119: 0.9950 - recall_119: 0.9998 - false_positives_119: 13.2762\n",
      "Epoch 67/72\n",
      "524/524 [==============================] - 0s 859us/step - loss: 0.0138 - accuracy: 0.9974 - precision_119: 0.9953 - recall_119: 0.9995 - false_positives_119: 14.3543\n",
      "Epoch 68/72\n",
      "524/524 [==============================] - 0s 747us/step - loss: 0.0155 - accuracy: 0.9972 - precision_119: 0.9944 - recall_119: 1.0000 - false_positives_119: 12.8914\n",
      "Epoch 69/72\n",
      "524/524 [==============================] - 0s 814us/step - loss: 0.0170 - accuracy: 0.9965 - precision_119: 0.9940 - recall_119: 0.9991 - false_positives_119: 13.5695\n",
      "Epoch 70/72\n",
      "524/524 [==============================] - 0s 780us/step - loss: 0.0167 - accuracy: 0.9970 - precision_119: 0.9944 - recall_119: 0.9995 - false_positives_119: 14.3524\n",
      "Epoch 71/72\n",
      "524/524 [==============================] - 0s 809us/step - loss: 0.0099 - accuracy: 0.9983 - precision_119: 0.9967 - recall_119: 0.9999 - false_positives_119: 10.8590\n",
      "Epoch 72/72\n",
      "524/524 [==============================] - 0s 788us/step - loss: 0.0188 - accuracy: 0.9957 - precision_119: 0.9925 - recall_119: 0.9990 - false_positives_119: 16.2990\n",
      "Epoch 1/25\n",
      "524/524 [==============================] - 1s 824us/step - loss: 0.3386 - accuracy: 0.8522 - precision_120: 0.8095 - recall_120: 0.9444 - false_positives_120: 401.3543\n",
      "Epoch 2/25\n",
      "524/524 [==============================] - 0s 930us/step - loss: 0.0538 - accuracy: 0.9892 - precision_120: 0.9827 - recall_120: 0.9957 - false_positives_120: 47.5010\n",
      "Epoch 3/25\n",
      "524/524 [==============================] - 0s 889us/step - loss: 0.0462 - accuracy: 0.9904 - precision_120: 0.9837 - recall_120: 0.9977 - false_positives_120: 43.0076\n",
      "Epoch 4/25\n",
      "524/524 [==============================] - 0s 789us/step - loss: 0.0317 - accuracy: 0.9935 - precision_120: 0.9873 - recall_120: 0.9997 - false_positives_120: 33.9676\n",
      "Epoch 5/25\n",
      "524/524 [==============================] - 0s 798us/step - loss: 0.0316 - accuracy: 0.9922 - precision_120: 0.9880 - recall_120: 0.9967 - false_positives_120: 33.3219\n",
      "Epoch 6/25\n",
      "524/524 [==============================] - 0s 802us/step - loss: 0.0342 - accuracy: 0.9925 - precision_120: 0.9873 - recall_120: 0.9978 - false_positives_120: 32.6305\n",
      "Epoch 7/25\n",
      "524/524 [==============================] - 0s 774us/step - loss: 0.0263 - accuracy: 0.9942 - precision_120: 0.9896 - recall_120: 0.9990 - false_positives_120: 29.0248\n",
      "Epoch 8/25\n",
      "524/524 [==============================] - 0s 751us/step - loss: 0.0229 - accuracy: 0.9947 - precision_120: 0.9909 - recall_120: 0.9983 - false_positives_120: 24.4648\n",
      "Epoch 9/25\n",
      "524/524 [==============================] - 0s 763us/step - loss: 0.0239 - accuracy: 0.9950 - precision_120: 0.9905 - recall_120: 0.9997 - false_positives_120: 25.4019\n",
      "Epoch 10/25\n",
      "524/524 [==============================] - 0s 774us/step - loss: 0.0223 - accuracy: 0.9948 - precision_120: 0.9902 - recall_120: 0.9995 - false_positives_120: 26.7619\n",
      "Epoch 11/25\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 0s 768us/step - loss: 0.0233 - accuracy: 0.9948 - precision_120: 0.9903 - recall_120: 0.9994 - false_positives_120: 26.1505\n",
      "Epoch 12/25\n",
      "524/524 [==============================] - 0s 833us/step - loss: 0.0249 - accuracy: 0.9945 - precision_120: 0.9899 - recall_120: 0.9991 - false_positives_120: 25.2343\n",
      "Epoch 13/25\n",
      "524/524 [==============================] - 0s 783us/step - loss: 0.0205 - accuracy: 0.9957 - precision_120: 0.9918 - recall_120: 0.9998 - false_positives_120: 24.1162\n",
      "Epoch 14/25\n",
      "524/524 [==============================] - 0s 800us/step - loss: 0.0221 - accuracy: 0.9946 - precision_120: 0.9895 - recall_120: 0.9999 - false_positives_120: 24.0038\n",
      "Epoch 15/25\n",
      "524/524 [==============================] - 0s 738us/step - loss: 0.0215 - accuracy: 0.9945 - precision_120: 0.9896 - recall_120: 0.9995 - false_positives_120: 25.3029\n",
      "Epoch 16/25\n",
      "524/524 [==============================] - 0s 777us/step - loss: 0.0202 - accuracy: 0.9957 - precision_120: 0.9918 - recall_120: 0.9997 - false_positives_120: 22.6152\n",
      "Epoch 17/25\n",
      "524/524 [==============================] - 0s 752us/step - loss: 0.0180 - accuracy: 0.9963 - precision_120: 0.9931 - recall_120: 0.9995 - false_positives_120: 18.9352\n",
      "Epoch 18/25\n",
      "524/524 [==============================] - 0s 739us/step - loss: 0.0213 - accuracy: 0.9950 - precision_120: 0.9909 - recall_120: 0.9991 - false_positives_120: 24.4400\n",
      "Epoch 19/25\n",
      "524/524 [==============================] - 0s 831us/step - loss: 0.0188 - accuracy: 0.9953 - precision_120: 0.9914 - recall_120: 0.9993 - false_positives_120: 24.1467\n",
      "Epoch 20/25\n",
      "524/524 [==============================] - 0s 765us/step - loss: 0.0175 - accuracy: 0.9961 - precision_120: 0.9923 - recall_120: 0.9998 - false_positives_120: 21.1810\n",
      "Epoch 21/25\n",
      "524/524 [==============================] - 0s 766us/step - loss: 0.0166 - accuracy: 0.9955 - precision_120: 0.9923 - recall_120: 0.9988 - false_positives_120: 21.0000\n",
      "Epoch 22/25\n",
      "524/524 [==============================] - 0s 743us/step - loss: 0.0144 - accuracy: 0.9967 - precision_120: 0.9935 - recall_120: 0.9999 - false_positives_120: 19.7562\n",
      "Epoch 23/25\n",
      "524/524 [==============================] - 0s 754us/step - loss: 0.0158 - accuracy: 0.9966 - precision_120: 0.9939 - recall_120: 0.9993 - false_positives_120: 16.6971\n",
      "Epoch 24/25\n",
      "524/524 [==============================] - 0s 800us/step - loss: 0.0188 - accuracy: 0.9960 - precision_120: 0.9928 - recall_120: 0.9994 - false_positives_120: 20.4762\n",
      "Epoch 25/25\n",
      "524/524 [==============================] - 0s 743us/step - loss: 0.0125 - accuracy: 0.9970 - precision_120: 0.9948 - recall_120: 0.9992 - false_positives_120: 16.3810\n",
      "Epoch 1/150\n",
      "524/524 [==============================] - 1s 784us/step - loss: 0.4933 - accuracy: 0.7999 - precision_121: 0.7337 - recall_121: 0.9871 - false_positives_121: 739.7219\n",
      "Epoch 2/150\n",
      "524/524 [==============================] - 0s 801us/step - loss: 0.2754 - accuracy: 0.9792 - precision_121: 0.9794 - recall_121: 0.9791 - false_positives_121: 49.4762\n",
      "Epoch 3/150\n",
      "524/524 [==============================] - 0s 736us/step - loss: 0.2049 - accuracy: 0.9821 - precision_121: 0.9864 - recall_121: 0.9779 - false_positives_121: 38.3048\n",
      "Epoch 4/150\n",
      "524/524 [==============================] - 0s 780us/step - loss: 0.1639 - accuracy: 0.9863 - precision_121: 0.9844 - recall_121: 0.9876 - false_positives_121: 40.9695\n",
      "Epoch 5/150\n",
      "524/524 [==============================] - 0s 782us/step - loss: 0.1268 - accuracy: 0.9903 - precision_121: 0.9853 - recall_121: 0.9951 - false_positives_121: 35.1295\n",
      "Epoch 6/150\n",
      "524/524 [==============================] - 0s 871us/step - loss: 0.1097 - accuracy: 0.9897 - precision_121: 0.9848 - recall_121: 0.9947 - false_positives_121: 35.8971\n",
      "Epoch 7/150\n",
      "524/524 [==============================] - 0s 897us/step - loss: 0.0853 - accuracy: 0.9916 - precision_121: 0.9885 - recall_121: 0.9946 - false_positives_121: 28.88190s - loss: 0.0846 - accuracy: 0.9915 - precision_121: 0.9883 - recall_121: 0.9946 - false_positives_121:\n",
      "Epoch 8/150\n",
      "524/524 [==============================] - 0s 797us/step - loss: 0.0706 - accuracy: 0.9919 - precision_121: 0.9887 - recall_121: 0.9951 - false_positives_121: 28.8419\n",
      "Epoch 9/150\n",
      "524/524 [==============================] - 0s 787us/step - loss: 0.0587 - accuracy: 0.9939 - precision_121: 0.9912 - recall_121: 0.9965 - false_positives_121: 25.0762\n",
      "Epoch 10/150\n",
      "524/524 [==============================] - 0s 762us/step - loss: 0.0557 - accuracy: 0.9939 - precision_121: 0.9905 - recall_121: 0.9973 - false_positives_121: 25.3638\n",
      "Epoch 11/150\n",
      "524/524 [==============================] - 0s 783us/step - loss: 0.0529 - accuracy: 0.9944 - precision_121: 0.9906 - recall_121: 0.9985 - false_positives_121: 24.9543\n",
      "Epoch 12/150\n",
      "524/524 [==============================] - 0s 763us/step - loss: 0.0464 - accuracy: 0.9950 - precision_121: 0.9918 - recall_121: 0.9983 - false_positives_121: 21.4781\n",
      "Epoch 13/150\n",
      "524/524 [==============================] - 0s 853us/step - loss: 0.0455 - accuracy: 0.9949 - precision_121: 0.9920 - recall_121: 0.9978 - false_positives_121: 22.5524\n",
      "Epoch 14/150\n",
      "524/524 [==============================] - 0s 799us/step - loss: 0.0386 - accuracy: 0.9946 - precision_121: 0.9922 - recall_121: 0.9971 - false_positives_121: 21.9429\n",
      "Epoch 15/150\n",
      "524/524 [==============================] - 0s 780us/step - loss: 0.0334 - accuracy: 0.9956 - precision_121: 0.9929 - recall_121: 0.9984 - false_positives_121: 19.0933\n",
      "Epoch 16/150\n",
      "524/524 [==============================] - 0s 790us/step - loss: 0.0396 - accuracy: 0.9945 - precision_121: 0.9916 - recall_121: 0.9972 - false_positives_121: 23.8514\n",
      "Epoch 17/150\n",
      "524/524 [==============================] - 0s 817us/step - loss: 0.0281 - accuracy: 0.9960 - precision_121: 0.9937 - recall_121: 0.9983 - false_positives_121: 17.2876\n",
      "Epoch 18/150\n",
      "524/524 [==============================] - 0s 847us/step - loss: 0.0251 - accuracy: 0.9966 - precision_121: 0.9953 - recall_121: 0.9981 - false_positives_121: 15.4019\n",
      "Epoch 19/150\n",
      "524/524 [==============================] - 0s 771us/step - loss: 0.0296 - accuracy: 0.9961 - precision_121: 0.9929 - recall_121: 0.9993 - false_positives_121: 19.5543\n",
      "Epoch 20/150\n",
      "524/524 [==============================] - 0s 817us/step - loss: 0.0273 - accuracy: 0.9965 - precision_121: 0.9940 - recall_121: 0.9990 - false_positives_121: 17.6114\n",
      "Epoch 21/150\n",
      "524/524 [==============================] - 0s 954us/step - loss: 0.0293 - accuracy: 0.9956 - precision_121: 0.9920 - recall_121: 0.9993 - false_positives_121: 20.5695\n",
      "Epoch 22/150\n",
      "524/524 [==============================] - 0s 819us/step - loss: 0.0308 - accuracy: 0.9953 - precision_121: 0.9918 - recall_121: 0.9989 - false_positives_121: 20.1867\n",
      "Epoch 23/150\n",
      "524/524 [==============================] - 0s 876us/step - loss: 0.0266 - accuracy: 0.9957 - precision_121: 0.9919 - recall_121: 0.9994 - false_positives_121: 20.1029\n",
      "Epoch 24/150\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0250 - accuracy: 0.9967 - precision_121: 0.9942 - recall_121: 0.9994 - false_positives_121: 18.3219A: 0s - loss: 0.0236 - accuracy: 0.9970 - precision_121: 0.9947 - recall_121: 0.9995 - false_positives_12\n",
      "Epoch 25/150\n",
      "524/524 [==============================] - 0s 776us/step - loss: 0.0237 - accuracy: 0.9963 - precision_121: 0.9936 - recall_121: 0.9990 - false_positives_121: 17.9124\n",
      "Epoch 26/150\n",
      "524/524 [==============================] - 0s 756us/step - loss: 0.0226 - accuracy: 0.9964 - precision_121: 0.9930 - recall_121: 0.9997 - false_positives_121: 19.6476\n",
      "Epoch 27/150\n",
      "524/524 [==============================] - 0s 775us/step - loss: 0.0226 - accuracy: 0.9963 - precision_121: 0.9936 - recall_121: 0.9990 - false_positives_121: 17.5848\n",
      "Epoch 28/150\n",
      "524/524 [==============================] - 0s 918us/step - loss: 0.0224 - accuracy: 0.9964 - precision_121: 0.9933 - recall_121: 0.9996 - false_positives_121: 17.6800\n",
      "Epoch 29/150\n",
      "524/524 [==============================] - 0s 870us/step - loss: 0.0233 - accuracy: 0.9965 - precision_121: 0.9931 - recall_121: 0.9999 - false_positives_121: 17.9638\n",
      "Epoch 30/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 0s 832us/step - loss: 0.0251 - accuracy: 0.9959 - precision_121: 0.9935 - recall_121: 0.9981 - false_positives_121: 17.4419\n",
      "Epoch 31/150\n",
      "524/524 [==============================] - 0s 794us/step - loss: 0.0192 - accuracy: 0.9973 - precision_121: 0.9947 - recall_121: 0.9999 - false_positives_121: 16.5010\n",
      "Epoch 32/150\n",
      "524/524 [==============================] - 0s 818us/step - loss: 0.0233 - accuracy: 0.9962 - precision_121: 0.9924 - recall_121: 1.0000 - false_positives_121: 19.4362\n",
      "Epoch 33/150\n",
      "524/524 [==============================] - 0s 808us/step - loss: 0.0258 - accuracy: 0.9958 - precision_121: 0.9932 - recall_121: 0.9984 - false_positives_121: 18.2648\n",
      "Epoch 34/150\n",
      "524/524 [==============================] - 0s 780us/step - loss: 0.0173 - accuracy: 0.9972 - precision_121: 0.9950 - recall_121: 0.9996 - false_positives_121: 15.5619\n",
      "Epoch 35/150\n",
      "524/524 [==============================] - 0s 744us/step - loss: 0.0184 - accuracy: 0.9967 - precision_121: 0.9939 - recall_121: 0.9994 - false_positives_121: 17.2952\n",
      "Epoch 36/150\n",
      "524/524 [==============================] - 0s 784us/step - loss: 0.0183 - accuracy: 0.9964 - precision_121: 0.9932 - recall_121: 0.9996 - false_positives_121: 17.3162\n",
      "Epoch 37/150\n",
      "524/524 [==============================] - 0s 837us/step - loss: 0.0183 - accuracy: 0.9963 - precision_121: 0.9932 - recall_121: 0.9993 - false_positives_121: 16.7257\n",
      "Epoch 38/150\n",
      "524/524 [==============================] - 0s 749us/step - loss: 0.0189 - accuracy: 0.9968 - precision_121: 0.9942 - recall_121: 0.9995 - false_positives_121: 16.0038\n",
      "Epoch 39/150\n",
      "524/524 [==============================] - 0s 862us/step - loss: 0.0206 - accuracy: 0.9971 - precision_121: 0.9942 - recall_121: 1.0000 - false_positives_121: 16.0705\n",
      "Epoch 40/150\n",
      "524/524 [==============================] - 0s 739us/step - loss: 0.0145 - accuracy: 0.9976 - precision_121: 0.9957 - recall_121: 0.9996 - false_positives_121: 10.9524\n",
      "Epoch 41/150\n",
      "524/524 [==============================] - 0s 831us/step - loss: 0.0215 - accuracy: 0.9971 - precision_121: 0.9943 - recall_121: 0.9999 - false_positives_121: 14.2857\n",
      "Epoch 42/150\n",
      "524/524 [==============================] - 0s 912us/step - loss: 0.0150 - accuracy: 0.9978 - precision_121: 0.9958 - recall_121: 0.9998 - false_positives_121: 13.7029\n",
      "Epoch 43/150\n",
      "524/524 [==============================] - 0s 856us/step - loss: 0.0126 - accuracy: 0.9967 - precision_121: 0.9954 - recall_121: 0.9980 - false_positives_121: 13.2533\n",
      "Epoch 44/150\n",
      "524/524 [==============================] - 0s 931us/step - loss: 0.0185 - accuracy: 0.9963 - precision_121: 0.9935 - recall_121: 0.9992 - false_positives_121: 16.0781\n",
      "Epoch 45/150\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0189 - accuracy: 0.9966 - precision_121: 0.9936 - recall_121: 0.9995 - false_positives_121: 15.7029\n",
      "Epoch 46/150\n",
      "524/524 [==============================] - 0s 797us/step - loss: 0.0161 - accuracy: 0.9971 - precision_121: 0.9945 - recall_121: 0.9996 - false_positives_121: 15.0362\n",
      "Epoch 47/150\n",
      "524/524 [==============================] - 0s 765us/step - loss: 0.0134 - accuracy: 0.9977 - precision_121: 0.9955 - recall_121: 1.0000 - false_positives_121: 13.2038\n",
      "Epoch 48/150\n",
      "524/524 [==============================] - 0s 749us/step - loss: 0.0124 - accuracy: 0.9983 - precision_121: 0.9967 - recall_121: 1.0000 - false_positives_121: 11.0933\n",
      "Epoch 49/150\n",
      "524/524 [==============================] - 0s 935us/step - loss: 0.0132 - accuracy: 0.9972 - precision_121: 0.9953 - recall_121: 0.9991 - false_positives_121: 13.6438\n",
      "Epoch 50/150\n",
      "524/524 [==============================] - 0s 831us/step - loss: 0.0119 - accuracy: 0.9977 - precision_121: 0.9959 - recall_121: 0.9997 - false_positives_121: 11.6800\n",
      "Epoch 51/150\n",
      "524/524 [==============================] - 0s 750us/step - loss: 0.0166 - accuracy: 0.9964 - precision_121: 0.9940 - recall_121: 0.9988 - false_positives_121: 15.5943\n",
      "Epoch 52/150\n",
      "524/524 [==============================] - 1s 1ms/step - loss: 0.0137 - accuracy: 0.9976 - precision_121: 0.9952 - recall_121: 1.0000 - false_positives_121: 13.1790\n",
      "Epoch 53/150\n",
      "524/524 [==============================] - 0s 803us/step - loss: 0.0189 - accuracy: 0.9968 - precision_121: 0.9938 - recall_121: 0.9999 - false_positives_121: 14.9581\n",
      "Epoch 54/150\n",
      "524/524 [==============================] - 0s 808us/step - loss: 0.0171 - accuracy: 0.9969 - precision_121: 0.9945 - recall_121: 0.9993 - false_positives_121: 13.7143\n",
      "Epoch 55/150\n",
      "524/524 [==============================] - 0s 849us/step - loss: 0.0143 - accuracy: 0.9966 - precision_121: 0.9940 - recall_121: 0.9994 - false_positives_121: 13.0762\n",
      "Epoch 56/150\n",
      "524/524 [==============================] - 0s 842us/step - loss: 0.0110 - accuracy: 0.9982 - precision_121: 0.9967 - recall_121: 0.9997 - false_positives_121: 10.8343\n",
      "Epoch 57/150\n",
      "524/524 [==============================] - 0s 807us/step - loss: 0.0164 - accuracy: 0.9965 - precision_121: 0.9933 - recall_121: 0.9998 - false_positives_121: 14.8990\n",
      "Epoch 58/150\n",
      "524/524 [==============================] - 0s 821us/step - loss: 0.0144 - accuracy: 0.9972 - precision_121: 0.9946 - recall_121: 0.9998 - false_positives_121: 14.0400\n",
      "Epoch 59/150\n",
      "524/524 [==============================] - 0s 868us/step - loss: 0.0078 - accuracy: 0.9988 - precision_121: 0.9977 - recall_121: 0.9999 - false_positives_121: 8.5867\n",
      "Epoch 60/150\n",
      "524/524 [==============================] - 0s 804us/step - loss: 0.0148 - accuracy: 0.9975 - precision_121: 0.9951 - recall_121: 0.9999 - false_positives_121: 11.5105\n",
      "Epoch 61/150\n",
      "524/524 [==============================] - 0s 793us/step - loss: 0.0102 - accuracy: 0.9981 - precision_121: 0.9966 - recall_121: 0.9996 - false_positives_121: 10.3352\n",
      "Epoch 62/150\n",
      "524/524 [==============================] - 0s 830us/step - loss: 0.0165 - accuracy: 0.9977 - precision_121: 0.9954 - recall_121: 1.0000 - false_positives_121: 11.9905\n",
      "Epoch 63/150\n",
      "524/524 [==============================] - 0s 795us/step - loss: 0.0120 - accuracy: 0.9977 - precision_121: 0.9957 - recall_121: 0.9996 - false_positives_121: 11.5486\n",
      "Epoch 64/150\n",
      "524/524 [==============================] - 0s 790us/step - loss: 0.0136 - accuracy: 0.9975 - precision_121: 0.9949 - recall_121: 1.0000 - false_positives_121: 13.7181\n",
      "Epoch 65/150\n",
      "524/524 [==============================] - 0s 796us/step - loss: 0.0170 - accuracy: 0.9968 - precision_121: 0.9939 - recall_121: 0.9997 - false_positives_121: 14.8762\n",
      "Epoch 66/150\n",
      "524/524 [==============================] - 0s 820us/step - loss: 0.0169 - accuracy: 0.9967 - precision_121: 0.9936 - recall_121: 0.9999 - false_positives_121: 14.8610\n",
      "Epoch 67/150\n",
      "524/524 [==============================] - 0s 813us/step - loss: 0.0119 - accuracy: 0.9980 - precision_121: 0.9963 - recall_121: 0.9997 - false_positives_121: 11.3962\n",
      "Epoch 68/150\n",
      "524/524 [==============================] - 0s 848us/step - loss: 0.0141 - accuracy: 0.9981 - precision_121: 0.9964 - recall_121: 0.9999 - false_positives_121: 9.4533\n",
      "Epoch 69/150\n",
      "524/524 [==============================] - 0s 796us/step - loss: 0.0159 - accuracy: 0.9975 - precision_121: 0.9951 - recall_121: 0.9999 - false_positives_121: 11.9771\n",
      "Epoch 70/150\n",
      "524/524 [==============================] - 0s 926us/step - loss: 0.0138 - accuracy: 0.9973 - precision_121: 0.9949 - recall_121: 0.9998 - false_positives_121: 13.4019\n",
      "Epoch 71/150\n",
      "524/524 [==============================] - 0s 762us/step - loss: 0.0131 - accuracy: 0.9979 - precision_121: 0.9957 - recall_121: 1.0000 - false_positives_121: 12.1429\n",
      "Epoch 72/150\n",
      "524/524 [==============================] - 0s 822us/step - loss: 0.0155 - accuracy: 0.9977 - precision_121: 0.9957 - recall_121: 0.9999 - false_positives_121: 11.4000\n",
      "Epoch 73/150\n",
      "524/524 [==============================] - 0s 798us/step - loss: 0.0126 - accuracy: 0.9971 - precision_121: 0.9953 - recall_121: 0.9989 - false_positives_121: 12.8190\n",
      "Epoch 74/150\n",
      "524/524 [==============================] - 0s 804us/step - loss: 0.0117 - accuracy: 0.9978 - precision_121: 0.9957 - recall_121: 1.0000 - false_positives_121: 12.8267\n",
      "Epoch 75/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 0s 808us/step - loss: 0.0148 - accuracy: 0.9972 - precision_121: 0.9956 - recall_121: 0.9988 - false_positives_121: 11.9333\n",
      "Epoch 76/150\n",
      "524/524 [==============================] - 0s 820us/step - loss: 0.0125 - accuracy: 0.9980 - precision_121: 0.9970 - recall_121: 0.9990 - false_positives_121: 9.7390\n",
      "Epoch 77/150\n",
      "524/524 [==============================] - 0s 821us/step - loss: 0.0124 - accuracy: 0.9974 - precision_121: 0.9957 - recall_121: 0.9993 - false_positives_121: 11.9638\n",
      "Epoch 78/150\n",
      "524/524 [==============================] - 0s 817us/step - loss: 0.0146 - accuracy: 0.9971 - precision_121: 0.9943 - recall_121: 1.0000 - false_positives_121: 14.4724\n",
      "Epoch 79/150\n",
      "524/524 [==============================] - 0s 859us/step - loss: 0.0170 - accuracy: 0.9971 - precision_121: 0.9943 - recall_121: 0.9999 - false_positives_121: 14.2895\n",
      "Epoch 80/150\n",
      "524/524 [==============================] - 0s 822us/step - loss: 0.0092 - accuracy: 0.9983 - precision_121: 0.9968 - recall_121: 0.9997 - false_positives_121: 10.1143\n",
      "Epoch 81/150\n",
      "524/524 [==============================] - 0s 806us/step - loss: 0.0096 - accuracy: 0.9982 - precision_121: 0.9968 - recall_121: 0.9995 - false_positives_121: 9.6552\n",
      "Epoch 82/150\n",
      "524/524 [==============================] - 0s 828us/step - loss: 0.0162 - accuracy: 0.9975 - precision_121: 0.9950 - recall_121: 0.9999 - false_positives_121: 11.4629\n",
      "Epoch 83/150\n",
      "524/524 [==============================] - 0s 812us/step - loss: 0.0160 - accuracy: 0.9974 - precision_121: 0.9950 - recall_121: 0.9999 - false_positives_121: 12.1333\n",
      "Epoch 84/150\n",
      "524/524 [==============================] - 0s 845us/step - loss: 0.0134 - accuracy: 0.9977 - precision_121: 0.9958 - recall_121: 0.9996 - false_positives_121: 11.4667\n",
      "Epoch 85/150\n",
      "524/524 [==============================] - 0s 799us/step - loss: 0.0089 - accuracy: 0.9985 - precision_121: 0.9977 - recall_121: 0.9992 - false_positives_121: 7.3219\n",
      "Epoch 86/150\n",
      "524/524 [==============================] - 0s 821us/step - loss: 0.0144 - accuracy: 0.9973 - precision_121: 0.9952 - recall_121: 0.9996 - false_positives_121: 9.8381\n",
      "Epoch 87/150\n",
      "524/524 [==============================] - 0s 826us/step - loss: 0.0138 - accuracy: 0.9965 - precision_121: 0.9946 - recall_121: 0.9985 - false_positives_121: 13.4990\n",
      "Epoch 88/150\n",
      "524/524 [==============================] - 0s 765us/step - loss: 0.0115 - accuracy: 0.9982 - precision_121: 0.9964 - recall_121: 1.0000 - false_positives_121: 10.3714\n",
      "Epoch 89/150\n",
      "524/524 [==============================] - 0s 815us/step - loss: 0.0206 - accuracy: 0.9963 - precision_121: 0.9933 - recall_121: 0.9996 - false_positives_121: 13.6286\n",
      "Epoch 90/150\n",
      "524/524 [==============================] - 0s 786us/step - loss: 0.0119 - accuracy: 0.9979 - precision_121: 0.9958 - recall_121: 1.0000 - false_positives_121: 11.7886\n",
      "Epoch 91/150\n",
      "524/524 [==============================] - 0s 824us/step - loss: 0.0127 - accuracy: 0.9972 - precision_121: 0.9944 - recall_121: 0.9999 - false_positives_121: 12.6743\n",
      "Epoch 92/150\n",
      "524/524 [==============================] - 0s 860us/step - loss: 0.0130 - accuracy: 0.9977 - precision_121: 0.9958 - recall_121: 0.9997 - false_positives_121: 11.3486\n",
      "Epoch 93/150\n",
      "524/524 [==============================] - 0s 928us/step - loss: 0.0154 - accuracy: 0.9973 - precision_121: 0.9951 - recall_121: 0.9996 - false_positives_121: 13.8476\n",
      "Epoch 94/150\n",
      "524/524 [==============================] - 0s 801us/step - loss: 0.0163 - accuracy: 0.9967 - precision_121: 0.9936 - recall_121: 0.9999 - false_positives_121: 14.9905\n",
      "Epoch 95/150\n",
      "524/524 [==============================] - 0s 761us/step - loss: 0.0135 - accuracy: 0.9978 - precision_121: 0.9957 - recall_121: 1.0000 - false_positives_121: 11.0762\n",
      "Epoch 96/150\n",
      "524/524 [==============================] - 0s 823us/step - loss: 0.0145 - accuracy: 0.9973 - precision_121: 0.9949 - recall_121: 0.9998 - false_positives_121: 13.2133\n",
      "Epoch 97/150\n",
      "524/524 [==============================] - 0s 811us/step - loss: 0.0136 - accuracy: 0.9967 - precision_121: 0.9945 - recall_121: 0.9990 - false_positives_121: 12.8610\n",
      "Epoch 98/150\n",
      "524/524 [==============================] - 0s 857us/step - loss: 0.0101 - accuracy: 0.9978 - precision_121: 0.9964 - recall_121: 0.9992 - false_positives_121: 10.7505\n",
      "Epoch 99/150\n",
      "524/524 [==============================] - 0s 766us/step - loss: 0.0123 - accuracy: 0.9974 - precision_121: 0.9950 - recall_121: 0.9998 - false_positives_121: 11.5390\n",
      "Epoch 100/150\n",
      "524/524 [==============================] - 0s 832us/step - loss: 0.0119 - accuracy: 0.9980 - precision_121: 0.9962 - recall_121: 0.9998 - false_positives_121: 9.3943\n",
      "Epoch 101/150\n",
      "524/524 [==============================] - 0s 786us/step - loss: 0.0089 - accuracy: 0.9985 - precision_121: 0.9969 - recall_121: 1.0000 - false_positives_121: 8.9733\n",
      "Epoch 102/150\n",
      "524/524 [==============================] - 0s 829us/step - loss: 0.0129 - accuracy: 0.9980 - precision_121: 0.9964 - recall_121: 0.9996 - false_positives_121: 9.6190\n",
      "Epoch 103/150\n",
      "524/524 [==============================] - 0s 855us/step - loss: 0.0125 - accuracy: 0.9979 - precision_121: 0.9965 - recall_121: 0.9993 - false_positives_121: 9.9371\n",
      "Epoch 104/150\n",
      "524/524 [==============================] - 0s 806us/step - loss: 0.0155 - accuracy: 0.9970 - precision_121: 0.9954 - recall_121: 0.9987 - false_positives_121: 12.5695\n",
      "Epoch 105/150\n",
      "524/524 [==============================] - 0s 814us/step - loss: 0.0133 - accuracy: 0.9975 - precision_121: 0.9951 - recall_121: 1.0000 - false_positives_121: 12.5962\n",
      "Epoch 106/150\n",
      "524/524 [==============================] - 0s 796us/step - loss: 0.0083 - accuracy: 0.9979 - precision_121: 0.9966 - recall_121: 0.9992 - false_positives_121: 9.8457\n",
      "Epoch 107/150\n",
      "524/524 [==============================] - 0s 764us/step - loss: 0.0092 - accuracy: 0.9977 - precision_121: 0.9962 - recall_121: 0.9993 - false_positives_121: 10.7505\n",
      "Epoch 108/150\n",
      "524/524 [==============================] - 0s 888us/step - loss: 0.0192 - accuracy: 0.9966 - precision_121: 0.9932 - recall_121: 1.0000 - false_positives_121: 14.2971\n",
      "Epoch 109/150\n",
      "524/524 [==============================] - 0s 791us/step - loss: 0.0146 - accuracy: 0.9971 - precision_121: 0.9944 - recall_121: 0.9998 - false_positives_121: 13.1981\n",
      "Epoch 110/150\n",
      "524/524 [==============================] - 0s 798us/step - loss: 0.0128 - accuracy: 0.9979 - precision_121: 0.9969 - recall_121: 0.9989 - false_positives_121: 9.8819\n",
      "Epoch 111/150\n",
      "524/524 [==============================] - 0s 780us/step - loss: 0.0139 - accuracy: 0.9974 - precision_121: 0.9953 - recall_121: 0.9995 - false_positives_121: 11.0990\n",
      "Epoch 112/150\n",
      "524/524 [==============================] - 0s 888us/step - loss: 0.0115 - accuracy: 0.9976 - precision_121: 0.9952 - recall_121: 1.0000 - false_positives_121: 11.9562\n",
      "Epoch 113/150\n",
      "524/524 [==============================] - 0s 820us/step - loss: 0.0143 - accuracy: 0.9970 - precision_121: 0.9950 - recall_121: 0.9992 - false_positives_121: 12.5981\n",
      "Epoch 114/150\n",
      "524/524 [==============================] - 0s 850us/step - loss: 0.0129 - accuracy: 0.9977 - precision_121: 0.9954 - recall_121: 0.9999 - false_positives_121: 10.8114\n",
      "Epoch 115/150\n",
      "524/524 [==============================] - 0s 802us/step - loss: 0.0116 - accuracy: 0.9977 - precision_121: 0.9956 - recall_121: 0.9999 - false_positives_121: 11.8571\n",
      "Epoch 116/150\n",
      "524/524 [==============================] - 0s 786us/step - loss: 0.0073 - accuracy: 0.9985 - precision_121: 0.9970 - recall_121: 1.0000 - false_positives_121: 8.9390\n",
      "Epoch 117/150\n",
      "524/524 [==============================] - 0s 820us/step - loss: 0.0134 - accuracy: 0.9972 - precision_121: 0.9947 - recall_121: 0.9998 - false_positives_121: 15.3905\n",
      "Epoch 118/150\n",
      "524/524 [==============================] - 0s 756us/step - loss: 0.0116 - accuracy: 0.9970 - precision_121: 0.9946 - recall_121: 0.9995 - false_positives_121: 13.3067\n",
      "Epoch 119/150\n",
      "524/524 [==============================] - 0s 766us/step - loss: 0.0130 - accuracy: 0.9969 - precision_121: 0.9944 - recall_121: 0.9994 - false_positives_121: 14.0114\n",
      "Epoch 120/150\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "524/524 [==============================] - 0s 781us/step - loss: 0.0114 - accuracy: 0.9978 - precision_121: 0.9963 - recall_121: 0.9993 - false_positives_121: 10.3124\n",
      "Epoch 121/150\n",
      "524/524 [==============================] - 0s 803us/step - loss: 0.0090 - accuracy: 0.9985 - precision_121: 0.9969 - recall_121: 1.0000 - false_positives_121: 9.8400\n",
      "Epoch 122/150\n",
      "524/524 [==============================] - 0s 798us/step - loss: 0.0077 - accuracy: 0.9987 - precision_121: 0.9976 - recall_121: 0.9998 - false_positives_121: 8.1543\n",
      "Epoch 123/150\n",
      "524/524 [==============================] - 0s 751us/step - loss: 0.0140 - accuracy: 0.9970 - precision_121: 0.9951 - recall_121: 0.9989 - false_positives_121: 13.1867\n",
      "Epoch 124/150\n",
      "524/524 [==============================] - 0s 846us/step - loss: 0.0151 - accuracy: 0.9972 - precision_121: 0.9950 - recall_121: 0.9994 - false_positives_121: 12.6381\n",
      "Epoch 125/150\n",
      "524/524 [==============================] - 0s 795us/step - loss: 0.0098 - accuracy: 0.9978 - precision_121: 0.9959 - recall_121: 0.9996 - false_positives_121: 10.8343\n",
      "Epoch 126/150\n",
      "524/524 [==============================] - 0s 787us/step - loss: 0.0109 - accuracy: 0.9977 - precision_121: 0.9960 - recall_121: 0.9995 - false_positives_121: 10.6152\n",
      "Epoch 127/150\n",
      "524/524 [==============================] - 0s 845us/step - loss: 0.0110 - accuracy: 0.9973 - precision_121: 0.9949 - recall_121: 0.9997 - false_positives_121: 12.6800\n",
      "Epoch 128/150\n",
      "524/524 [==============================] - 0s 804us/step - loss: 0.0078 - accuracy: 0.9983 - precision_121: 0.9967 - recall_121: 0.9999 - false_positives_121: 8.8552\n",
      "Epoch 129/150\n",
      "524/524 [==============================] - 0s 898us/step - loss: 0.0125 - accuracy: 0.9973 - precision_121: 0.9954 - recall_121: 0.9992 - false_positives_121: 12.1048\n",
      "Epoch 130/150\n",
      "524/524 [==============================] - 0s 849us/step - loss: 0.0151 - accuracy: 0.9970 - precision_121: 0.9948 - recall_121: 0.9991 - false_positives_121: 11.8000\n",
      "Epoch 131/150\n",
      "524/524 [==============================] - 0s 806us/step - loss: 0.0089 - accuracy: 0.9984 - precision_121: 0.9971 - recall_121: 0.9998 - false_positives_121: 9.3695\n",
      "Epoch 132/150\n",
      "524/524 [==============================] - 0s 794us/step - loss: 0.0105 - accuracy: 0.9981 - precision_121: 0.9965 - recall_121: 0.9998 - false_positives_121: 10.1810\n",
      "Epoch 133/150\n",
      "524/524 [==============================] - 0s 829us/step - loss: 0.0102 - accuracy: 0.9984 - precision_121: 0.9968 - recall_121: 1.0000 - false_positives_121: 10.4781\n",
      "Epoch 134/150\n",
      "524/524 [==============================] - 0s 806us/step - loss: 0.0129 - accuracy: 0.9976 - precision_121: 0.9956 - recall_121: 0.9996 - false_positives_121: 10.7657\n",
      "Epoch 135/150\n",
      "524/524 [==============================] - 0s 822us/step - loss: 0.0120 - accuracy: 0.9975 - precision_121: 0.9953 - recall_121: 0.9997 - false_positives_121: 12.5162\n",
      "Epoch 136/150\n",
      "524/524 [==============================] - 0s 851us/step - loss: 0.0149 - accuracy: 0.9977 - precision_121: 0.9954 - recall_121: 0.9999 - false_positives_121: 11.0057\n",
      "Epoch 137/150\n",
      "524/524 [==============================] - 0s 788us/step - loss: 0.0107 - accuracy: 0.9981 - precision_121: 0.9962 - recall_121: 1.0000 - false_positives_121: 11.5467\n",
      "Epoch 138/150\n",
      "524/524 [==============================] - 0s 777us/step - loss: 0.0120 - accuracy: 0.9979 - precision_121: 0.9965 - recall_121: 0.9994 - false_positives_121: 10.7086\n",
      "Epoch 139/150\n",
      "524/524 [==============================] - 0s 785us/step - loss: 0.0129 - accuracy: 0.9976 - precision_121: 0.9953 - recall_121: 1.0000 - false_positives_121: 11.8190\n",
      "Epoch 140/150\n",
      "524/524 [==============================] - 0s 762us/step - loss: 0.0097 - accuracy: 0.9985 - precision_121: 0.9970 - recall_121: 0.9999 - false_positives_121: 9.1962\n",
      "Epoch 141/150\n",
      "524/524 [==============================] - 0s 787us/step - loss: 0.0093 - accuracy: 0.9982 - precision_121: 0.9966 - recall_121: 0.9998 - false_positives_121: 9.5981\n",
      "Epoch 142/150\n",
      "524/524 [==============================] - 0s 840us/step - loss: 0.0088 - accuracy: 0.9983 - precision_121: 0.9972 - recall_121: 0.9994 - false_positives_121: 8.9886\n",
      "Epoch 143/150\n",
      "524/524 [==============================] - 0s 814us/step - loss: 0.0099 - accuracy: 0.9981 - precision_121: 0.9963 - recall_121: 0.9998 - false_positives_121: 10.9333\n",
      "Epoch 144/150\n",
      "524/524 [==============================] - 0s 938us/step - loss: 0.0102 - accuracy: 0.9978 - precision_121: 0.9957 - recall_121: 1.0000 - false_positives_121: 10.9676\n",
      "Epoch 145/150\n",
      "524/524 [==============================] - 0s 822us/step - loss: 0.0096 - accuracy: 0.9980 - precision_121: 0.9960 - recall_121: 1.0000 - false_positives_121: 10.7200\n",
      "Epoch 146/150\n",
      "524/524 [==============================] - 0s 801us/step - loss: 0.0119 - accuracy: 0.9978 - precision_121: 0.9964 - recall_121: 0.9993 - false_positives_121: 10.3714\n",
      "Epoch 147/150\n",
      "524/524 [==============================] - 0s 943us/step - loss: 0.0116 - accuracy: 0.9978 - precision_121: 0.9955 - recall_121: 1.0000 - false_positives_121: 10.4095\n",
      "Epoch 148/150\n",
      "524/524 [==============================] - 0s 801us/step - loss: 0.0101 - accuracy: 0.9980 - precision_121: 0.9960 - recall_121: 1.0000 - false_positives_121: 11.2286\n",
      "Epoch 149/150\n",
      "524/524 [==============================] - 0s 855us/step - loss: 0.0147 - accuracy: 0.9967 - precision_121: 0.9934 - recall_121: 1.0000 - false_positives_121: 15.8743\n",
      "Epoch 150/150\n",
      "524/524 [==============================] - 0s 863us/step - loss: 0.0094 - accuracy: 0.9982 - precision_121: 0.9967 - recall_121: 0.9998 - false_positives_121: 10.4667\n"
     ]
    }
   ],
   "source": [
    "y_pred = [0 for x in range(1000)]\n",
    "\n",
    "params = [(75, 0.2, 0.1), (10, 0.5, 0.3), (28, 0.1, 0.4), (120, 0.6, 0.1), (50, 0.2, 0.5), (90, 0.2, 0.05),\n",
    "         (42, 0.25, 0.1), (72, 0.3, 0.15), (25, 0.2, 0.1), (150, 0.2, 0.35)]\n",
    "\n",
    "for epochs, d1, d2 in params:\n",
    "    kaggle_model = create_custom_model(X_pca, d1, d2)\n",
    "    kaggle_model.fit(X_pca, y, batch_size=20, epochs=epochs)\n",
    "\n",
    "    y_pred_temp = kaggle_model.predict(X_test_score_kaggle)\n",
    "    y_temp = []\n",
    "    for i in range(len(y_pred_temp)):\n",
    "        if y_pred_temp[i] > 0.5:\n",
    "            y_temp.append(1)\n",
    "        else:\n",
    "            y_temp.append(0)\n",
    "    for i in range(len(y_temp)):\n",
    "        y_pred[i] += y_temp[i]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1105,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.4, 0.0, 1.0, 0.0, 0.6, 0.0, 0.0, 0.0, 0.3, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 1.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.3, 0.6, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3, 0.0, 0.0, 1.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 1.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 1.0, 0.0, 0.9, 0.6, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.2, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.9, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.2, 0.2, 0.7, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.3, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 1.0, 0.3, 0.0, 0.0, 0.0, 1.0, 0.0, 0.1, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.3, 0.0, 0.0, 1.0, 0.0, 0.0, 0.1, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.3, 0.0, 0.0, 0.0, 0.9, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.1, 0.0, 0.0, 1.0, 0.9, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.1, 0.0, 1.0, 0.7, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 1.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.8, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 1.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.2, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.8, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.1, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.3, 1.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.9, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.5, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 1.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.6, 0.0, 0.0, 0.0, 0.0, 0.3, 0.0, 0.0, 0.3, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.4, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.1, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 0.6, 0.0, 0.0, 0.0, 1.0, 0.9, 0.0, 1.0, 0.8, 0.0, 0.5, 0.2, 0.0, 0.0, 0.0, 0.0, 0.0, 1.0, 0.0, 1.0, 0.8, 0.0, 0.0, 0.0, 0.2, 0.6, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0, 0.0]\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(y_pred)):\n",
    "    y_pred[i] = y_pred[i]/10\n",
    "print(y_pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.098\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>ID</th>\n",
       "      <th>Predicted</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>83414</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>83415</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>83416</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>83417</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>83418</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>995</th>\n",
       "      <td>84409</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>996</th>\n",
       "      <td>84410</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>997</th>\n",
       "      <td>84411</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>998</th>\n",
       "      <td>84412</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>999</th>\n",
       "      <td>84413</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>1000 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "        ID  Predicted\n",
       "0    83414          0\n",
       "1    83415          0\n",
       "2    83416          0\n",
       "3    83417          0\n",
       "4    83418          0\n",
       "..     ...        ...\n",
       "995  84409          0\n",
       "996  84410          0\n",
       "997  84411          0\n",
       "998  84412          0\n",
       "999  84413          0\n",
       "\n",
       "[1000 rows x 2 columns]"
      ]
     },
     "execution_count": 1106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index = np.array([int(x) for x in range(83414, 84414)])\n",
    "kaggle_df = pd.DataFrame(index, columns=['ID'])\n",
    "\n",
    "y_pred_temp = []\n",
    "for i in range(len(y_pred)):\n",
    "    if y_pred[i] > 0.5:\n",
    "        y_pred_temp.append(1)\n",
    "    else:\n",
    "        y_pred_temp.append(0)\n",
    "y_pred_temp = np.array(y_pred_temp)\n",
    "kaggle_df[\"Predicted\"] = y_pred_temp\n",
    "\n",
    "print(np.mean(y_pred_temp))\n",
    "\n",
    "kaggle_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1000,
   "metadata": {},
   "outputs": [],
   "source": [
    "kaggle_df.to_csv(\"/Users/shrenik/Desktop/UCLA/Year-3/labels_1.csv\", index=False, header=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
