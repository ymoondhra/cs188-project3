{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np # linear algebra\n",
    "import pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n",
    "import matplotlib.pyplot as plt # this is used for the plot the graph \n",
    "from datetime import date\n",
    "\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.experimental import enable_iterative_imputer\n",
    "from sklearn.impute import IterativeImputer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from sklearn.preprocessing import MultiLabelBinarizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "import random \n",
    "random.seed(42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "csv_path_1 = \"training_dataset.csv\"\n",
    "csv_path_2 = \"score.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 0. First, let's understand our data..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>dt</th>\n",
       "      <th>weekday</th>\n",
       "      <th>year</th>\n",
       "      <th>id_driver</th>\n",
       "      <th>id_carrier_number</th>\n",
       "      <th>dim_carrier_type</th>\n",
       "      <th>dim_carrier_company_name</th>\n",
       "      <th>home_base_city</th>\n",
       "      <th>home_base_state</th>\n",
       "      <th>carrier_trucks</th>\n",
       "      <th>...</th>\n",
       "      <th>most_recent_load_date</th>\n",
       "      <th>load_day</th>\n",
       "      <th>loads</th>\n",
       "      <th>marketplace_loads_otr</th>\n",
       "      <th>marketplace_loads_atlas</th>\n",
       "      <th>marketplace_loads</th>\n",
       "      <th>brokerage_loads_otr</th>\n",
       "      <th>brokerage_loads_atlas</th>\n",
       "      <th>brokerage_loads</th>\n",
       "      <th>total_loads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2019</td>\n",
       "      <td>21350</td>\n",
       "      <td>U0109015</td>\n",
       "      <td>Owner Operator</td>\n",
       "      <td>CA&amp;F TRUCKING</td>\n",
       "      <td>Maywood</td>\n",
       "      <td>CA</td>\n",
       "      <td>[\"poweronly\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>2019-12-16</td>\n",
       "      <td>2</td>\n",
       "      <td>0</td>\n",
       "      <td>438</td>\n",
       "      <td>438</td>\n",
       "      <td>0</td>\n",
       "      <td>45</td>\n",
       "      <td>45</td>\n",
       "      <td>483</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>Friday</td>\n",
       "      <td>2021</td>\n",
       "      <td>36437</td>\n",
       "      <td>C0097727</td>\n",
       "      <td>Fleet</td>\n",
       "      <td>New opportunities inc</td>\n",
       "      <td>Los Angeles</td>\n",
       "      <td>CA</td>\n",
       "      <td>[\"poweronly\", \"boxtruck\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-02-03</td>\n",
       "      <td>2021-01-15</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>72</td>\n",
       "      <td>74</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>75</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>Thursday</td>\n",
       "      <td>2019</td>\n",
       "      <td>19323</td>\n",
       "      <td>U0107081</td>\n",
       "      <td>Owner Operator</td>\n",
       "      <td>RAS</td>\n",
       "      <td>Compton</td>\n",
       "      <td>CA</td>\n",
       "      <td>[\"poweronly\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>2020-09-25</td>\n",
       "      <td>2019-12-26</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>180</td>\n",
       "      <td>180</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>182</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>Wednesday</td>\n",
       "      <td>2021</td>\n",
       "      <td>34809</td>\n",
       "      <td>C0094651</td>\n",
       "      <td>Fleet</td>\n",
       "      <td>NFS asset Drayage</td>\n",
       "      <td>Lynwood</td>\n",
       "      <td>CA</td>\n",
       "      <td>[\"poweronly\", \"dryvan\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>2021-02-17</td>\n",
       "      <td>2021-02-10</td>\n",
       "      <td>3</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>Monday</td>\n",
       "      <td>2017</td>\n",
       "      <td>4728</td>\n",
       "      <td>U0094376</td>\n",
       "      <td>Owner Operator</td>\n",
       "      <td>joes transportation</td>\n",
       "      <td>Norco</td>\n",
       "      <td>CA</td>\n",
       "      <td>[\"dryvan\"]</td>\n",
       "      <td>...</td>\n",
       "      <td>2017-10-11</td>\n",
       "      <td>2017-07-24</td>\n",
       "      <td>2</td>\n",
       "      <td>57</td>\n",
       "      <td>0</td>\n",
       "      <td>57</td>\n",
       "      <td>314</td>\n",
       "      <td>0</td>\n",
       "      <td>314</td>\n",
       "      <td>371</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows Ã— 30 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "           dt    weekday  year  id_driver id_carrier_number dim_carrier_type  \\\n",
       "0  2019-12-16     Monday  2019      21350          U0109015   Owner Operator   \n",
       "1  2021-01-15     Friday  2021      36437          C0097727            Fleet   \n",
       "2  2019-12-26   Thursday  2019      19323          U0107081   Owner Operator   \n",
       "3  2021-02-10  Wednesday  2021      34809          C0094651            Fleet   \n",
       "4  2017-07-24     Monday  2017       4728          U0094376   Owner Operator   \n",
       "\n",
       "  dim_carrier_company_name home_base_city home_base_state  \\\n",
       "0            CA&F TRUCKING        Maywood              CA   \n",
       "1   New opportunities inc     Los Angeles              CA   \n",
       "2                      RAS        Compton              CA   \n",
       "3        NFS asset Drayage        Lynwood              CA   \n",
       "4      joes transportation          Norco              CA   \n",
       "\n",
       "              carrier_trucks  ...  most_recent_load_date    load_day loads  \\\n",
       "0              [\"poweronly\"]  ...             2021-02-17  2019-12-16     2   \n",
       "1  [\"poweronly\", \"boxtruck\"]  ...             2021-02-03  2021-01-15     1   \n",
       "2              [\"poweronly\"]  ...             2020-09-25  2019-12-26     1   \n",
       "3    [\"poweronly\", \"dryvan\"]  ...             2021-02-17  2021-02-10     3   \n",
       "4                 [\"dryvan\"]  ...             2017-10-11  2017-07-24     2   \n",
       "\n",
       "  marketplace_loads_otr marketplace_loads_atlas marketplace_loads  \\\n",
       "0                     0                     438               438   \n",
       "1                     2                      72                74   \n",
       "2                     0                     180               180   \n",
       "3                     0                       0                 0   \n",
       "4                    57                       0                57   \n",
       "\n",
       "   brokerage_loads_otr brokerage_loads_atlas brokerage_loads total_loads  \n",
       "0                    0                    45              45         483  \n",
       "1                    0                     1               1          75  \n",
       "2                    0                     2               2         182  \n",
       "3                    0                     0               0          62  \n",
       "4                  314                     0             314         371  \n",
       "\n",
       "[5 rows x 30 columns]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df = pd.read_csv(csv_path_1) # load the pandas dataframe\n",
    "df_score = pd.read_csv(csv_path_2)\n",
    "initial_cols_to_drop = [\"Unnamed: 0\",\"Unnamed: 0.1\", \"period\", \"test\", \"recent_date\", \"date\"] \n",
    "for col_name in initial_cols_to_drop: # drops columns that aren't supposed to be in dataset\n",
    "    try:\n",
    "        df = df.drop(columns=[col_name])\n",
    "        df_score = df_score.drop(columns=[col_name])\n",
    "    except:\n",
    "        continue\n",
    "#df = df.rename(columns={\"Unnamed: 0.1\": \"TODO_FIND_COLUMN_NAME_2\"})\n",
    "display(df.head())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>year</th>\n",
       "      <th>id_driver</th>\n",
       "      <th>num_trucks</th>\n",
       "      <th>days_signup_to_approval</th>\n",
       "      <th>loads</th>\n",
       "      <th>marketplace_loads_otr</th>\n",
       "      <th>marketplace_loads_atlas</th>\n",
       "      <th>marketplace_loads</th>\n",
       "      <th>brokerage_loads_otr</th>\n",
       "      <th>brokerage_loads_atlas</th>\n",
       "      <th>brokerage_loads</th>\n",
       "      <th>total_loads</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83344.000000</td>\n",
       "      <td>71124.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "      <td>83414.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>2018.960930</td>\n",
       "      <td>18222.414954</td>\n",
       "      <td>22.582921</td>\n",
       "      <td>298.752489</td>\n",
       "      <td>2.076270</td>\n",
       "      <td>29.477762</td>\n",
       "      <td>71.579675</td>\n",
       "      <td>101.057436</td>\n",
       "      <td>148.258422</td>\n",
       "      <td>13.073021</td>\n",
       "      <td>161.331443</td>\n",
       "      <td>266.502661</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.359343</td>\n",
       "      <td>11667.704926</td>\n",
       "      <td>48.829719</td>\n",
       "      <td>390.345107</td>\n",
       "      <td>2.672163</td>\n",
       "      <td>88.171940</td>\n",
       "      <td>194.532776</td>\n",
       "      <td>214.502147</td>\n",
       "      <td>415.978060</td>\n",
       "      <td>42.241592</td>\n",
       "      <td>413.792137</td>\n",
       "      <td>448.806175</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>2015.000000</td>\n",
       "      <td>20.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>2018.000000</td>\n",
       "      <td>7890.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>5.000000</td>\n",
       "      <td>37.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>2019.000000</td>\n",
       "      <td>16299.000000</td>\n",
       "      <td>4.000000</td>\n",
       "      <td>61.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>13.000000</td>\n",
       "      <td>15.000000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>37.000000</td>\n",
       "      <td>110.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2020.000000</td>\n",
       "      <td>28974.000000</td>\n",
       "      <td>14.000000</td>\n",
       "      <td>497.000000</td>\n",
       "      <td>2.000000</td>\n",
       "      <td>23.000000</td>\n",
       "      <td>18.000000</td>\n",
       "      <td>94.000000</td>\n",
       "      <td>112.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>135.000000</td>\n",
       "      <td>325.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>2021.000000</td>\n",
       "      <td>38125.000000</td>\n",
       "      <td>195.000000</td>\n",
       "      <td>1653.000000</td>\n",
       "      <td>129.000000</td>\n",
       "      <td>902.000000</td>\n",
       "      <td>1324.000000</td>\n",
       "      <td>1348.000000</td>\n",
       "      <td>4266.000000</td>\n",
       "      <td>371.000000</td>\n",
       "      <td>4266.000000</td>\n",
       "      <td>4266.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "               year     id_driver    num_trucks  days_signup_to_approval  \\\n",
       "count  83414.000000  83414.000000  83344.000000             71124.000000   \n",
       "mean    2018.960930  18222.414954     22.582921               298.752489   \n",
       "std        1.359343  11667.704926     48.829719               390.345107   \n",
       "min     2015.000000     20.000000      1.000000                 0.000000   \n",
       "25%     2018.000000   7890.000000      1.000000                 0.000000   \n",
       "50%     2019.000000  16299.000000      4.000000                61.000000   \n",
       "75%     2020.000000  28974.000000     14.000000               497.000000   \n",
       "max     2021.000000  38125.000000    195.000000              1653.000000   \n",
       "\n",
       "              loads  marketplace_loads_otr  marketplace_loads_atlas  \\\n",
       "count  83414.000000           83414.000000             83414.000000   \n",
       "mean       2.076270              29.477762                71.579675   \n",
       "std        2.672163              88.171940               194.532776   \n",
       "min        1.000000               0.000000                 0.000000   \n",
       "25%        1.000000               0.000000                 0.000000   \n",
       "50%        1.000000               2.000000                 0.000000   \n",
       "75%        2.000000              23.000000                18.000000   \n",
       "max      129.000000             902.000000              1324.000000   \n",
       "\n",
       "       marketplace_loads  brokerage_loads_otr  brokerage_loads_atlas  \\\n",
       "count       83414.000000         83414.000000           83414.000000   \n",
       "mean          101.057436           148.258422              13.073021   \n",
       "std           214.502147           415.978060              42.241592   \n",
       "min             0.000000             0.000000               0.000000   \n",
       "25%             0.000000             0.000000               0.000000   \n",
       "50%            13.000000            15.000000               0.000000   \n",
       "75%            94.000000           112.000000               1.000000   \n",
       "max          1348.000000          4266.000000             371.000000   \n",
       "\n",
       "       brokerage_loads   total_loads  \n",
       "count     83414.000000  83414.000000  \n",
       "mean        161.331443    266.502661  \n",
       "std         413.792137    448.806175  \n",
       "min           0.000000      1.000000  \n",
       "25%           5.000000     37.000000  \n",
       "50%          37.000000    110.000000  \n",
       "75%         135.000000    325.000000  \n",
       "max        4266.000000   4266.000000  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 83414 entries, 0 to 83413\n",
      "Data columns (total 30 columns):\n",
      " #   Column                    Non-Null Count  Dtype  \n",
      "---  ------                    --------------  -----  \n",
      " 0   dt                        83414 non-null  object \n",
      " 1   weekday                   83414 non-null  object \n",
      " 2   year                      83414 non-null  int64  \n",
      " 3   id_driver                 83414 non-null  int64  \n",
      " 4   id_carrier_number         83414 non-null  object \n",
      " 5   dim_carrier_type          83414 non-null  object \n",
      " 6   dim_carrier_company_name  83365 non-null  object \n",
      " 7   home_base_city            83369 non-null  object \n",
      " 8   home_base_state           83369 non-null  object \n",
      " 9   carrier_trucks            83414 non-null  object \n",
      " 10  num_trucks                83344 non-null  float64\n",
      " 11  interested_in_drayage     83414 non-null  object \n",
      " 12  port_qualified            83414 non-null  object \n",
      " 13  signup_source             83414 non-null  object \n",
      " 14  ts_signup                 83414 non-null  object \n",
      " 15  ts_first_approved         71124 non-null  object \n",
      " 16  days_signup_to_approval   71124 non-null  float64\n",
      " 17  driver_with_twic          83414 non-null  object \n",
      " 18  dim_preferred_lanes       3412 non-null   object \n",
      " 19  first_load_date           83414 non-null  object \n",
      " 20  most_recent_load_date     83414 non-null  object \n",
      " 21  load_day                  83414 non-null  object \n",
      " 22  loads                     83414 non-null  int64  \n",
      " 23  marketplace_loads_otr     83414 non-null  int64  \n",
      " 24  marketplace_loads_atlas   83414 non-null  int64  \n",
      " 25  marketplace_loads         83414 non-null  int64  \n",
      " 26  brokerage_loads_otr       83414 non-null  int64  \n",
      " 27  brokerage_loads_atlas     83414 non-null  int64  \n",
      " 28  brokerage_loads           83414 non-null  int64  \n",
      " 29  total_loads               83414 non-null  int64  \n",
      "dtypes: float64(2), int64(10), object(18)\n",
      "memory usage: 19.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 1. Generate Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# converts date from csv to a python datetime object making it easier to work with\n",
    "def convert_dates(df):\n",
    "    dates_columns = ['most_recent_load_date', 'first_load_date', 'load_day', 'dt']\n",
    "    for col_name in dates_columns:\n",
    "        try:\n",
    "            df[col_name] = pd.to_datetime(df[col_name], format='%Y-%m-%d')\n",
    "        except:\n",
    "            continue\n",
    "\n",
    "convert_dates(df)\n",
    "convert_dates(df_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0   2021-02-17\n",
       "1   2021-02-03\n",
       "2   2020-09-25\n",
       "3   2021-02-17\n",
       "4   2017-10-11\n",
       "Name: most_recent_load_date, dtype: datetime64[ns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df['most_recent_load_date'].head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "325.0\n",
      "2021-02-14 00:00:00\n"
     ]
    }
   ],
   "source": [
    "total_loads75 = df.total_loads.quantile(0.75) # finds 75th percentile of loads\n",
    "most_recent_load_date75 = df.most_recent_load_date.quantile(0.75) # finds 75th percentile of most recent load date\n",
    "\n",
    "print(total_loads75)\n",
    "print(most_recent_load_date75)\n",
    "\n",
    "\n",
    "# Manual Check\n",
    "# sorted_dts = sorted(list(df.most_recent_load_date))\n",
    "# quartile_estimate_index = int(len(sorted_dts)*0.75)\n",
    "# print(\"SORTED INDEX\", sorted_dts[quartile_estimate_index])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# new_labels = {\"label\": {}}\n",
    "num_days_worked_dict = {}\n",
    "\n",
    "for index, row in df.iterrows(): # changes the labels in the label columns\n",
    "    # checks if the load and most recent load date are in the 75th percentile\n",
    "    if row[\"total_loads\"] >= total_loads75 and row[\"most_recent_load_date\"] >= most_recent_load_date75:\n",
    "        df.at[index, \"label\"] = 1\n",
    "    else:\n",
    "        df.at[index, \"label\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AxesSubplot:xlabel='dt,dt'>"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "df[\"dt\"].groupby([df[\"dt\"].dt.year, df[\"dt\"].dt.month]).count().plot(kind=\"bar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df.groupby(\"id_driver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO: dt, weekday, year, id_carrier_number, dim_preferred_lanes, load_day, loads\n",
    "new_arr = []\n",
    "for key, group in groups:\n",
    "    group.sort_values(by=\"load_day\", ascending=False, inplace=True)\n",
    "    temp_arr = []\n",
    "    temp_arr.append(key)\n",
    "    \n",
    "    if group[\"dim_carrier_type\"].nunique() == 2:\n",
    "        temp_arr.append(\"Both\")\n",
    "    elif group[\"dim_carrier_type\"].nunique() == 0:\n",
    "        temp_arr.append(None)\n",
    "    else:\n",
    "        temp_arr.append((group[\"dim_carrier_type\"].iloc[0]))\n",
    "    \n",
    "    \n",
    "    idxmax_cols = [\"dim_carrier_company_name\", \"home_base_city\", \"home_base_state\", \n",
    "                   \"carrier_trucks\", \"signup_source\", \"ts_signup\", \"ts_first_approved\",\n",
    "                  \"days_signup_to_approval\"]\n",
    "    \n",
    "    for col in idxmax_cols:\n",
    "        try:\n",
    "            temp_arr.append(group[col].value_counts().dropna(how=\"any\").idxmax())\n",
    "        except:\n",
    "            temp_arr.append(None)\n",
    "    \n",
    "    try:\n",
    "        temp_arr.append(group[\"num_trucks\"].dropna(how=\"any\").mean())\n",
    "    except:\n",
    "        temp_arr.append(None)\n",
    "        \n",
    "    iloc_cols = [\"interested_in_drayage\", \"port_qualified\", \"driver_with_twic\", \n",
    "                 \"first_load_date\", \"most_recent_load_date\", \"marketplace_loads_otr\", \n",
    "                 \"marketplace_loads_atlas\", \"marketplace_loads\", \"brokerage_loads_otr\",\n",
    "                 \"brokerage_loads_atlas\", \"brokerage_loads\", \"total_loads\"]\n",
    "    for col in iloc_cols:\n",
    "        try:\n",
    "            temp_arr.append(group[col].dropna(how=\"any\").iloc[0])\n",
    "        except:\n",
    "            temp_arr.append(None)\n",
    "            \n",
    "    temp_arr.append(group[\"label\"].value_counts().dropna(how=\"any\").idxmax())\n",
    "            \n",
    "    temp_arr.append(group.shape[0])\n",
    "    \n",
    "    new_arr.append(np.array(temp_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"id_driver\", \"dim_carrier_type\", \"dim_carrier_company_name\", \"home_base_city\", \"home_base_state\", \n",
    "                \"carrier_trucks\", \"signup_source\", \"ts_signup\", \"ts_first_approved\",\n",
    "                \"days_signup_to_approval\", \"num_trucks\", \"interested_in_drayage\", \n",
    "                \"port_qualified\", \"driver_with_twic\", \n",
    "                \"first_load_date\", \"most_recent_load_date\", \"marketplace_loads_otr\", \n",
    "                \"marketplace_loads_atlas\", \"marketplace_loads\", \"brokerage_loads_otr\",\n",
    "                \"brokerage_loads_atlas\", \"brokerage_loads\", \"total_loads\", \"num_trips_made\", \"label\"]\n",
    "\n",
    "df = pd.DataFrame(np.array(new_arr), columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert = [\"id_driver\", \"days_signup_to_approval\", \"marketplace_loads_otr\", \n",
    "               \"marketplace_loads_atlas\", \"marketplace_loads\", \"brokerage_loads_otr\",\n",
    "               \"brokerage_loads_atlas\", \"brokerage_loads\", \"total_loads\", \"num_trips_made\", \"label\",\n",
    "               \"num_trucks\", \"dim_carrier_type\", \"dim_carrier_company_name\", \"home_base_city\", \"home_base_state\",\n",
    "               \"interested_in_drayage\", \"port_qualified\", \"signup_source\", \"driver_with_twic\"]\n",
    "for col in convert:\n",
    "    df[col] = df[col].convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5291 entries, 0 to 5290\n",
      "Data columns (total 25 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   id_driver                 5291 non-null   Int64         \n",
      " 1   dim_carrier_type          5291 non-null   string        \n",
      " 2   dim_carrier_company_name  5284 non-null   string        \n",
      " 3   home_base_city            5279 non-null   string        \n",
      " 4   home_base_state           5279 non-null   string        \n",
      " 5   carrier_trucks            5291 non-null   object        \n",
      " 6   signup_source             5291 non-null   string        \n",
      " 7   ts_signup                 5291 non-null   object        \n",
      " 8   ts_first_approved         3962 non-null   object        \n",
      " 9   days_signup_to_approval   3962 non-null   Int64         \n",
      " 10  num_trucks                5249 non-null   float64       \n",
      " 11  interested_in_drayage     5291 non-null   string        \n",
      " 12  port_qualified            5291 non-null   string        \n",
      " 13  driver_with_twic          5291 non-null   string        \n",
      " 14  first_load_date           5291 non-null   datetime64[ns]\n",
      " 15  most_recent_load_date     5291 non-null   datetime64[ns]\n",
      " 16  marketplace_loads_otr     5291 non-null   Int64         \n",
      " 17  marketplace_loads_atlas   5291 non-null   Int64         \n",
      " 18  marketplace_loads         5291 non-null   Int64         \n",
      " 19  brokerage_loads_otr       5291 non-null   Int64         \n",
      " 20  brokerage_loads_atlas     5291 non-null   Int64         \n",
      " 21  brokerage_loads           5291 non-null   Int64         \n",
      " 22  total_loads               5291 non-null   Int64         \n",
      " 23  num_trips_made            5291 non-null   Int64         \n",
      " 24  label                     5291 non-null   Int64         \n",
      "dtypes: Int64(11), datetime64[ns](2), float64(1), object(3), string(8)\n",
      "memory usage: 1.1+ MB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "count    5291.000000\n",
       "mean       15.765262\n",
       "std        36.862613\n",
       "min         1.000000\n",
       "25%         1.000000\n",
       "50%         3.000000\n",
       "75%        12.000000\n",
       "max       624.000000\n",
       "Name: label, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[\"label\"].describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "groups = df_score.groupby(\"id_driver\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "# NO: dt, weekday, year, id_carrier_number, dim_preferred_lanes, load_day, loads\n",
    "new_arr = []\n",
    "for key, group in groups:\n",
    "    group.sort_values(by=\"load_day\", ascending=False, inplace=True)\n",
    "    temp_arr = []\n",
    "    temp_arr.append(key)\n",
    "    \n",
    "    if group[\"dim_carrier_type\"].nunique() == 2:\n",
    "        temp_arr.append(\"Both\")\n",
    "    elif group[\"dim_carrier_type\"].nunique() == 0:\n",
    "        temp_arr.append(None)\n",
    "    else:\n",
    "        temp_arr.append((group[\"dim_carrier_type\"].iloc[0]))\n",
    "    \n",
    "    \n",
    "    idxmax_cols = [\"dim_carrier_company_name\", \"home_base_city\", \"home_base_state\", \n",
    "                   \"carrier_trucks\", \"signup_source\", \"ts_signup\", \"ts_first_approved\",\n",
    "                  \"days_signup_to_approval\"]\n",
    "    \n",
    "    for col in idxmax_cols:\n",
    "        try:\n",
    "            temp_arr.append(group[col].value_counts().dropna(how=\"any\").idxmax())\n",
    "        except:\n",
    "            temp_arr.append(None)\n",
    "    \n",
    "    try:\n",
    "        temp_arr.append(group[\"num_trucks\"].dropna(how=\"any\").mean())\n",
    "    except:\n",
    "        temp_arr.append(None)\n",
    "        \n",
    "    iloc_cols = [\"interested_in_drayage\", \"port_qualified\", \"driver_with_twic\", \n",
    "                 \"first_load_date\", \"load_day\", \"marketplace_loads_otr\", \n",
    "                 \"marketplace_loads_atlas\", \"marketplace_loads\", \"brokerage_loads_otr\",\n",
    "                 \"brokerage_loads_atlas\", \"brokerage_loads\"]\n",
    "    for col in iloc_cols:\n",
    "        try:\n",
    "            temp_arr.append(group[col].dropna(how=\"any\").iloc[0])\n",
    "        except:\n",
    "            temp_arr.append(None)\n",
    "            \n",
    "    temp_arr.append(group.shape[0])\n",
    "    \n",
    "    new_arr.append(np.array(temp_arr))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "column_names = [\"id_driver\", \"dim_carrier_type\", \"dim_carrier_company_name\", \"home_base_city\", \"home_base_state\", \n",
    "                \"carrier_trucks\", \"signup_source\", \"ts_signup\", \"ts_first_approved\",\n",
    "                \"days_signup_to_approval\", \"num_trucks\", \"interested_in_drayage\", \n",
    "                \"port_qualified\", \"driver_with_twic\", \n",
    "                \"first_load_date\", \"most_recent_load_date\", \"marketplace_loads_otr\", \n",
    "                \"marketplace_loads_atlas\", \"marketplace_loads\", \"brokerage_loads_otr\",\n",
    "                \"brokerage_loads_atlas\", \"brokerage_loads\", \"num_trips_made\"]\n",
    "\n",
    "df_score = pd.DataFrame(np.array(new_arr), columns=column_names)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "convert = [\"id_driver\", \"days_signup_to_approval\", \"marketplace_loads_otr\", \n",
    "               \"marketplace_loads_atlas\", \"marketplace_loads\", \"brokerage_loads_otr\",\n",
    "               \"brokerage_loads_atlas\", \"brokerage_loads\", \"num_trips_made\",\n",
    "               \"num_trucks\", \"dim_carrier_type\", \"dim_carrier_company_name\", \"home_base_city\", \"home_base_state\",\n",
    "               \"interested_in_drayage\", \"port_qualified\", \"signup_source\", \"driver_with_twic\"]\n",
    "for col in convert:\n",
    "    df_score[col] = df_score[col].convert_dtypes()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 668 entries, 0 to 667\n",
      "Data columns (total 23 columns):\n",
      " #   Column                    Non-Null Count  Dtype         \n",
      "---  ------                    --------------  -----         \n",
      " 0   id_driver                 668 non-null    Int64         \n",
      " 1   dim_carrier_type          668 non-null    string        \n",
      " 2   dim_carrier_company_name  668 non-null    string        \n",
      " 3   home_base_city            668 non-null    string        \n",
      " 4   home_base_state           668 non-null    string        \n",
      " 5   carrier_trucks            668 non-null    object        \n",
      " 6   signup_source             668 non-null    string        \n",
      " 7   ts_signup                 668 non-null    object        \n",
      " 8   ts_first_approved         572 non-null    object        \n",
      " 9   days_signup_to_approval   572 non-null    Int64         \n",
      " 10  num_trucks                668 non-null    float64       \n",
      " 11  interested_in_drayage     668 non-null    string        \n",
      " 12  port_qualified            668 non-null    string        \n",
      " 13  driver_with_twic          668 non-null    string        \n",
      " 14  first_load_date           668 non-null    datetime64[ns]\n",
      " 15  most_recent_load_date     668 non-null    datetime64[ns]\n",
      " 16  marketplace_loads_otr     668 non-null    Int64         \n",
      " 17  marketplace_loads_atlas   668 non-null    Int64         \n",
      " 18  marketplace_loads         668 non-null    Int64         \n",
      " 19  brokerage_loads_otr       668 non-null    Int64         \n",
      " 20  brokerage_loads_atlas     668 non-null    Int64         \n",
      " 21  brokerage_loads           668 non-null    Int64         \n",
      " 22  num_trips_made            668 non-null    Int64         \n",
      "dtypes: Int64(9), datetime64[ns](2), float64(1), object(3), string(8)\n",
      "memory usage: 126.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_score.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 3. Basic Statistics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "id_driver\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "id_driver                  1.000000\n",
       "num_trucks                 0.169567\n",
       "brokerage_loads_atlas      0.145307\n",
       "marketplace_loads_atlas    0.138116\n",
       "marketplace_loads          0.123344\n",
       "num_trips_made             0.075683\n",
       "total_loads                0.052722\n",
       "label                      0.018007\n",
       "marketplace_loads_otr     -0.012441\n",
       "brokerage_loads           -0.037352\n",
       "brokerage_loads_otr       -0.063795\n",
       "days_signup_to_approval   -0.734778\n",
       "Name: id_driver, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "dim_carrier_type\n",
      "dim_carrier_type is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "dim_carrier_company_name\n",
      "dim_carrier_company_name is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "home_base_city\n",
      "home_base_city is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "home_base_state\n",
      "home_base_state is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "carrier_trucks\n",
      "carrier_trucks is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "signup_source\n",
      "signup_source is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "ts_signup\n",
      "ts_signup is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "ts_first_approved\n",
      "ts_first_approved is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "days_signup_to_approval\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "days_signup_to_approval    1.000000\n",
       "brokerage_loads_otr        0.048116\n",
       "brokerage_loads            0.027929\n",
       "label                      0.010462\n",
       "marketplace_loads_otr      0.007436\n",
       "total_loads               -0.043765\n",
       "num_trucks                -0.053498\n",
       "num_trips_made            -0.064084\n",
       "marketplace_loads         -0.089268\n",
       "brokerage_loads_atlas     -0.092088\n",
       "marketplace_loads_atlas   -0.099058\n",
       "id_driver                 -0.734778\n",
       "Name: days_signup_to_approval, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "num_trucks\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "num_trucks                 1.000000\n",
       "id_driver                  0.169567\n",
       "label                      0.059784\n",
       "total_loads                0.017664\n",
       "brokerage_loads_otr        0.001285\n",
       "brokerage_loads           -0.006155\n",
       "num_trips_made            -0.035292\n",
       "brokerage_loads_atlas     -0.042167\n",
       "marketplace_loads_atlas   -0.050920\n",
       "days_signup_to_approval   -0.053498\n",
       "marketplace_loads_otr     -0.058752\n",
       "marketplace_loads         -0.065660\n",
       "Name: num_trucks, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "interested_in_drayage\n",
      "interested_in_drayage is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "port_qualified\n",
      "port_qualified is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "driver_with_twic\n",
      "driver_with_twic is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "first_load_date\n",
      "first_load_date is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "most_recent_load_date\n",
      "most_recent_load_date is not of type integer\n",
      "---------------------------------------------------------------------\n",
      "marketplace_loads_otr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "marketplace_loads_otr      1.000000\n",
       "label                      0.511867\n",
       "marketplace_loads          0.395290\n",
       "total_loads                0.268972\n",
       "num_trips_made             0.163324\n",
       "marketplace_loads_atlas    0.083147\n",
       "brokerage_loads_otr        0.080873\n",
       "brokerage_loads            0.080687\n",
       "days_signup_to_approval    0.007436\n",
       "brokerage_loads_atlas      0.005160\n",
       "id_driver                 -0.012441\n",
       "num_trucks                -0.058752\n",
       "Name: marketplace_loads_otr, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "marketplace_loads_atlas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "marketplace_loads_atlas    1.000000\n",
       "marketplace_loads          0.948243\n",
       "num_trips_made             0.577596\n",
       "total_loads                0.541759\n",
       "label                      0.445315\n",
       "brokerage_loads_atlas      0.410271\n",
       "id_driver                  0.138116\n",
       "marketplace_loads_otr      0.083147\n",
       "brokerage_loads            0.059796\n",
       "brokerage_loads_otr       -0.012599\n",
       "num_trucks                -0.050920\n",
       "days_signup_to_approval   -0.099058\n",
       "Name: marketplace_loads_atlas, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "marketplace_loads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "marketplace_loads          1.000000\n",
       "marketplace_loads_atlas    0.948243\n",
       "total_loads                0.585073\n",
       "num_trips_made             0.584442\n",
       "label                      0.573574\n",
       "marketplace_loads_otr      0.395290\n",
       "brokerage_loads_atlas      0.379811\n",
       "id_driver                  0.123344\n",
       "brokerage_loads            0.080827\n",
       "brokerage_loads_otr        0.014158\n",
       "num_trucks                -0.065660\n",
       "days_signup_to_approval   -0.089268\n",
       "Name: marketplace_loads, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "brokerage_loads_otr\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "brokerage_loads_otr        1.000000\n",
       "brokerage_loads            0.984385\n",
       "total_loads                0.803391\n",
       "label                      0.572785\n",
       "num_trips_made             0.239032\n",
       "marketplace_loads_otr      0.080873\n",
       "days_signup_to_approval    0.048116\n",
       "marketplace_loads          0.014158\n",
       "num_trucks                 0.001285\n",
       "brokerage_loads_atlas     -0.011804\n",
       "marketplace_loads_atlas   -0.012599\n",
       "id_driver                 -0.063795\n",
       "Name: brokerage_loads_otr, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "brokerage_loads_atlas\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "brokerage_loads_atlas      1.000000\n",
       "marketplace_loads_atlas    0.410271\n",
       "marketplace_loads          0.379811\n",
       "total_loads                0.329874\n",
       "num_trips_made             0.327819\n",
       "label                      0.257713\n",
       "brokerage_loads            0.164395\n",
       "id_driver                  0.145307\n",
       "marketplace_loads_otr      0.005160\n",
       "brokerage_loads_otr       -0.011804\n",
       "num_trucks                -0.042167\n",
       "days_signup_to_approval   -0.092088\n",
       "Name: brokerage_loads_atlas, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "brokerage_loads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "brokerage_loads            1.000000\n",
       "brokerage_loads_otr        0.984385\n",
       "total_loads                0.850586\n",
       "label                      0.610399\n",
       "num_trips_made             0.293505\n",
       "brokerage_loads_atlas      0.164395\n",
       "marketplace_loads          0.080827\n",
       "marketplace_loads_otr      0.080687\n",
       "marketplace_loads_atlas    0.059796\n",
       "days_signup_to_approval    0.027929\n",
       "num_trucks                -0.006155\n",
       "id_driver                 -0.037352\n",
       "Name: brokerage_loads, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "total_loads\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "total_loads                1.000000\n",
       "brokerage_loads            0.850586\n",
       "brokerage_loads_otr        0.803391\n",
       "label                      0.802860\n",
       "marketplace_loads          0.585073\n",
       "num_trips_made             0.541811\n",
       "marketplace_loads_atlas    0.541759\n",
       "brokerage_loads_atlas      0.329874\n",
       "marketplace_loads_otr      0.268972\n",
       "id_driver                  0.052722\n",
       "num_trucks                 0.017664\n",
       "days_signup_to_approval   -0.043765\n",
       "Name: total_loads, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "num_trips_made\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "num_trips_made             1.000000\n",
       "marketplace_loads          0.584442\n",
       "marketplace_loads_atlas    0.577596\n",
       "total_loads                0.541811\n",
       "label                      0.481593\n",
       "brokerage_loads_atlas      0.327819\n",
       "brokerage_loads            0.293505\n",
       "brokerage_loads_otr        0.239032\n",
       "marketplace_loads_otr      0.163324\n",
       "id_driver                  0.075683\n",
       "num_trucks                -0.035292\n",
       "days_signup_to_approval   -0.064084\n",
       "Name: num_trips_made, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n",
      "label\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "label                      1.000000\n",
       "total_loads                0.802860\n",
       "brokerage_loads            0.610399\n",
       "marketplace_loads          0.573574\n",
       "brokerage_loads_otr        0.572785\n",
       "marketplace_loads_otr      0.511867\n",
       "num_trips_made             0.481593\n",
       "marketplace_loads_atlas    0.445315\n",
       "brokerage_loads_atlas      0.257713\n",
       "num_trucks                 0.059784\n",
       "id_driver                  0.018007\n",
       "days_signup_to_approval    0.010462\n",
       "Name: label, dtype: float64"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "---------------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "corr_matrix = df.corr()\n",
    "for col_name in (list(df.columns.values)): # prints all the correlation matrices corresponding to each feature\n",
    "    try:\n",
    "        print(col_name)\n",
    "        display(corr_matrix[col_name].sort_values(ascending=False))\n",
    "        print('---------------------------------------------------------------------')\n",
    "    except:\n",
    "        print(\"{} is not of type integer\".format(col_name))\n",
    "        print('---------------------------------------------------------------------')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    " Also year and TODO_FIND_COLUMN_NAME_2 and year are highly correlated and have a similar impact on label, so we could drop one? \n",
    "\n",
    "Is there really a need for brokerage_loads when it is so highly correlated to brokerage_loads_otr due to the vast majority of shipments being delivered over-the-road as compared to via ATLAS? \n",
    "\n",
    "I have the same question about total_loads due to the vast majority of loads being brokerage loads...\n",
    "\n",
    "What's the point of having both year and date?\n",
    "\n",
    "We can remove the id_carrier_number column from this dataset as it is not relevant to predicting a label of 0 or 1 (When trying to find high performing drivers, we need to know their carrier number, so we can extract the id_carrier_number column for now...)\n",
    "\n",
    "We could one-hot-encode sign-up source and see its effect on labels.\n",
    "\n",
    "We can remove the ts_first_approved column because the date of approval shouldn't matter that much but instead the days_signup_to_approval matter.\n",
    "\n",
    "dim_preferred_lanes only has a few values so we can either remove the column or impute values.\n",
    "\n",
    "Also first_load_date, most_recent_load_date and load_day shouldn't matter much. Instead we can have values such as: number of days doing the job = most_recent_load_date - first_load_date\n",
    "AND\n",
    "days_from_last_load_to_today = todays_date - most_recent_load_date\n",
    "\n",
    "There are also a couple other features we need to impute.\n",
    "\n",
    "Also, only people that are port qualified can provide drayage services, so we should create a field called qualified_and_interest_in_drayage which is only 1 (yes) when interested_in_drayage = \"yes\" and port_qualified = \"yes\". We can also cross these features..."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 4. Data Feature Extraction Plan and Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# df[\"location\"] = list(zip(df[\"home_base_city\"], df[\"home_base_state\"]))# feature cross to get (city, state) tuple\n",
    "# # feature cross for interested in drayage and port qualified\n",
    "# df[\"drayage_interested_port_qualified\"] = list(zip(df[\"interested_in_drayage\"], df[\"port_qualified\"]))\n",
    "# display(df[\"location\"])\n",
    "# display(df[\"drayage_interested_port_qualified\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0       100000\n",
       "1       100000\n",
       "2       100000\n",
       "3       100000\n",
       "4       100000\n",
       "         ...  \n",
       "5286    100000\n",
       "5287    000001\n",
       "5288    000001\n",
       "5289    000001\n",
       "5290    000001\n",
       "Name: drayage_interested_port_qualified, Length: 5291, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "0      100000\n",
       "1      100000\n",
       "2      100000\n",
       "3      100000\n",
       "4      100000\n",
       "        ...  \n",
       "663    100000\n",
       "664    000001\n",
       "665    000010\n",
       "666    000010\n",
       "667    010000\n",
       "Name: drayage_interested_port_qualified, Length: 668, dtype: object"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "def drayage_feature_cross(df):\n",
    "    loc_cross = list(zip(df[\"home_base_city\"], df[\"home_base_state\"]))# feature cross to get (city, state) tuple\n",
    "    # feature cross for interested in drayage and port qualified\n",
    "    drayage_cross = list(zip(df[\"interested_in_drayage\"], df[\"port_qualified\"]))\n",
    "\n",
    "    drayage_arr = []\n",
    "    for list_item in drayage_cross:\n",
    "        if list_item[0] == \"yes\" and list_item[1] == \"yes\":\n",
    "            drayage_arr.append(\"000001\")\n",
    "        if list_item[0] == \"yes\" and list_item[1] == \"no\":\n",
    "            drayage_arr.append(\"000010\")\n",
    "        if list_item[0] == \"no\" and list_item[1] == \"yes\":\n",
    "            drayage_arr.append(\"000100\")\n",
    "        if list_item[0] == \"no\" and list_item[1] == \"no\":\n",
    "            drayage_arr.append(\"001000\")\n",
    "        if list_item[0] == \"not specified\" and list_item[1] == \"yes\":\n",
    "            drayage_arr.append(\"010000\")\n",
    "        if list_item[0] == \"not specified\" and list_item[1] == \"no\":\n",
    "            drayage_arr.append(\"100000\")\n",
    "\n",
    "    df[\"drayage_interested_port_qualified\"] = np.array(drayage_arr)\n",
    "    display(df[\"drayage_interested_port_qualified\"])\n",
    "\n",
    "drayage_feature_cross(df)\n",
    "drayage_feature_cross(df_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "id_driver_number_col = np.array(df[\"id_driver\"]) # extract id_driver column\n",
    "id_driver_number_col_score = np.array(df_score[\"id_driver\"]) # extract id_driver column\n",
    "\n",
    "drop_cols = [\"id_driver\", \"home_base_city\",\n",
    "             \"home_base_state\", \"interested_in_drayage\", \"port_qualified\", \n",
    "             \"ts_signup\", \"ts_first_approved\"]\n",
    "for col in drop_cols:\n",
    "    try:\n",
    "        df = df.drop(columns = [col]) # drop columns that don't affect the label value by much\n",
    "        df_score = df_score.drop(columns = [col]) # drop columns that don't affect the label value by much\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "names = {}\n",
    "for index, row in df.iterrows():\n",
    "    names[row[\"dim_carrier_company_name\"]] = int(names.get(row[\"dim_carrier_company_name\"], 0) + 1)\n",
    "listo = list(names.items())\n",
    "listo.sort(reverse=True, key=lambda x: int(x[1]))\n",
    "#listo[:50]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "# 50:  1290\n",
      "Percentage 50:  0.5176565008025682\n",
      "['NFS asset Drayage', 'MC Express Trucking LLC', 'Roadrunner Transportation', 'Dong Fang Marketing Inc', 'ROADMOND LOGISTICS INC.', 'Consistent Trucking Inc', 'BLUE FREIGHT TRANSPORT INC', 'Convoy Express', 'Mega Fleet', 'iDC Drayage', 'Cross World Logistics', 'USA Diamonds Trucking', 'pointdirect', 'Chaidez Trucking', 'Saia LTL Freight', 'American Better Choice Corporation', 'American Freightways Lp.', 'Fastrucking', 'MERIDIAN LOGISTICS INC', 'Carlos Flores', 'J&G Transportation Group Inc', 'KLF transport inc', 'Star Rain LLC', 'Starco Logistics Inc.', '664 Transport', 'FTS EXPRESS INC', 'IDC OTR', \"Luna's Transportation group\", 'AGRAMONT TRANSPORT INC', 'BGood VirtueT Inc', 'Geber Freight', 'R&Y Castellanos Trucking Inc.', 'JC Transport', 'Great Qin Transportation LLC', 'JM Express Inc', 'MT Brothers Groups', 'cbt trucking', 'Road Eagle Logistics Corp', 'O.A. EXPRESS INC', 'AMPAK Logistics INC.', 'Kuang Trucking Inc.', 'nolan transportation group', '360 new way inc', 'Innovative Transportation, LLC', 'freight advisor corp', 'one USA group', 'Blue Horizon', 'STS TRUCKING', 'AL JR TRUCKING', 'MG Trucking']\n"
     ]
    }
   ],
   "source": [
    "listo = listo[:50]\n",
    "count_50 = sum([x[1] for x in listo])\n",
    "print(\"# 50: \", count_50)\n",
    "print(\"Percentage 50: \", count_50/len(names))\n",
    "\n",
    "names_arr = [tuples[0] for tuples in listo]\n",
    "print(names_arr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def bucketize(df):\n",
    "    days_worked = []\n",
    "    for index, row in df.iterrows(): # bucketize the most frequent dim_carrier_company names, \n",
    "                                     # put less frequent names in a single bucket\n",
    "        try:\n",
    "            if row[\"dim_carrier_company_name\"] not in names_arr:\n",
    "                df.at[index, \"dim_carrier_company_name\"] = \"Other\"\n",
    "        except:\n",
    "            df.at[index, \"dim_carrier_company_name\"] = \"Other\"\n",
    "\n",
    "        # find number of days driver has worked\n",
    "        if row[\"most_recent_load_date\"] != np.nan and row[\"first_load_date\"] != np.nan:\n",
    "            days_worked.append((row[\"most_recent_load_date\"] - row[\"first_load_date\"]).days)\n",
    "        else:\n",
    "            days_worked.append(None)\n",
    "    df[\"days_tenured\"] = np.array(days_worked)\n",
    "\n",
    "bucketize(df)\n",
    "bucketize(df_score)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get total_loads for df_score in order to find labels\n",
    "total_loads = []\n",
    "for index, row in df_score.iterrows():\n",
    "    total_loads.append(row[\"marketplace_loads\"] + row[\"brokerage_loads\"])\n",
    "df_score[\"total_loads\"] = np.array(total_loads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "164.0\n",
      "2020-10-07 06:00:00\n"
     ]
    }
   ],
   "source": [
    "total_loads_score_75 = df_score.total_loads.quantile(0.75) # finds 75th percentile of loads\n",
    "most_recent_load_date_score_75 = df_score.most_recent_load_date.quantile(0.75) # finds 75th percentile of most recent load date\n",
    "\n",
    "print(total_loads_score_75)\n",
    "print(most_recent_load_date_score_75)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "668\n",
      "[0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 1, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 0, 0, 0, 1, 1, 0, 0, 1, 0, 1, 0, 0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0]\n"
     ]
    }
   ],
   "source": [
    "score_labels = []\n",
    "for index, row in df_score.iterrows(): # changes the labels in the label columns\n",
    "    # checks if the load and most recent load date are in the 75th percentile\n",
    "    if row[\"total_loads\"] >= total_loads_score_75 and row[\"most_recent_load_date\"] >= most_recent_load_date_score_75:\n",
    "        score_labels.append(1)\n",
    "    else:\n",
    "        score_labels.append(0)\n",
    "print(len(score_labels))\n",
    "print(score_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "cols = [\"most_recent_load_date\", \"first_load_date\", \"weekday\", \"load_day\", \"total_loads\"]\n",
    "for col in cols:\n",
    "    try:\n",
    "        df = df.drop(columns=[col])\n",
    "        df_score = df_score.drop(columns=[col])\n",
    "    except:\n",
    "        continue"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_unlabeled = df.drop(columns=[\"label\"])\n",
    "labels = df[\"label\"].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 5291 entries, 0 to 5290\n",
      "Data columns (total 16 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   dim_carrier_type                   5291 non-null   string \n",
      " 1   dim_carrier_company_name           5291 non-null   string \n",
      " 2   carrier_trucks                     5291 non-null   object \n",
      " 3   signup_source                      5291 non-null   string \n",
      " 4   days_signup_to_approval            3962 non-null   Int64  \n",
      " 5   num_trucks                         5249 non-null   float64\n",
      " 6   driver_with_twic                   5291 non-null   string \n",
      " 7   marketplace_loads_otr              5291 non-null   Int64  \n",
      " 8   marketplace_loads_atlas            5291 non-null   Int64  \n",
      " 9   marketplace_loads                  5291 non-null   Int64  \n",
      " 10  brokerage_loads_otr                5291 non-null   Int64  \n",
      " 11  brokerage_loads_atlas              5291 non-null   Int64  \n",
      " 12  brokerage_loads                    5291 non-null   Int64  \n",
      " 13  num_trips_made                     5291 non-null   Int64  \n",
      " 14  drayage_interested_port_qualified  5291 non-null   object \n",
      " 15  days_tenured                       5291 non-null   int64  \n",
      "dtypes: Int64(8), float64(1), int64(1), object(2), string(4)\n",
      "memory usage: 702.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_unlabeled.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 668 entries, 0 to 667\n",
      "Data columns (total 16 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   dim_carrier_type                   668 non-null    string \n",
      " 1   dim_carrier_company_name           668 non-null    string \n",
      " 2   carrier_trucks                     668 non-null    object \n",
      " 3   signup_source                      668 non-null    string \n",
      " 4   days_signup_to_approval            572 non-null    Int64  \n",
      " 5   num_trucks                         668 non-null    float64\n",
      " 6   driver_with_twic                   668 non-null    string \n",
      " 7   marketplace_loads_otr              668 non-null    Int64  \n",
      " 8   marketplace_loads_atlas            668 non-null    Int64  \n",
      " 9   marketplace_loads                  668 non-null    Int64  \n",
      " 10  brokerage_loads_otr                668 non-null    Int64  \n",
      " 11  brokerage_loads_atlas              668 non-null    Int64  \n",
      " 12  brokerage_loads                    668 non-null    Int64  \n",
      " 13  num_trips_made                     668 non-null    Int64  \n",
      " 14  drayage_interested_port_qualified  668 non-null    object \n",
      " 15  days_tenured                       668 non-null    int64  \n",
      "dtypes: Int64(8), float64(1), int64(1), object(2), string(4)\n",
      "memory usage: 88.8+ KB\n"
     ]
    }
   ],
   "source": [
    "df_score.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "Int64Index: 5959 entries, 0 to 667\n",
      "Data columns (total 16 columns):\n",
      " #   Column                             Non-Null Count  Dtype  \n",
      "---  ------                             --------------  -----  \n",
      " 0   dim_carrier_type                   5959 non-null   string \n",
      " 1   dim_carrier_company_name           5959 non-null   string \n",
      " 2   carrier_trucks                     5959 non-null   object \n",
      " 3   signup_source                      5959 non-null   string \n",
      " 4   days_signup_to_approval            4534 non-null   Int64  \n",
      " 5   num_trucks                         5917 non-null   float64\n",
      " 6   driver_with_twic                   5959 non-null   string \n",
      " 7   marketplace_loads_otr              5959 non-null   Int64  \n",
      " 8   marketplace_loads_atlas            5959 non-null   Int64  \n",
      " 9   marketplace_loads                  5959 non-null   Int64  \n",
      " 10  brokerage_loads_otr                5959 non-null   Int64  \n",
      " 11  brokerage_loads_atlas              5959 non-null   Int64  \n",
      " 12  brokerage_loads                    5959 non-null   Int64  \n",
      " 13  num_trips_made                     5959 non-null   Int64  \n",
      " 14  drayage_interested_port_qualified  5959 non-null   object \n",
      " 15  days_tenured                       5959 non-null   int64  \n",
      "dtypes: Int64(8), float64(1), int64(1), object(2), string(4)\n",
      "memory usage: 838.0+ KB\n"
     ]
    }
   ],
   "source": [
    "df_concat = pd.concat([df_unlabeled, df_score])\n",
    "df_concat.info()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "imputer = IterativeImputer()\n",
    "categorical_features_one_hot = [\"dim_carrier_type\", \"dim_carrier_company_name\", \"carrier_trucks\", \n",
    "                                \"signup_source\", \"driver_with_twic\", \"drayage_interested_port_qualified\"]\n",
    "\n",
    "df_num = df_concat.drop(columns=categorical_features_one_hot)\n",
    "numerical_features = list(df_num)\n",
    "\n",
    "num_pipeline = Pipeline([\n",
    "        ('imputer', imputer),\n",
    "        ('std_scaler', StandardScaler()),\n",
    "    ])\n",
    "\n",
    "full_pipeline = ColumnTransformer([\n",
    "        (\"num\", num_pipeline, numerical_features),\n",
    "        (\"cat\", OneHotEncoder(sparse=False), categorical_features_one_hot),\n",
    "    ])\n",
    "df_prepared = full_pipeline.fit_transform(df_concat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 0.19069159, -0.39848404, -0.23261086, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.09368743, -0.39848404, -0.23261086, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       [-0.03227512, -0.39848404, -0.23261086, ...,  0.        ,\n",
       "         0.        ,  1.        ],\n",
       "       ...,\n",
       "       [-0.89155671, -0.39848404, -0.23261086, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.89155671, -0.37499584, -0.15643114, ...,  1.        ,\n",
       "         0.        ,  0.        ],\n",
       "       [-0.89155671, -0.39848404, -0.23261086, ...,  0.        ,\n",
       "         1.        ,  0.        ]])"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "display(df_prepared)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = df_prepared[:5291]\n",
    "y = labels\n",
    "score_y = df_prepared[5291:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(4232, 88) (1059, 88)\n",
      "(4232,) (1059,)\n"
     ]
    }
   ],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "print(X_train.shape, X_test.shape)\n",
    "print(y_train.shape, y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 5. Linear Regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.linear_model import LinearRegression\n",
    "\n",
    "lin_reg = LogisticRegression()\n",
    "lin_reg.fit(X_train, y_train)\n",
    "lr_predicted = lin_reg.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import mean_squared_error\n",
    "\n",
    "mse = mean_squared_error(target_test, lr_predicted)\n",
    "rmse = np.sqrt(mse)\n",
    "rmse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import statsmodels.api as sm\n",
    "\n",
    "X = sm.add_constant(X_train)\n",
    "toyregr_sm = sm.OLS(y_train, X)\n",
    "results_sm = toyregr_sm.fit()\n",
    "\n",
    "print(results_sm.summary())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 6. PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max_len = len(df.columns)\n",
    "arr = []\n",
    "for i in range(1, max_len+1):\n",
    "    pca = PCA(n_components=len(df.columns))\n",
    "    pca.fit(df)\n",
    "    arr.append(pca)\n",
    "    #pca.fit_transform(df)\n",
    "# need to transform test data after finishing data pipelining"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 7. Ensemble AKA Robert's BS pls mercy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import make_regression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestRegressor\n",
    "from sklearn.metrics import r2_score\n",
    "\n",
    "# assuming we have X_train,X_test,y_train,y_test at this time\n",
    "# I first run Random Forest using random hard coded settings to get a baseline\n",
    "rf = RandomForestRegressor(n_estimators=80,max_depth=7,max_features=3)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "test_score = r2_score(y_test,y_pred)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "import numpy as np\n",
    "# I then use RandomizedSearchCV to find the optimal hyperparameters\n",
    "n_estimators = [int(x) for x in np.linspace(start = 100, stop = 1000, num = 10)]\n",
    "max_features = ['auto', 'sqrt']\n",
    "max_depth = [int(x) for x in np.linspace(5, 100, num = 10)]\n",
    "max_depth.append(None)\n",
    "min_samples_split = [2, 5, 7, 10, 20]\n",
    "min_samples_leaf = [1, 2, 5, 10]\n",
    "bootstrap = [True, False]\n",
    "random_grid = {'n_estimators': n_estimators,\n",
    "               'max_features': max_features,\n",
    "               'max_depth': max_depth,\n",
    "               'min_samples_split': min_samples_split,\n",
    "               'min_samples_leaf': min_samples_leaf,\n",
    "               'bootstrap': bootstrap}\n",
    "\n",
    "rf_random = RandomizedSearchCV(estimator = rf, param_distributions = random_grid, n_iter = 100, cv = 3, verbose=2, random_state=42, n_jobs = -1)\n",
    "rf_random.fit(X_train, y_train)\n",
    "rf_random.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# I then output the r2 score again as a sanity check to verify that my RanomdizedSearchCV actually did find the best settings\n",
    "rf = RandomForestRegressor(n_estimators=700,max_depth=47,max_features='auto',min_samples_split=2,min_samples_leaf=2,bootstrap=True)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "test_score = r2_score(y_test,y_pred)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we then use the hyperparameters we found from the RandomizedSearchCV to do a second more thorough check around that range\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "param_grid = {\n",
    "    'bootstrap': [True],\n",
    "    'max_depth': [40, 45, 50, 55, 60],\n",
    "    'max_features': [2, 5, 7, 10, 12],\n",
    "    'min_samples_leaf': [2, 3, 4, 5, 6],\n",
    "    'min_samples_split': [2, 3, 4, 5, 6],\n",
    "    'n_estimators': [100, 200, 500, 700, 1000]\n",
    "}\n",
    "# Create a based model\n",
    "rf = RandomForestRegressor()\n",
    "# Instantiate the grid search model\n",
    "grid_search = GridSearchCV(estimator = rf, param_grid = param_grid, \n",
    "                          cv = 3, n_jobs = -1, verbose = 2)\n",
    "grid_search.fit(X_train, y_train)\n",
    "grid_search.best_params_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# we then output the results using the optimal hyperparameters to check that our model has improved\n",
    "rf = RandomForestRegressor(n_estimators=500,max_depth=40,max_features=7,min_samples_split=4,min_samples_leaf=2,bootstrap=True)\n",
    "rf.fit(X_train,y_train)\n",
    "y_pred = rf.predict(X_test)\n",
    "from sklearn.metrics import r2_score\n",
    "test_score = r2_score(y_test,y_pred)\n",
    "test_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# AdaBoost using the same settings\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn import metrics\n",
    "\n",
    "dt = DecisionTreeClassifier(max_depth=3)\n",
    "ab = AdaBoostClassifier(base_estimator=dt,learning_rate=1,n_estimators=50)\n",
    "ab.fit(X_train,y_train)\n",
    "y_pred = ab.predict(X_test)\n",
    "test_score = r2_score(y_test,y_pred)\n",
    "accuracyResult = metrics.accuracy_score(y_test,y_pred)\n",
    "print(\"R2 Score: \",test_score)\n",
    "print(\"Accuracy Score: \",accuracyResult)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 8. Neural Network Classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# # Define a transform to normalize the data\n",
    "# transform = transforms.Compose([transforms.ToTensor(),\n",
    "#                                 transforms.Normalize((0.5,), (0.5,)),\n",
    "#                               ])\n",
    "# Download and load the training data\n",
    "NN_X_train = torch.tensor(df.drop([\"label\"], axis=1).values)\n",
    "NN_y_train = torch.tensor(df[\"label\"].values)\n",
    "trainset = TensorDataset(NN_X_train, NN_y_train)\n",
    "trainloader = DataLoader(trainset, batch_size=64, shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "NUM_FEATURES = 20\n",
    "NUM_HIDDEN1_NODES = 400\n",
    "NUM_EPOCHS = 30\n",
    "\n",
    "model = nn.Sequential(nn.Linear(NUM_FEATURES, NUM_HIDDEN1_NODES),\n",
    "                      nn.Sigmoid(),\n",
    "                      nn.Linear(NUM_HIDDEN1_NODES, 1)\n",
    "                     )\n",
    "\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimizer = optim.SGD(model.parameters(), lr=0.003)\n",
    "\n",
    "for e in range(NUM_EPOCHS):\n",
    "    running_loss = 0\n",
    "    for data, labels in trainloader:\n",
    "        optimizer.zero_grad()\n",
    "        output = model(data)\n",
    "        loss = criterion(output, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    print(f\"Training loss: {running_loss/len(trainloader)}\")\n",
    "    \n",
    "# class NeuralNet(nn.Module):\n",
    "#     def __init__(self):\n",
    "#         super(NeuralNet, self).__init__()\n",
    "        \n",
    "#         # Inputs to hidden layer linear transformation\n",
    "#         self.hidden1 = nn.Linear(NUM_FEATURES, NUM_HIDDEN1_NODES)\n",
    "#         self.output = nn.Linear(NUM_HIDDEN1_NODES, 1)\n",
    "        \n",
    "#         self.sigmoid = nn.Sigmoid()\n",
    "        \n",
    "#     def forward(self, x):\n",
    "#         x = self.hidden1(x)\n",
    "#         x = self.sigmoid(x)\n",
    "#         x = self.output(x)\n",
    "#         x = self.softmax(x)\n",
    "#         return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model = Network()\n",
    "# model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 9. Cross-Validate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn import model_selection\n",
    "\n",
    "kfold = model_selection.KFold(n_splits=10, random_state=42, shuffle=True)\n",
    "\n",
    "sample_model_kfold = sample()\n",
    "\n",
    "sample_results_kfold = model_selection.cross_val_score(sample_model_kfold, df_prepared, df_labels, cv=kfold)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
